---
title: "HHI VR Interface User Test - Data Analysis - R Markdown"
author: "Alexander Masurovsky"
date: "7/14/2019"
output: 
  pdf_document: 
    fig_height: 6
    fig_width: 9
    toc: yes
---

```{r markdown_setup}
knitr::opts_chunk$set(tidy = TRUE, message = FALSE, warning = FALSE, echo=TRUE)

```

# Initialize

Initial setup code: directories, libraries, etc.
```{r setup}
rm(list=ls()) # clear variables
cat("\014") # clear console

# load libraries
library(readr)
library(readxl)
library(tidyverse)
library(dplyr)
library(psych)
library(ggplot2)
library(see) #geomviolindot
library(RColorBrewer)
library(cowplot)
library(lsr)
library(ggpubr)
library(car)
library(rstatix)
library(tinytex)
library(xtable)
library(stargazer)
library("TOSTER")
source("R_rainclouds.R")
#source("smart_t_test.R")

# set analysis directory (current working directory)
analysis_dir <- "~/R/Projects/HHI_Leap_User_Test/"

# set unity data directory
unity_data_dir <- "~/R/Projects/HHI_Leap_User_Test/Unity_Data"

# set coagulated survey data file name
survey_data_filename <- "survey_results.xlsx"

# Note: drop count data files stored in Drop_Counting directory

# select subjects to remove for analysis (99 means remove none)
remove_these_subjects <- 99 # c(12, 30)

```

## Global aesthetics
```{r aesthetics_global}
# theme
theme_set(theme_cowplot())

# plot order
plot_order <- c("B_Leap","HHI_Leap","Oculus")

# colors
mycolors=c("darkgrey","blue","darkorange") # colorblind safe (I think)
#mycolors=c("darkorange","forestgreen","blue")
#mycolors=c("grey","forestgreen","black")
#mycolors=c("mediumseagreen", "pink3", "black")
#mycolors=c("mediumseagreen", "thistle3", "black")
mysmoothing=1.5
myalpha=.3

# text sizes
title_size <- 30
axis_text_size <- 30
legend_title_size <- 10
legend_text_size <- 10
legend_pos <- "none"

#significance symbols
mysymbols = c("*** ", "***", "**", "*","")
mysymbols2 = c("*** ", "***", "**", "*","p > .05")


```

# Pre-processing

## Survey data

### Load in and organize

1.  Save as .xlsx (may need to open in Google Docs first)
2.  Clean manually **before running this script** using find-and-replace -- numbers initially contain additional text that needs to be eliminated
3.  Name file this: survey_results.xlsx
The following code will load in the survey data after the above steps have been completed manually. The data set will be called **survey_data**.
```{r setup_subjective_data}
# Get names: read in old questionnaire for variable names
library(readxl)
survey_data <- read_excel(survey_data_filename, na="")

# clean headers and set up variables
# rename sentence for User Id column to just UserID
survey_data <- survey_data %>% rename(UserID = contains("user"))
# fix variable names by removing everything after the "."
names(survey_data) <- gsub("\\..*","",names(survey_data))

#survey_data$UserID <- factor(survey_data$UserID) # make UserID column into factors
survey_data <- survey_data %>% arrange(UserID) #order by user id

# rename columns
survey_data <- survey_data %>%
  rename(UserID=contains("UserID"),
         Hand=contains("starkeHand"),
         Gender=Sex,
         Arm=armlength,
         Disabilities=contains("Disabilities"),
         SkillController=`Skills[SkillController]`,
         SkillVR=`Skills[SkillVR]`,
         SkillGames=`Skills[SkillGames]`) %>%
  mutate(PrefCondition=factor(PrefCondition),
         Gender=factor(Gender, labels=c("Male","N/A", "Female")),
         UserID=factor(UserID),
         Hand=factor(Hand, labels=c("Left","Right")),
         `OculusQuestion[qO4]`=6-`OculusQuestion[qO4]`, # reverse score these questions
         `OculusQuestion[qO5]`=6-`OculusQuestion[qO6]`,
         `OculusQuestion[qO6]`=6-`OculusQuestion[qO6]`,
         `StandardLeapQuestion[qL4]`=6-`StandardLeapQuestion[qL4]`,
         `StandardLeapQuestion[qL5]`=6-`StandardLeapQuestion[qL5]`,
         `StandardLeapQuestion[qL6]`=6-`StandardLeapQuestion[qL6]`,
         `HHILeapQuestion[qH4]`=6-`HHILeapQuestion[qH4]`,
         `HHILeapQuestion[qH5]`=6-`HHILeapQuestion[qH5]`,
         `HHILeapQuestion[qH6]`=6-`HHILeapQuestion[qH6]`
          ) %>%
  mutate(PrefCondition=recode_factor(PrefCondition,
   "ohne Controller, Variante 1 (Standard Leap Motion)"="B_Leap",
            "mit Controller"="Oculus",
            "ohne Controller, Variante 2 (Leap Motion mit HHI-Anpassungen)"="HHI_Leap")) %>%
  arrange(UserID)



# create sample size variable for future use
sample_size = length(levels(survey_data$UserID)) # establish sample size

```

### Score SUS

```{r score_SUS}
# Score the SUS 
# (source: https://measuringu.com/sus/)
# For odd items: subtract one from the user response.
# For even-numbered items: subtract the user responses from 5
# This scales all values from 0 to 4 (with four being the most positive response).
# Add up the converted responses for each user and multiply that total by 2.5. This converts the 
# range of possible values from 0 to 100 instead of from 0 to 40.

# subset SUS questions by group; only take UserID and SUS data, recombine or compare/correlate with
# other data later
SUS_data <- select(survey_data, UserID, contains("SUS"))
SUS_data <- SUS_data[order(SUS_data$UserID),] # order by user id, in case there are missing user id nums

# generate SUS score for
# 1) each user and
# 2) each Interface, then
# 3) put into df of user ID x (SUS score x Interface)
# update the following df w/ scores as the loop progresses

SUS_scores <- data.frame("UserID"=SUS_data$UserID, Standard=1, HHI=1, Oculus=1)
# DO NOT CHANGE GROUP NAMES!

groups <- c("Standard", "HHI", "Oculus") # quick group names; correspond to Unity data labels

for (subj in 1:length(survey_data$UserID)){ # loop through all subjects
  for (grp in 1:3){ # loop through each condition/Interface
    tmp_score <- 0 # set temp score, add to it
    tmp_subset <- SUS_data %>%
      filter(UserID==subj) %>%
      select(contains(groups[grp]))
    
    cell_val <- 0 # the subject's response which we will perform calculations upon (reset after each grp)
    # add up score in this next for loop, captured in tmp_score
    for (q_num in 1:length(tmp_subset)) { #length of SUS
      cell_val <- tmp_subset[[q_num]]
      if((q_num %% 2) == 0) { # check if even
        tmp_score <- tmp_score + (5-cell_val)
       } else { # if odd (not even)
        tmp_score <- tmp_score + (cell_val-1)
      }
    }
    SUS_scores[subj,groups[grp]] <- tmp_score*2.5
  }
}

rm(SUS_data) # for cleanliness
SUS_scores <- rename(SUS_scores, B_Leap=Standard, HHI_Leap=HHI)

```

## Unity data

### Setup

#### Combine individual Unity datasets into one

This will loop through every file in a directory and combine it into one excel file. This section of code is a dumb robot, so make sure that ONLY data files to be combined are in the directory specified below.
```{r combine_unity_data, warning=FALSE, message=FALSE}

# Data file directory (.csv files with Unity data from our user test only!):
setwd(unity_data_dir)

file_list <- list.files() 

for (file in file_list){
  # if the data frame variable does not exist, create it and read in first file
  if (!exists("dataset")){
    dataset <- read_csv2(file, col_names = TRUE, locale = locale(decimal_mark = ","))
  }
  # if the merged dataset does exist, append to it
  if (exists("dataset")){
    temp_dataset <- read_csv2(file, col_names = TRUE, locale = locale(decimal_mark = ","))
    dataset<-rbind(dataset, temp_dataset)
    rm(temp_dataset)
  }
}

# write to a new file
setwd("~/R/Projects/HHI_Leap_User_Test/")

# The code below prevents an already existing data set from being overwritten. Rename file_name to save new file, or delete old file manually.
file_name <- "collected_unity_data.csv"
if (file_name %in% list.files()){
  print("file already exists!")
} else {write.csv(dataset, file_name)}

rm(dataset) # remove variable for cleanliness
```

#### Load Unity data set

The following code
* loads the data set (**make sure to check that the filename and working directory are correct!**)
* establishes that the id numbers are factors, not numbers (important for later code)
* creates a vector of group names
```{r load_unity_data}
# set working directory
setwd(analysis_dir)

# Load Unity dataset (confirm filename!) -- assumes American-style .csv file, which the collected data file should now be
my_file = "collected_unity_data.csv" # confirm filename
data_set <- read.csv(my_file, numerals = "warn.loss") #, "no.loss"))

data_set <- data_set %>% 
  select(everything(), -X) %>% 
  rename(Cube_Size=ObjectName,
       Interface=Device,
       InterfaceOrder=DeviceOrder) %>%
  mutate(id=factor(id)) %>%
  mutate(Cube_Size=recode_factor(Cube_Size,
                                  "Cube10x10x10(Clone)"="Large",
                                  "Cube6x6x6(Clone)"="Medium",
                                  "Cube3x3x3(Clone)"="Small"),
         Interface=recode_factor(Interface,
                                 "Leap"="B_Leap",
                                 "Leap_HHI"="HHI_Leap")
  )

group_names <- c("B_Leap","HHI_Leap","Oculus") # will use this later

# remove duplicates (not sure why these exist)
trials_original_n <- nrow(data_set)
data_set <- data_set %>% distinct(.)
trials_duplicates_removed_n <- nrow(data_set)
```

#### Load in accidental drop data

An accidental drop is where the subject accidentally dropped the cube on the way to the target. These were initially noted manually by experimenter during the test. These are to be removed and counted as the Errors metric.

```{r load_in_accidental_drop_data, warning=FALSE, message=FALSE}
# load in all files from folder (make sure only data files in folder)
# add error (1 or 0) to trial number
# use SpawnOrder variable to match it up

# read in each data set and append to unity data set

# put name of directory w/ error files here
my_folder <- "Drop_Counting"
my_dir <- paste0(getwd(),"/",my_folder,"/")
setwd(my_dir)

file_list <- list.files() 
#file<-file_list[30]

for (file in file_list){
  temp_dataset <- read_excel(paste0(my_dir,file), skip=1, na="")
  temp_subject <- sub("\\.xlsx", "", file)
    temp_subject <- as.numeric(sub(".*S", "", temp_subject))
  
  # mutate temp dataset to match format of dataset (Interface="",id="", Drop=1 or 0)
  temp_dataset_long <- temp_dataset %>%
    slice(1:30) %>%
  select(Trial, Oculus, B_Leap='Leap', HHI_Leap='HHI Leap') %>%
    gather(key="Interface", value="Drop", 'Oculus':'HHI_Leap') %>%
    rename(SpawnOrder=Trial) %>%
    mutate(id=temp_subject,#id=as.character(temp_subject),
           SpawnOrder=as.numeric(SpawnOrder))
  temp_dataset_long$Drop[is.na(temp_dataset_long$Drop)] <- 0 #turn NA's into 0's 
  temp_dataset_long$Drop <- as.numeric(temp_dataset_long$Drop) # drops are numbers
  
  # add temp_dataset_long to big error data set
  if(!exists("error_dataset")){
    error_dataset <- temp_dataset_long
  } else {
    error_dataset <- bind_rows(error_dataset, temp_dataset_long)
  }
}


error_dataset <- error_dataset %>%
  mutate(id=factor(id))

# join error data to unity data set (data_set)
data_set <- left_join(data_set, error_dataset, by=c("id","Interface","SpawnOrder"))


setwd("..") # move back up to original folder

# clean up
rm(error_dataset, temp_dataset, temp_dataset_long, file_list, my_folder, my_dir)
```

#### InterfaceOrder data

The following code takes Interface order from the Unity data set and adds it to the survey data set.
```{r Interface_order}

# compile a data frame of user id and Interface order
Interface_order <- data.frame("id"=c(1:sample_size)) #create df to fill w/ Interface order by id
for (x in 1:length(Interface_order$id)){
  temp_subset <- subset(data_set, id==x)
  Interface_order[x,"InterfaceOrder"] <- temp_subset$InterfaceOrder[[1]]}
rm(temp_subset) # remove temp subset variable from list

# re-name Interface order to first letters only
# L=Standard Leap, H=HHILeap, O=Oculus
levels(Interface_order$InterfaceOrder) <- gsub("LeapHHI","H",levels(Interface_order$InterfaceOrder))
levels(Interface_order$InterfaceOrder) <- gsub("Leap","L",levels(Interface_order$InterfaceOrder))
levels(Interface_order$InterfaceOrder) <- gsub("Oculus","O",levels(Interface_order$InterfaceOrder))
levels(Interface_order$InterfaceOrder) <- gsub("-","",levels(Interface_order$InterfaceOrder))

# add Interface order to survey_data
# TRY WITH DPLYR LATER
survey_data <- cbind(survey_data, "InterfaceOrder"=Interface_order$InterfaceOrder)
#rm(Interface_order) # remove Interface order dataset to keep tings clean

group_counts <- data.frame(table(Interface_order$InterfaceOrder))
# rename columns to "Order" and "Count":
group_counts <- group_counts %>% rename(InterfaceOrder = Var1, Count=Freq) 

```

### Explore Unity data

The goal is to clean the data so that the mean metrics calculated (accuracy and time measures) reflect normal use of the interfaces, not errors such as accidental drops or a system glitch.

The new strategy is to use only one cleaning data set, using various filters. Determine the filters **first**, then apply all at once.

This will improve our ability to keep track of what we did and prevent multiple data sets from floating around.

#### Visualize accidental drops

First *plot time from grab to release* by *distance.*

Note: starting distance is 0.3 m.

Plots: Distance by release time (time from grab to grab loss).
Manually detected accidental drops are highlighted in red; distance > .2 m highlighted in orange; distance >.1 and < .2 highlighted in blue.
```{r verify_accidental_drops, results='hold'}

# create data_set.clean for inspection
data_set.clean <- data_set %>% filter(Drop==0, LandOnTable==TRUE)

# set limits
limits_y <- c(0,0.4)
limits_x <- c(0,10)

p_title<- ggdraw() + draw_label("Time from grab to release by distance \nHighlight: manually recorded drop", fontface='plain')

leap_drops <- ggplot(data_set %>% filter(Interface=="B_Leap"), aes(TimeFromGrabToGrabLoss, Distance, color=Drop==1, shape=LandOnTable))+
  geom_point(size=1)+
  theme(legend.position = "none")+
  scale_color_manual(values=c("Grey","Red"))+
  scale_shape_manual(values=c(15,16))+
  ggtitle(label="B_Leap")+
  coord_cartesian(xlim=limits_x, ylim=limits_y)

HHI_drops <- ggplot(data_set %>% filter(Interface=="HHI_Leap"), aes(TimeFromGrabToGrabLoss, Distance, color=Drop==1, shape=LandOnTable))+
  geom_point(size=1)+
  theme(legend.position = "none")+
  ggtitle(label="HHI")+
  scale_color_manual(values=c("Grey","Red"))+
  scale_shape_manual(values=c(15,16))+
  coord_cartesian(xlim=limits_x, ylim=limits_y)

oculus_drops <- ggplot(data_set %>% filter(Interface=="Oculus"), aes(TimeFromGrabToGrabLoss, Distance, color=Drop==1, shape=LandOnTable))+
  geom_point(size=1)+
  theme(legend.position = "none")+
  ggtitle(label="oculus")+
  scale_color_manual(values=c("Grey","Red"))+
  scale_shape_manual(values=c(15,16))+
  coord_cartesian(xlim=limits_x, ylim=limits_y)

plot_grid(p_title, leap_drops, HHI_drops, oculus_drops, labels="AUTO")

# potentially missed accidental drops
p_title<- ggdraw() + draw_label("Time from grab to grab loss by distance\nAccidental drops removed\nHighlight: distance > 0.2", fontface='plain')

leap_drops <- ggplot(data_set.clean %>% filter(Interface=="B_Leap"), aes(TimeFromGrabToGrabLoss, Distance, color=Distance>0.2))+
  geom_point(size=1)+
  scale_color_manual(values=c("Grey","Orange"))+
  theme(legend.position = "none")+
  ggtitle(label="B_Leap")+
  coord_cartesian(xlim=limits_x, ylim=limits_y)

HHI_drops <- ggplot(data_set.clean %>% filter(Interface=="HHI_Leap"), aes(TimeFromGrabToGrabLoss, Distance, color=Distance>0.2))+
  geom_point(size=1)+
  ggtitle(label="HHI")+
  theme(legend.position = "none")+
  scale_color_manual(values=c("Grey","Orange"))+
  coord_cartesian(xlim=limits_x, ylim=limits_y)

oculus_drops <- ggplot(data_set.clean %>% filter(Interface=="Oculus"), aes(TimeFromGrabToGrabLoss, Distance, color=Distance>0.2))+
  geom_point(size=1)+
  theme(legend.position = "none")+
  ggtitle(label="oculus")+
  scale_color_manual(values=c("Grey","Orange"))+
  coord_cartesian(xlim=limits_x, ylim=limits_y)

plot_grid(p_title, leap_drops, HHI_drops, oculus_drops, labels="AUTO")

# release times by distance
p_title<- ggdraw() + draw_label("Time from grab to release x distance \nHighlight: distance>0.1", fontface='plain')

leap_drops <- ggplot(data_set.clean %>% filter(Interface=="B_Leap", Drop==0), aes(TimeFromGrabToGrabLoss, Distance, color=Distance>=0.1 & Distance<0.2))+
  geom_point(size=1)+
  scale_color_manual(values=c("Grey","Blue"))+
  theme(legend.position = "none")+
  ggtitle(label="B_Leap")+
  coord_cartesian(xlim=limits_x, ylim=limits_y)

HHI_drops <- ggplot(data_set.clean %>% filter(Interface=="HHI_Leap", Drop==0), aes(TimeFromGrabToGrabLoss, Distance, color=Distance>=0.1 & Distance<0.2))+
  geom_point(size=1)+
  theme(legend.position = "none")+
  ggtitle(label="HHI")+
  scale_color_manual(values=c("Grey","Blue"))+
  coord_cartesian(xlim=limits_x, ylim=limits_y)

oculus_drops <- ggplot(data_set.clean %>% filter(Interface=="Oculus", Drop==0), aes(TimeFromGrabToGrabLoss, Distance, color=Distance>=0.1 & Distance<0.2))+
  geom_point(size=1)+
  ggtitle(label="oculus")+
  theme(legend.position = "none")+
  scale_color_manual(values=c("Grey","Blue"))+
  coord_cartesian(xlim=limits_x, ylim=limits_y)

plot_grid(p_title, leap_drops, HHI_drops, oculus_drops, labels="AUTO")

```
Looking at the pattern of manually recorded accidental drops (red), we can see that though most tend to be short times with distances around 0.3, some have longer times and smaller distances. There is no definitive rule for automatic detection.

Clearly some accidental drops were missed (**orange**), as there is a small cluster of data points in the top left for both Leap variants, with a distance around 0.3 and a time close to 0. The data points with longer times and distances over 0.2 are more mysterious; however, these could very well be accidental drops as well that were not observed by the experimenter.

With a distance cut-off of 0.2, these are removed, leaving a series of data points between the distances of 0.1 and 0.2 which need to be explained -- they may or may not also be accidental drops. Visually, the HHI Leap seems to have more of these data points. This is especially confusing because several of these points for both Leap conditions have times (grab and release) that are greater than 2 seconds.

Simply removing all data points with a distance greater than 0.1 would improve the accuracy metric for the HHI Leap. These data points should contain some sort of penalty, either as errors or in the accuracy average.

There are data points with low times that also have high accuracy (low distance). Therefore, simply using a low time from grab to release is not enough to automatically detect accidental drops.

**Distance cut-offs**

**All data points over 0.2 can reasonably be considered accidental drops**. More investigation needs to be done to determine what to do with **data points with a distance between 0.1 and 0.2**. For **Longer times**, it is difficult to explain these data points between distances of 0.1 and 0.2, *especially those with longer times from grab to release*.

**Shorter release times** in the 0.1-0.2 distance range could indicate accidental drops that were not caught by the experimenter.

We can try to visualize grab and release errors by plotting time to grab and time from grab to release on one plot. I've done so below, using *color* to indicate long distances. Red: closer to 0.3; blue: between 1 and 2; grey: less than 1. Square data points indicate cubes that did not land on the table.

These plots *include* manually-detected accidental drops (they have not yet been removed).

##### Metric-based detection: Accidental Drops

```{r grab_by_release_plots}

temp_plot_data <- data_set
dist_group <- "string"

# put each trial into a bin for plotting purposes
for (x in 1:length(temp_plot_data$Distance)){
  if (temp_plot_data$LandOnTable[x]==FALSE){dist_group[x] <- "off table"} else {
  if (temp_plot_data$Distance[x] < 0.1){dist_group[x]<-"<0.1"}
  if (temp_plot_data$Distance[x] >=0.1 & temp_plot_data$Distance[x]<0.2){dist_group[x]<-"0.1-0.2"}
  if (temp_plot_data$Distance[x] >=0.2 & temp_plot_data$Distance[x]<=0.3){dist_group[x]<-"0.2-0.3"}
  if (temp_plot_data$Distance[x] >0.3){dist_group[x] <- ">0.3"}
}}
dist_group=factor(dist_group, levels=c("<0.1","0.1-0.2","0.2-0.3",">0.3","off table"))
if ("dist_group" %in% names(temp_plot_data)){} else {
temp_plot_data <- cbind(temp_plot_data, dist_group)}
rm(dist_group)

# grab times by release times w/ color gradient for distance


# set parameters
grab_lims=c(0,4)
release_lims=c(0,5)
alpharange=c(0.1,0.4)
val_colors<-c("grey33","blue", "coral3", "coral2", "coral")


# title
p_title<- ggdraw()+
  draw_label("Dashed line: Release time = 0.5 s\n\nBlue dots left of dotted line are\nconsidered accidental drops", fontface='plain', hjust=0.6)

p_leap <- ggplot(temp_plot_data %>% 
                   filter(Interface=="B_Leap"), aes(TimeFromGrabToGrabLoss, TimeFromSpawnToGrab, color=dist_group, alpha=Distance>0.1))+
  geom_point(size=1)+
  #scale_color_gradientn(colors=c("Grey","Blue","Red"), limits=c(0,0.3))+
  #scale_color_gradient(low="grey33", high="Red", guide="colourbar", limits=c(0,0.3))+
  #scale_alpha_continuous(limits=c(0,0.1), range=alpharange, guide=guide_legend(reverse=TRUE, title="< 0.1"))+
  theme(plot.title = element_text(size=title_size*.6), axis.title = element_text(size=axis_text_size*.7))+
  scale_shape_manual(values=c(15,16), guide="none")+
  scale_alpha_manual(values=c(0.1,1.0), guide="none")+
  scale_color_manual(values=val_colors, guide="none")+
  geom_vline(aes(xintercept=0.5), linetype="dashed")+
  labs(color="Accuracy", title="B_Leap", x="Release time (s)", y="Grab time (s)")+
  #theme(legend.position = "none")+
  coord_cartesian(ylim=grab_lims, xlim=release_lims)

p_HHI <- ggplot(temp_plot_data %>% filter(Interface=="HHI_Leap"), aes(TimeFromGrabToGrabLoss, TimeFromSpawnToGrab, color=dist_group, alpha=Distance>0.1))+
  geom_point(size=1)+
  scale_color_manual(values=val_colors)+
  scale_shape_manual(values=c(15,16), guide="none")+
  geom_vline(aes(xintercept=0.5), linetype="dashed")+
 # scale_alpha_continuous(limits=c(0,0.1), range=alpharange, guide="none")+
  #scale_color_gradientn(colors=c("Grey","Blue","Red"), limits=c(0,0.3))+
  scale_alpha_manual(values=c(0.1,1.0))+
  theme(plot.title = element_text(size=title_size*.6), axis.title = element_text(size=axis_text_size*.7))+
  #scale_color_gradient(low="Grey", high="Red", guide="colourbar", limits=c(0,0.3))+
  theme(legend.position = "none")+
  labs(color="Accuracy", title="HHI_Leap", x="Release time (s)", y="Grab time (s)")+
  coord_cartesian(ylim=grab_lims, xlim=release_lims)

p_oculus <- ggplot(temp_plot_data %>% filter(Interface=="Oculus"), aes(TimeFromGrabToGrabLoss, TimeFromSpawnToGrab, color=dist_group, alpha=Distance>0.1))+
  geom_point(size=1)+
  #scale_color_gradient(low="Grey", high="Red", guide="colourbar", limits=c(0,0.3))+
  #scale_color_gradientn(colors=c("Grey","Blue","Red"), limits=c(0,0.3))+
  scale_alpha_manual(values=c(0.1,1.0), guide="none")+
  geom_vline(aes(xintercept=0.5), linetype="dashed")+
  theme(plot.title = element_text(size=title_size*.6), axis.title = element_text(size=axis_text_size*.7))+
  scale_color_manual(values=val_colors, guide=guide_legend(reverse=TRUE, override.aes=list(size=5)), breaks=c("<0.1","0.1-0.2","0.2-0.3",">0.3","off table"))+
  scale_shape_manual(values=c(16,15), guide="none")+
 # scale_alpha_continuous(limits=c(0,0.1), range=alpharange, guide="none")+
  #theme(legend.position = "none")+
  labs(color="Accuracy (m)", title="Oculus", x="Release time (s)", y="Grab time (s)")+
  coord_cartesian(ylim=grab_lims, xlim=release_lims)

plot_grid(p_leap, p_HHI, p_oculus, labels=c("A","B","C",""))#p_title)
ggsave("accidental_drop_detection.jpg", width=10, height=8)



```

For B_Leap, there are many red dots on the left side of the plot, where time from grab to release is close to 0. This indicates a quick drop right after pick-up and a long distance from the target -- almost definitely an accidental drop.

For HHI Leap, there are not as many red dots, but there appear to be more blue dots (between 0.1 and 0.2), e.g., there is a blue dot with a grab time of ~1 second and a release time of ~4 seconds. 

The last plot is to determine if the same subjects are responsible for the weird values (distance: 0.1-0.2). Subjects 16 and 25 each have 3 values on this plot. The question we are trying to answer is: are values under a certain time indicative of an accidental drop?

The red dots in the bottom-left corner, where x and y are both close to 0, *may represent an accidental spawn into the hand*. There appears to be only one, for the B_Leap, that really fits this description (however, this is following removal of manually-detected accidental drops). This method could potentially determine which of the manually-detected accidental drops were spawn-into-the-hand errors, **which could potentially demonstrate the success of the HHI Leap's modified grab algorithm**.

##### Closer look

Below are plots of
* trials that did not land on the table
* distances between 0.1 and 0.2, color-coded by subject
* very low grab times with high accuracy, color-coded by subject
```{r grab_release_more_exploration}
ggplot(temp_plot_data %>% filter(LandOnTable==FALSE), aes(TimeFromGrabToGrabLoss, TimeFromSpawnToGrab, color=as.factor(Drop)))+
  geom_point(size=5, shape=15)+
  scale_color_manual(values=c("blue","red"), labels=c("No", "Yes"), guide=guide_legend(title="Accidental drop"))+
  scale_shape_manual(values=c(16,15))+
  #theme(legend.position = "none")+
  ggtitle(label="Landed off table: accidental drops")+coord_cartesian(ylim=grab_lims, xlim=release_lims)

ggplot(temp_plot_data %>% filter(Interface=="HHI_Leap", Distance>=0.1 & Distance<0.2), aes(TimeFromGrabToGrabLoss, TimeFromSpawnToGrab, color=id, size=Distance))+
  geom_point()+
  scale_size_continuous(limits=c(0.1,0.2), range=c(3,6))+
  #theme(legend.position = "none")+
  ggtitle(label="Distance 0.1-0.2, HHI")+coord_cartesian(ylim=c(0,3), xlim=release_lims)

ggplot(temp_plot_data %>% filter(Interface=="HHI_Leap", Distance<0.02, TimeFromSpawnToGrab<0.3), aes(TimeFromGrabToGrabLoss, TimeFromSpawnToGrab, color=id))+
  geom_point(size=5)+
  geom_text(aes(label=Distance),vjust=-0.1,position=position_jitter(width=0,height=0.003))+
  #scale_size_continuous(limits=c(0.1,0.2), range=c(3,6))+
  #theme(legend.position = "none")+
  ggtitle(label="Low grab times, high accuracy, HHI Leap")+coord_cartesian(ylim=c(0,0.02), xlim=c(1,3))

```

There are four points for the HHI Leap that have a grab time between 0.01 and 0.015 seconds, yet very high accuracy (shown in text). This may indicate an error in how the system registered grab time, or perhaps a data entry error. These will be eliminated by setting a grab time cut-off at 0.1 seconds and will *not* be added to the accidental drop counts.

5 trials were logged by the system as having not landed on the table. 3 of them were recorded manually as accidental drops. I think it is safe to say that the other two were also accidental drops, simply missed by the researcher. The additional two will be included as accidental drops.

### Visualize all Unity data

**Distance** or **Accuracy** is defined as the length of the 2D vector from the center point of the cube's bottom surface to the center point of the target. Unit is meters.
Distance of the cube at spawn: 30 cm (0.3 m).
Spawn = regeneration of cube at the beginning of a new trial, taken from video gaming lingo.

**Time from spawn to grab** is the time from when the cube spawned to the time that the user successfully grabbed the cube. This will be renamed to **grab time**.

**Time from grab to grab loss** is the measurement of time from grab to release. This will be renamed to **release time**.

**Time from spawn to grab loss** is the total time for each trial. This will be renamed to **total time**.

The following plots explore these metrics; manually-recorded drops and trials where the cube did not land on the table are *not inculded*.
```{r explore_unity_metrics, results='hold'}
#note: using data_set.clean (drops and offtable removed)

# box plot, distance by subject, pre clean
distance_subjects_box<-  ggplot(data_set.clean, aes(id, Distance, color=Interface)) +
  theme_minimal() +
  theme(legend.position = "none") +
  geom_boxplot(#outlier.colour="black",
           outlier.size=1, notch=FALSE) +
  scale_color_brewer(palette="Dark2") +
    labs(title="Distance - subject and Interface") +
    coord_cartesian(ylim=c(0, 0.4))

# grab times box plot of subjects and Interfaces pre clean
grabtime_subjects_box<-  ggplot(data_set.clean, aes(id, TimeFromSpawnToGrab, color=Interface)) +
  theme_minimal() +
  theme(legend.position = "none") +
  geom_boxplot(outlier.size=1, notch=FALSE) +
  # geom_point() +
#  geom_violin(scale="area") +
  scale_color_brewer(palette="Dark2") +
    labs(title="Grab times - subject and Interface") +
    coord_cartesian(ylim=c(0, 10))

# release times - by subject - box plot
releasetime_subjects_box<- ggplot(data_set.clean, aes(id, TimeFromGrabToGrabLoss, color=Interface)) +
theme_minimal() +
theme(legend.position = "bottom") +
geom_boxplot(outlier.size=1, notch=FALSE) +
scale_color_brewer(palette="Dark2") +
  labs(title="Release times - subject and Interface") #+coord_cartesian(ylim=c(0, 0.1))

plot_grid(distance_subjects_box, grabtime_subjects_box, releasetime_subjects_box)

# density plot: distance
distance_density<- ggplot(data_set.clean, aes(Distance))+
  #geom_histogram(binwidth = 0.1)+
  geom_density(fill="Grey")+labs(paste0("Distance, mean=",round(mean(data_set.clean$Distance),2)))+
  geom_vline(aes(xintercept = mean(Distance)), color="Blue")+theme(legend.position = "none")+coord_cartesian(xlim=c(0,0.4))

# density plot: spawn to grab
grabtime_density<- ggplot(data_set.clean, aes(TimeFromSpawnToGrab))+
  #geom_histogram(binwidth = 0.1)+
  geom_density(fill="Grey")+labs(paste0("Grab time, mean=",round(mean(data_set.clean$TimeFromSpawnToGrab),2)))+geom_vline(aes(xintercept = mean(TimeFromSpawnToGrab)), color="Blue")+theme(legend.position = "none")#+coord_cartesian(xlim=c(0,10))

# density plot: grab to release time
releasetime_density<- ggplot(data_set.clean, aes(TimeFromGrabToGrabLoss))+
  #geom_histogram(binwidth = 0.1)+
  geom_density(fill="Grey")+labs(paste0("Release time, mean=",round(mean(data_set.clean$TimeFromGrabToGrabLoss),2)))+
  geom_vline(aes(xintercept = mean(TimeFromGrabToGrabLoss)), color="Blue")+theme(legend.position = "none")#+coord_cartesian(xlim=c(0,10))

# density plot: total time
totaltime_density<- ggplot(data_set.clean, aes(TimeFromSpawnToGrabLoss))+
  #geom_histogram(binwidth = 0.1)+
  geom_density(fill="Grey")+labs(paste0("Total time, mean=",round(mean(data_set.clean$TimeFromSpawnToGrabLoss),2)))+
  geom_vline(aes(xintercept = mean(TimeFromSpawnToGrabLoss)), color="Blue")#+coord_cartesian(xlim=c(0,10))

plot_grid(distance_density, grabtime_density, releasetime_density, totaltime_density)

# bot plots
distance_box<- ggplot(data_set.clean, aes(Interface, Distance, color=Interface))+geom_boxplot()+scale_color_brewer(palette="Set2")+ggtitle(label="Distance")+ coord_cartesian(ylim=c(0,0.4))+theme(legend.position = "none")#+coord_flip(ylim=c(0,0.35))
  #geom_text(data=data_set.clean %>% filter(Distance > 0.5), aes(Interface, Distance, label=paste0(Distance), position="stack"))

distance_box2<- ggplot(data_set.clean, aes(Interface, Distance, color=Interface))+
  geom_boxplot(guide="none")+scale_color_brewer(palette="Set2")+ggtitle(label="Distance")+theme(legend.position = "none")#+coord_cartesian(ylim=c(0,0.4))

grabtime_box<- ggplot(data_set.clean, aes(Interface, TimeFromSpawnToGrab, color=Interface))+
  geom_boxplot()+scale_color_brewer(palette="Set2")+ggtitle(label="Time from spawn to grab")+theme(legend.position = "none")#+coord_cartesian(ylim=c(0,0.4))

releasetime_box<- ggplot(data_set.clean, aes(Interface, TimeFromGrabToGrabLoss, color=Interface))+
  geom_boxplot()+scale_color_brewer(palette="Set2")+ggtitle(label="Time from grab to release")+theme(legend.position = "none")#+coord_cartesian(ylim=c(0,0.4))

totaltime_box<- ggplot(data_set.clean, aes(Interface, TimeFromSpawnToGrabLoss, color=Interface))+
  geom_boxplot()+scale_color_brewer(palette="Set2")+ggtitle(label="Total time")#+coord_cartesian(ylim=c(0,0.4))

plot_grid(distance_box, distance_box2, grabtime_box, releasetime_box, totaltime_box)

```

#### Extreme oultliers

There are some extremely long times in both the grab and release time metrics.

For **grab times**, a time of 30 seconds may be due to a problem that we do not want to include in our metric, such as if the subject stopped and asked the experimenter for help. These outliers may have an impact on the mean and will certainly affect the variance.

Subject 12 seems to have absurdly long grab times for the HHI Leap Motion. 

Subjects 12 and 30 both seem to absurdly have long release times. They also have very low distance times. Clearly they prioritized accuracy over time.

Subjects 31 and 32 were run as potential replacements. The grab times for subject 31 on the HHI Leap seem much higher than the other two, but the difference from the other two Interfaces, and variance, are not so large as with subject 12. Release times for subjects 31 and 32 seems normal.

There is a case for considering these two to be outliers.

Let's take a quick look at subject 12 and 30's demographics and other stats compared to the rest of the over-all group.

Then we will look at overall times for subjects 12 and 30, as well as overall times for subjects 31 and 32.

#### Replace subjects?

```{r subject_12, results='hold'}

# subject 12 and 30's demo's
cat("\nSubject 12 and 30:\n")
survey_data %>%
  filter(UserID==12 | UserID==30) %>%
  select(UserID, Age:SkillGames, Gender, Hand)

# the sample
cat("\nThe sample:\n")
survey_data %>% 
  filter(UserID!=12 & UserID!=30) %>%
  select(Age:SkillGames) %>%
  summarise_each(median)
cat("\n")

# sample gender distribution
ggplot(survey_data %>%
        filter(UserID!=12) %>%
        select(UserID, Gender) %>%
        count(Gender) %>%
        mutate(percent=round(100*(n/sum(n)),1)),
       aes(x=Gender, y=n, fill=Gender)) +
  geom_bar(stat="identity") + theme_minimal() + scale_fill_brewer(palette=1, type="qual")

# sample hand
survey_data %>%
  filter(UserID!=12) %>%
  select(UserID, Hand) %>%
  count(Hand) %>%
  mutate(percent=round(100*(n/sum(n)),1))

# compare total times for subjects 12 and 30 to sample
  ggplot(data_set.clean %>% filter(id!=12, id!=30, id!=31, id!=32),
         aes(Interface, TimeFromSpawnToGrabLoss, fill="Sample")) +
  theme_minimal() +
  scale_fill_brewer(palette=1, type="qual", direction=-1)+#1, type="qual")+
  # scale_fill_manual(values=brewer.pal(n = 8, name = "Set2"),
  #   labels=c("Subject 12", "Subject 13", "B_Leap", "HHI", "Oculus"))+
  theme(legend.position = "top", legend.title=element_blank()) +
  geom_boxplot(width=0.4, alpha=0.7) +
  geom_boxplot(data=data_set.clean %>% filter(id==12 | id==30), aes(Interface, TimeFromSpawnToGrabLoss, fill=id), width=0.4)+
  labs(title="Total time by Interface for sample (n=28), S12 and S30") +
  coord_cartesian(ylim=c(0, 15))
  
  # compare total times for subjects 12 and 30 to sample
  ggplot(data_set.clean %>% filter(id!=12, id!=30, id!=31, id!=32),
         aes(Interface, TimeFromSpawnToGrab, fill="Sample")) +
  theme_minimal() +
  scale_fill_brewer(palette=1, type="qual", direction=-1)+#1, type="qual")+
  # scale_fill_manual(values=brewer.pal(n = 8, name = "Set2"),
  #   labels=c("Subject 12", "Subject 13", "B_Leap", "HHI", "Oculus"))+
  theme(legend.position = "top", legend.title=element_blank()) +
  geom_boxplot(width=0.4, alpha=0.7) +
  geom_boxplot(data=data_set.clean %>% filter(id==12 | id==30), aes(Interface, TimeFromSpawnToGrab, fill=id), width=0.4)+
  labs(title="Grab time by Interface for sample (n=28), S12 and S30") +
  coord_cartesian(ylim=c(0, 15))
  
  # compare total times for subjects 31 and 32 to sample
  ggplot(data_set.clean %>% filter(id!=12, id!=30, id!=31, id!=32),
         aes(Interface, TimeFromSpawnToGrabLoss, fill="Sample")) +
  theme_minimal() +
  scale_fill_brewer(palette=1, type="qual", direction=-1)+#1, type="qual")+
  # scale_fill_manual(values=brewer.pal(n = 8, name = "Set2"),
  #   labels=c("Subject 12", "Subject 13", "B_Leap", "HHI", "Oculus"))+
  theme(legend.position = "top", legend.title=element_blank()) +
  geom_boxplot(width=0.4, alpha=0.7) +
  geom_boxplot(data=data_set.clean %>% filter(id==31 | id==32), aes(Interface, TimeFromSpawnToGrabLoss, fill=id), width=0.4)+
  labs(title="Total time by Interface for sample (n=28), S31 and S32") +
  coord_cartesian(ylim=c(0, 15))
  

```

We would be losing two females from an already small group.

Looking at release times of all involved, those of subjects 12 and 30 are clearly far above the normal range compared to those of 31 and 32. However, this may not be enough justification to remove them: All we know is that these are users who participated in the study. They may represent a part of the true population variance.

**For now, we will not remove any subjects.**


### Clean Unity data

All cleaning will occur in this section.

NOTE: the variable below, *remove_subjects*, takes those subjects out of the data set. The variable *include* is used to filter subjects that will be included in the analysis. For now, all subjects are kept in the *include* variable.

#### Summary of cut-offs

Below includes all cut-offs (including initial cleaning):

Cut and add to accidental drop count:
* Distance >=0.2
* Distance >= 0.1 & <= 0.2 & TimeFromGrabToGrabLoss < 0.5
* LandOnTable==FALSE

```{r clean_unity_data}

remove_subjects <- 99#remove_these_subjects #c(12, 30) # insert subject numbers seperated by commas here
include <- c(1:sample_size)
include <- include[-remove_subjects] # this line removes subjects specified above

# remove accidental drops and add to accidental drop count
# data_set will contain all original drop counts; unity_data_clean will contain updated drops
temp_plot_data <- data_set

accidental_drops_total <- length((data_set %>% filter(Drop==1))[[1]])
accidental_drops_total

accidental_drops_auto_detect <- 0 # to count accidental drops detected by the metric-based method

# tag above criteria as accidental drops
for (x in 1:length(temp_plot_data$id)){
  #if (temp_plot_data$Drop[x]==0){
    if (temp_plot_data$LandOnTable[x]==FALSE){
      temp_plot_data$Drop[x]<-1
      accidental_drops_auto_detect <- accidental_drops_auto_detect+1
      }
    if (temp_plot_data$Distance[x] >= 0.2){
      temp_plot_data$Drop[x]<-1
      accidental_drops_auto_detect <- accidental_drops_auto_detect+1}
    if (temp_plot_data$Distance[x] >= 0.1 & temp_plot_data$Distance[x]<0.2 & temp_plot_data$TimeFromGrabToGrabLoss[x] <= 0.5){
      temp_plot_data$Drop[x]<-1
      accidental_drops_auto_detect <- accidental_drops_auto_detect+1}
  #}
}

# report how many were counted (including original manual detected drops)
accidental_drops_auto_detect 

accidental_drops_total <- length((temp_plot_data %>% filter(Drop==1))[[1]])
accidental_drops_total

# unity_data_drops will serve as the data set from which drop counts will be derived.
unity_data_drops <- temp_plot_data

# now, create clean data set (unity_data_clean)
# remove accidental drops
unity_data_clean <- unity_data_drops %>%
  filter(Drop==0,
         #TimeFromSpawnToGrab > 0.1,
         id %in% include)

# remove subjects, if any
survey_data <- survey_data %>%
  filter(UserID %in% include)

# recalculate sample size, if necessary
sample_size <- length(survey_data$UserID)

# total number of accidental drops
accidental_drops_total <- length((unity_data_drops %>% filter(Drop==1))[[1]])

# count number of manually detected accidental drops
accidental_drops_manual <- length((data_set %>% filter(Drop==1))[[1]])
accidental_drops_manual.percent <- 100*(accidental_drops_manual/length(data_set[[1]]))

# auto detect drops percent
accidental_drops_auto_detect.percent <- 100*(accidental_drops_auto_detect/length(data_set[[1]]))

# manual, not auto-detected
accidental_drops_manual_only <- accidental_drops_total - accidental_drops_auto_detect

# auto, not manual-detected
accidental_drops_auto_only <- accidental_drops_total - accidental_drops_manual

```

#### Visualize cleaning results

```{r cleaning_results, results='hold'}
# box plot, distance by subject
distance_subjects_clean_box<-  ggplot(unity_data_clean, aes(id, Distance, color=Interface)) +
  theme_minimal() +
  theme(legend.position = "none") +
  geom_boxplot(#outlier.colour="black",
           outlier.size=1, notch=FALSE) +
  scale_color_brewer(palette="Dark2") +
    labs(title="Distances by subject and Interface") +
    coord_cartesian(ylim=c(0, 0.4))

# grab times box plot of subjects
grabtime_subjects_clean_box<-  ggplot(unity_data_clean, aes(id, TimeFromSpawnToGrab, color=Interface)) +
  theme_minimal() +
  theme(legend.position = "none") +
  geom_boxplot(outlier.size=1, notch=FALSE) +
  # geom_point() +
#  geom_violin(scale="area") +
  scale_color_brewer(palette="Dark2") +
    labs(title="Grab times by subject and Interface") +
    coord_cartesian(ylim=c(0, 10))

# release times - by subject - box plot
releasetime_subjects_clean_box<- ggplot(unity_data_clean, aes(id, TimeFromGrabToGrabLoss, color=Interface)) +
theme_minimal() +
theme(legend.position = "bottom") +
geom_boxplot(outlier.size=1, notch=FALSE) +
scale_color_brewer(palette="Dark2") +
  labs(title="Release times by subject and Interface") #+coord_cartesian(ylim=c(0, 0.1))

# total times - by subject - box plot
totaltime_subjects_clean_box<- ggplot(unity_data_clean, aes(id, TimeFromSpawnToGrabLoss, color=Interface)) +
theme_minimal() +
theme(legend.position = "bottom") +
geom_boxplot(outlier.size=1, notch=FALSE) +
scale_color_brewer(palette="Dark2") +
  labs(title="Total times by subject and Interface") #+coord_cartesian(ylim=c(0, 0.1))


# density plot: distance
distance_clean_density<- ggplot(unity_data_clean, aes(Distance))+
  #geom_histogram(binwidth = 0.1)+
  geom_density(fill="Grey")+labs(title=paste0("Distance (cleaned), mean=",round(mean(unity_data_clean$Distance),2)))+
  geom_vline(aes(xintercept = mean(Distance)), color="Blue")+theme(legend.position = "none")+coord_cartesian(xlim=c(0,0.4))

# density plot: spawn to grab
grabtime_clean_density<- ggplot(unity_data_clean, aes(TimeFromSpawnToGrab))+
  #geom_histogram(binwidth = 0.1)+
  geom_density(fill="Grey")+labs(paste0("Grab time (cleaned), mean=",round(mean(unity_data_clean$TimeFromSpawnToGrab),2)))+geom_vline(aes(xintercept = mean(TimeFromSpawnToGrab)), color="Blue")+theme(legend.position = "none")#+coord_cartesian(xlim=c(0,10))

# density plot: grab to release time
releasetime_clean_density<- ggplot(unity_data_clean, aes(TimeFromGrabToGrabLoss))+
  #geom_histogram(binwidth = 0.1)+
  geom_density(fill="Grey")+labs(paste0("Release time (cleaned), mean=",round(mean(unity_data_clean$TimeFromGrabToGrabLoss),2)))+
  geom_vline(aes(xintercept = mean(TimeFromGrabToGrabLoss)), color="Blue")+theme(legend.position = "none")#+coord_cartesian(xlim=c(0,10))

# density plot: total time
totaltime_clean_density<- ggplot(unity_data_clean, aes(TimeFromSpawnToGrabLoss))+
  #geom_histogram(binwidth = 0.1)+
  geom_density(fill="Grey")+labs(paste0("Total time (cleaned), mean=",round(mean(unity_data_clean$TimeFromSpawnToGrabLoss),2)))+
  geom_vline(aes(xintercept = mean(TimeFromSpawnToGrabLoss)), color="Blue")#+coord_cartesian(xlim=c(0,10))

# box plots
distance_clean_box<- ggplot(unity_data_clean, aes(Interface, Distance, color=Interface))+geom_boxplot()+scale_color_brewer(palette="Set2")+ggtitle(label="Distance, accidental drops removed, no additional clean")+ coord_cartesian(ylim=c(0,0.4))+theme(legend.position = "none")#+coord_flip(ylim=c(0,0.35))
  #geom_text(data=data_set.clean %>% filter(Distance > 0.5), aes(Interface, Distance, label=paste0(Distance), position="stack"))

grabtime_clean_box<- ggplot(unity_data_clean, aes(Interface, TimeFromSpawnToGrab, color=Interface))+
  geom_boxplot()+scale_color_brewer(palette="Set2")+ggtitle(label="Time to grab, accidental drops removed, no additional clean")+theme(legend.position = "none")#+coord_cartesian(ylim=c(0,0.4))

releasetime_clean_box<- ggplot(unity_data_clean, aes(Interface, TimeFromGrabToGrabLoss, color=Interface))+
  geom_boxplot()+scale_color_brewer(palette="Set2")+ggtitle(label="Time from grab to release, accidental drops removed, no additional clean")+theme(legend.position = "none")#+coord_cartesian(ylim=c(0,0.4))

totaltime_clean_box<- ggplot(unity_data_clean, aes(Interface, TimeFromSpawnToGrabLoss, color=Interface))+
  geom_boxplot()+scale_color_brewer(palette="Set2")+ggtitle(label="Total time, accidental drops removed, no additional clean")#+coord_cartesian(ylim=c(0,0.4))

# distance
plot_grid(distance_subjects_box, distance_box, distance_density, distance_subjects_clean_box, distance_clean_box, distance_clean_density, ncol = 3, nrow = 2)
# grab time
plot_grid(grabtime_subjects_box, grabtime_box, grabtime_density, grabtime_subjects_clean_box, grabtime_clean_box, grabtime_clean_density, ncol = 3, nrow = 2)
# release time
plot_grid(releasetime_subjects_box, releasetime_box, releasetime_density, releasetime_subjects_clean_box, releasetime_clean_box, releasetime_clean_density, ncol = 3, nrow = 2)
# total time
plot_grid(totaltime_box, totaltime_density, totaltime_clean_box, totaltime_clean_density)


```
Visual inspection of the density plots suggests that the density (and related measures such as the median) converge between the 3 Interfaces. The grand mean (grey line) gets noticably lower after the clean.

## Data sets for further analysis

These comipilations will contain the *subject means*, not the individual trials.

### Cube size data

Long data format divided into cube size.
```{r cube_size}
#cube size
# calculate means and sd's for cube size by Interface & id
# so it's now 6 means for each subject -- s3 dist leap small... etc...
# add cube size to data set

# means for cube size by Interface
  subject_data_cube_size <- unity_data_clean %>% #subject_data_cube_size %>%
#    left_join(unity_data_clean %>%
    group_by(id, Interface, Cube_Size) %>%
    summarise(Distance=mean(Distance),
              grabtime=mean(TimeFromSpawnToGrab),
              releasetime=mean(TimeFromGrabToGrabLoss),
              totaltime=mean(TimeFromSpawnToGrabLoss))#,by=c("id", "Interface", "Cube_Size"))

  
  # add accidental drop counts at cube level to data set
  subject_data_cube_size <- subject_data_cube_size %>%
    left_join(unity_data_drops %>%
                group_by(id,Interface,Cube_Size) %>%
                summarise(Drop_Count=sum(Drop)))
  
  # accidental drop rate
    subject_data_cube_size <- subject_data_cube_size %>%
    mutate(Drop_Rate=(Drop_Count/10)*100)

# set factor levels
subject_data_cube_size <- subject_data_cube_size %>% ungroup() %>%
  mutate(Cube_Size=factor(Cube_Size, levels=c("Small","Medium","Large")),
                          Interface=factor(Interface, levels=plot_order))
```

### Wide format

Wide format; one line per subject.
```{r subject_data_compilation_wide}

# compile wide data set and calculate means where necessary
# starting w/ wide because some metrics (i.e. subjective questions and demographics) are
# already in wide format

# start by taking from survey_data (already contains demos and subj. q's)
subject_data_all_wide <- survey_data %>%
  filter(UserID %in% include) %>%
  select(id=UserID, Gender:Disabilities, Hand, InterfaceOrder, OculusExpComment:PrefCondition,
         -contains("SUS"), -contains("comment"))

# leap groups (for Interface order analysis)
leap_first <- which(subject_data_all_wide$InterfaceOrder=="LOH" | subject_data_all_wide$InterfaceOrder=="LHO" | subject_data_all_wide$InterfaceOrder=="OLH")
HHI_Leap_first <- which(subject_data_all_wide$InterfaceOrder=="OHL" | subject_data_all_wide$InterfaceOrder=="HOL" | subject_data_all_wide$InterfaceOrder=="HLO")
# add group designation to subject_data_all_wide
subject_data_all_wide[leap_first,"Leap_Group"] <- "B_Leap_first"
subject_data_all_wide[HHI_Leap_first,"Leap_Group"] <- "HHI_Leap_first"
subject_data_all_wide$Leap_Group <- factor(subject_data_all_wide$Leap_Group)

# oculus groups (for Interface order analysis)
Oculus_first <- which(subject_data_all_wide$InterfaceOrder=="OLH" | subject_data_all_wide$InterfaceOrder=="OHL")
Oculus_last <- which(subject_data_all_wide$InterfaceOrder=="LHO" | subject_data_all_wide$InterfaceOrder=="HLO")
subject_data_all_wide[Oculus_first,"Oculus_Group"] <- "Oculus_first"
subject_data_all_wide[Oculus_last,"Oculus_Group"] <- "Oculus_last"
subject_data_all_wide$Oculus_Group <- factor(subject_data_all_wide$Oculus_Group)

# add error totals (errors previously calculated -- error_totals)
subject_data_all_wide <- subject_data_all_wide %>% 
  left_join(data_set %>%
              filter(id %in% include, Interface=="B_Leap") %>% group_by(id) %>%
              summarise(errors_Leap=sum(Drop)), by="id") %>%
  left_join(data_set %>% filter(id %in% include, Interface=="HHI_Leap") %>% group_by(id)%>%
             summarise(errors_Leap_HHI=sum(Drop)), by="id") %>%
  left_join(data_set %>% filter(id %in% include, Interface=="Oculus") %>% group_by(id)%>%
             summarise(errors_Oculus=sum(Drop)), by="id")

# add sus scores
subject_data_all_wide <- subject_data_all_wide %>%
  left_join(SUS_scores %>%
              rename(id=UserID, SUS_Leap=B_Leap, SUS_Leap_HHI=HHI_Leap, SUS_Oculus=Oculus), by="id")

# distance
  subject_data_all_wide <- subject_data_all_wide %>% 
    left_join(unity_data_clean %>%
    group_by(id, Interface) %>%
    summarise(Mean=mean(Distance)) %>%
    ungroup(id) %>%
                spread(Interface, Mean) %>%
              rename(distance_Leap_mean=B_Leap, distance_Leap_HHI_mean=HHI_Leap,
                     distance_Oculus_mean=Oculus), by="id")

# grab time
  subject_data_all_wide <- subject_data_all_wide %>%
    left_join(unity_data_clean %>%
    group_by(id, Interface) %>%
    summarise(Mean=mean(TimeFromSpawnToGrab)) %>%
    ungroup(id) %>%
                spread(Interface, Mean) %>%
                rename(grabtime_Leap_mean=B_Leap, grabtime_Leap_HHI_mean=HHI_Leap,
                     grabtime_Oculus_mean=Oculus), by="id")

# release time
  # add to data set
  subject_data_all_wide <- subject_data_all_wide %>%
    left_join(unity_data_clean %>%
    group_by(id, Interface) %>%
    summarise(Mean=mean(TimeFromGrabToGrabLoss)) %>%
    ungroup(id) %>%
                spread(Interface, Mean) %>%
                rename(releasetime_Leap_mean=B_Leap, releasetime_Leap_HHI_mean=HHI_Leap,
                     releasetime_Oculus_mean=Oculus), by="id")

# total time
  # means
  subject_data_all_wide <- subject_data_all_wide %>%
    left_join(unity_data_clean %>%
    group_by(id, Interface) %>%
    summarise(Mean=mean(TimeFromSpawnToGrabLoss)) %>%
    ungroup(id) %>%
                spread(Interface, Mean) %>%
                rename(totaltime_Leap_mean=B_Leap, totaltime_Leap_HHI_mean=HHI_Leap,
                     totaltime_Oculus_mean=Oculus), by="id")
  
  # practice time
    # calculate practice time (later correlate w/ performance)
    # = total_time recorded - sum of time from spawn to grab
  subject_data_all_wide <- subject_data_all_wide %>%
    left_join(data_set %>%
                select(id, Interface, TimeForTrainingPhase) %>%
                group_by(id, Interface) %>%
                distinct(.) %>%
                spread(Interface, TimeForTrainingPhase) %>%
                rename(TrainingTime_Leap=B_Leap, TrainingTime_HHI=HHI_Leap,
                       TrainingTime_Oculus=Oculus),
              by="id")
  
```

### Long format

This one is good for ggplots and ANOVA.
```{r subject_data_compilation_long}
# start a long version for statistical testing-ready data
subject_data_all_long <- subject_data_all_wide %>%
  select(id, InterfaceOrder, Leap_Group, Oculus_Group)

# accidental drops
subject_data_all_long <- subject_data_all_long %>%
  left_join(unity_data_drops %>%
              filter(id %in% include) %>%
              group_by(id,Interface) %>%
              summarise(Drop_Count=sum(Drop)))

# percentage
subject_data_all_long <- subject_data_all_long %>%
  mutate(Drop_Rate=(Drop_Count/30)*100)

# SUS
subject_data_all_long <- subject_data_all_long %>%
  left_join(SUS_scores %>%
              gather(key="Interface", value="SUS", "B_Leap","HHI_Leap","Oculus") %>%
              rename(id=UserID) %>%
              filter(id %in% include),
            by=c("id","Interface"))

# Distance means
subject_data_all_long <- subject_data_all_long %>%
  left_join(unity_data_clean %>%
    group_by(id, Interface) %>%
    summarise(Distance=mean(Distance)) %>%
    ungroup(id), by=c("id","Interface"))

# Grab Time means
subject_data_all_long <- subject_data_all_long %>%
  left_join(unity_data_clean %>%
    group_by(id, Interface) %>%
    summarise(grabtime=mean(TimeFromSpawnToGrab)) %>%
    ungroup(id), by=c("id","Interface"))

# Release time means
subject_data_all_long <- subject_data_all_long %>%
  left_join(unity_data_clean %>%
    group_by(id, Interface) %>%
    summarise(releasetime=mean(TimeFromGrabToGrabLoss)) %>%
    ungroup(id), by=c("id","Interface"))

# Total time means
subject_data_all_long <- subject_data_all_long %>%
  left_join(unity_data_clean %>%
    group_by(id, Interface) %>%
    summarise(totaltime=mean(TimeFromSpawnToGrabLoss)) %>%
    ungroup(id), by=c("id","Interface"))

# training time
subject_data_all_long <- subject_data_all_long %>%
  left_join(unity_data_clean %>%
              select(id, Interface, practice_time=TimeForTrainingPhase) %>%
              group_by(id, Interface) %>%
              distinct(.), by=c("id","Interface")) 

# find SD from grand mean to detect outliers, per Interface
find_z <- function(group_scores, score) {
  group_sd <- sd(group_scores)
  group_mean <- mean(group_scores)
  z <- 
  z
}

# Subjective questions
for (x in 1:8){
  # make a temp data set of question x totals
  temp_question_totals <- subject_data_all_wide %>%
    filter(id %in% include)%>%
    select(id, contains(as.character(x))) %>%
    rename(B_Leap=contains("Standard"),HHI_Leap=contains("HHI"),
           Oculus=contains("Oculus")) %>%
    gather(key=Interface,value=Score,c(2:4))
  # rename vars
  names(temp_question_totals)[3] <- paste0("Q_",x,"_Score")
  # names(temp_question_totals)[4] <- paste0("Q_",x,"_Rank")
  # add to big data set
  subject_data_all_long <- subject_data_all_long %>%
  left_join(temp_question_totals, by=c("id","Interface"))
}

# agency
subject_data_all_long <- subject_data_all_long %>%
  left_join(subject_data_all_wide %>%
              select(id, contains("Agency")) %>%
              rename(B_Leap=contains("Stan"), HHI_Leap=contains("HHI"), Oculus=contains("Oculus")) %>%
              gather(key="Interface", value="agency", c(2:4)) %>%
              group_by(id),# %>% mutate(agency_Rank=dense_rank(desc(agency))),
            by=c("id","Interface"))

# overall satisfaction
subject_data_all_long <- subject_data_all_long %>%
  left_join(subject_data_all_wide %>%
              select(id, contains("KunKey")) %>%
              rename(B_Leap=contains("Stan"), HHI_Leap=contains("HHI"), Oculus=contains("Oculus")) %>%
              gather(key="Interface", value="satisfaction", c(2:4))%>%
              group_by(id),#%>% mutate(satisfaction_Rank=dense_rank(desc(satisfaction))),
            by=c("id","Interface"))

# overall preferred condition
  subject_data_all_long <- subject_data_all_long %>%
    left_join(subject_data_all_wide %>%
                select(id, contains("PrefCondition")),
              by="id") %>%
    mutate(PrefCondition=factor(PrefCondition)) %>%
    mutate(PrefCondition=recode_factor(PrefCondition,
     "ohne Controller, Variante 1 (Standard Leap Motion)"="B_Leap",
              "mit Controller"="Oculus",
              "ohne Controller, Variante 2 (Leap Motion mit HHI-Anpassungen)"="HHI_Leap"))

# demographics
subject_data_all_long <- subject_data_all_long %>%
left_join(subject_data_all_wide %>%
            select(id, Age, Height, Arm),
          by="id")
  
# experience
  # w/ video game controllers
  subject_data_all_long <- subject_data_all_long %>%
    left_join(subject_data_all_wide %>%
                select(id, contains("SkillController")),
              by="id")

  # w/ VR
  subject_data_all_long <- subject_data_all_long %>%
  left_join(subject_data_all_wide %>%
              select(id, contains("SkillVR")),
            by="id")

  # w/ any game
  subject_data_all_long <- subject_data_all_long %>%
  left_join(subject_data_all_wide %>%
              select(id, contains("SkillGames")),
            by="id")

  
# reorder factors  
  subject_data_all_long <- subject_data_all_long %>%
    mutate(Interface=factor(Interface, levels=plot_order))


```

### Outlier classification: Z-scores

Note: SD's are calculated *per interface (Interface)*, not overall.
```{r z_score_clean}

z_flag <- 3

sink("outlier_report.csv")

cat("Flagging number of data points over this many z-scores: ", z_flag, "\n\n")

z_accuracy <- subject_data_all_long %>% select(id, Interface, Distance) %>% group_by(Interface) %>%
  mutate(z=(Distance-mean(Distance))/sd(Distance), flag=z > z_flag | z < -1*z_flag, flag_level=z_flag)
cat("Accuracy")
table(z_accuracy$flag)

z_grabtime <- subject_data_all_long %>% select(id, Interface, grabtime) %>% group_by(Interface) %>%
  mutate(z=(grabtime-mean(grabtime))/sd(grabtime), flag=z > z_flag | z < -1*z_flag, flag_level=z_flag)
cat("Grab time")
table(z_grabtime$flag)

z_releasetime <- subject_data_all_long %>% select(id, Interface, releasetime) %>% group_by(Interface) %>%
  mutate(z=(releasetime-mean(releasetime))/sd(releasetime), flag=z > z_flag | z < -1*z_flag, flag_level=z_flag) 
cat("Release time")
table(z_releasetime$flag)

z_totaltime <- subject_data_all_long %>% select(id, Interface, totaltime) %>% group_by(Interface) %>%
  mutate(z=(totaltime-mean(totaltime))/sd(totaltime), flag=z > z_flag | z < -1*z_flag, flag_level=z_flag)
cat("Total time")
table(z_totaltime$flag)

z_drops <- subject_data_all_long %>% select(id, Interface, Drop_Count) %>% group_by(Interface) %>%
  mutate(z=(Drop_Count-mean(Drop_Count))/sd(Drop_Count), flag=z > z_flag | z < -1*z_flag, flag_level=z_flag)
cat("Accidental drops")
table(z_drops$flag)

z_practice_time <- subject_data_all_long %>% select(id, Interface, practice_time) %>% group_by(Interface) %>%
  mutate(z=(practice_time-mean(practice_time))/sd(practice_time), flag=z > z_flag | z < -1*z_flag, flag_level=z_flag)
cat("Practice time")
table(z_practice_time$flag)

sink()

ggplot(subject_data_all_long, aes(id, totaltime, color=id%in%c(12,30)))+geom_point()+theme(legend.position = "none")+geom_label(data=subject_data_all_long%>%filter(id%in%c(12,30)), aes(label=Interface), nudge_x = 2)+labs(title="Total time (by subject)", subtite="Subjects 12 and 30 highlighted")

```

# Analysis

## Demographics

```{r demographics_plots}
# gender
gender <- table(subject_data_all_wide$Gender)

#handedness
handedness <- table(subject_data_all_wide$Hand)

demographics <- list(descriptives = subject_data_all_wide %>% get_summary_stats(Age, Height, Arm, SkillController, SkillVR, SkillGames) %>% select(variable, n, mean, sd, max, min, median, iqr))
cat("\nGender")
gender
cat("\nHandedness")
handedness
demographics$gender <- gender
demographics$handedness <- handedness
demographics

cat("Demographics\n\n")
print(as.data.frame(demographics))
cat("\nGender")
print(gender)
cat("\nHandedness\n")
print(table(subject_data_all_wide$Hand))
cat("\nInterface Order")
print(table(subject_data_all_wide$InterfaceOrder))

```

### Demographics Plots

```{r dem_plots}
# experience
  # controller
  # make temp plot dataset
  temp_plot_data <- data.frame(Response=c(1:5)) %>%
    mutate(Response=factor(Response)) %>%
    left_join(data.frame(table(subject_data_all_wide$SkillController)) %>% rename(Response=Var1,Count=Freq), by=c("Response")) %>%
    mutate(Response=factor(Response), Count=replace_na(Count, 0))
  exp_counts<-temp_plot_data %>%
    rename(controller_count=Count)#build a data set of counts for later
  # bar chart
p<-  ggplot(temp_plot_data,
         aes(x=Response, y=Count)) + 
    geom_bar(stat="identity",
             fill=brewer.pal(n=8, name = "Set2")[1]) +
    theme_minimal() +
    theme(plot.title = element_text(size=title_size*.75), axis.title = element_text(size=axis_text_size))+
      geom_label(aes(x=median(subject_data_all_long$SkillController), label=paste0("Median = ",median(subject_data_all_long$SkillController)), y=.75*max(Count)))+
    labs(title="Experience with Video Game Controllers")+
    scale_x_discrete(labels=c("1 (none)","2 (some)","3 (frequent past use)","4 (some current use)","5 (frequent current use)"))
p
ggsave(p, file="experience_controller.jpg")

  
  # VR
    temp_plot_data <- data.frame(Response=c(1:5)) %>%
    mutate(Response=factor(Response)) %>%
    left_join(data.frame(table(subject_data_all_wide$SkillVR)) %>% rename(Response=Var1,Count=Freq), by=c("Response")) %>%
    mutate(Response=factor(Response), Count=replace_na(Count, 0))
    exp_counts <- exp_counts %>% left_join(temp_plot_data %>%
                 rename(vr_count=Count), by="Response")
  # bar chart
  p<- ggplot(temp_plot_data,
         aes(x=Response, y=Count)) + 
    geom_bar(stat="identity",
             fill=brewer.pal(n=8, name = "Set2")[1]) +
    geom_label(aes(x=median(subject_data_all_long$SkillVR), label=paste0("Median = ",median(subject_data_all_long$SkillVR)), y=.75*max(Count)))+
  #  scale_color_brewer(palette="Dark2")+
  #  scale_fill_brewer(palette="Set3") +
    theme_minimal()+xlab(NULL)+
    theme(plot.title = element_text(size=title_size*.75), axis.title = element_text(size=axis_text_size))+
    labs(title="Experience with VR")+
    scale_x_discrete(labels=c("1 (none)","2 (some)","3 (frequent past use)","4 (some current use)","5 (frequent current use)"))
  p
  ggsave(p, file="experience_vr.jpg")

  
  # all games
    temp_plot_data <- data.frame(Response=c(1:5)) %>%
    mutate(Response=factor(Response)) %>%
    left_join(data.frame(table(subject_data_all_wide$SkillGames)) %>% rename(Response=Var1,Count=Freq), by=c("Response")) %>%
    mutate(Response=factor(Response), Count=replace_na(Count, 0))
    exp_counts <- exp_counts %>% left_join(temp_plot_data %>%
             rename(allgames_count=Count), by="Response")
  # bar chart
  p<- ggplot(temp_plot_data, aes(x=Response, y=Count)) + 
    geom_bar(stat="identity",
             fill=brewer.pal(n=8, name = "Set2")[1]) +
    theme_minimal() +
    theme(plot.title = element_text(size=title_size*.75), axis.title = element_text(size=axis_text_size))+
    geom_label(aes(x=median(subject_data_all_long$SkillGames), label=paste0("Median = ",median(subject_data_all_long$SkillGames)), y=.75*max(Count)))+
    labs(title="Experience with Electronic Games")+
    scale_x_discrete(labels=c("1 (none)","2 (some)","3 (frequent past use)","4 (some current use)","5 (frequent current use)"))
  p
  ggsave(p, file="experience_allgames.jpg")

  # box plot of all responses
  boxplot(subject_data_all_wide$SkillController,
          subject_data_all_wide$SkillVR,
            subject_data_all_wide$SkillGames,
          main="Experience",
          names=c("Controller","VR","All Games"),
          xlab="Response 1-5", notch=TRUE,
          horizontal=TRUE)

# count gender for each group
gender_count_groups <- data.frame("InterfaceOrder"=NULL, "Gender"=NULL, "Count"=NULL)
for (x in levels(survey_data$InterfaceOrder)){
  for (y in levels(survey_data$Gender)){
    temp.frame <- data.frame("InterfaceOrder"=x,"Gender"=y,
                             "Count"=length(which(survey_data$InterfaceOrder==x & survey_data$Gender==y)))
    gender_count_groups <- rbind(gender_count_groups, temp.frame)
  }
}

# plot groups with gender make-up
gender.group.plot <- ggplot() +
theme_minimal() +
#theme(legend.position = "none") +
geom_bar(stat="identity", aes(y = Count, x = InterfaceOrder, fill = Gender),
         data = gender_count_groups, "width"=.6) +
scale_fill_brewer(type="qual") +
#geom_errorbar(aes(ymin=Mean-(SE*1.96), ymax=Mean+(SE*1.96), colour=InterfaceOrder), width=.2) +
labs(title=paste0("Group counts w/ gender, N = ",sample_size), y="# subjects")
#geom_text(data=gender_count_groups, aes(y = Count, x = InterfaceOrder, label = Count),size=4)
#  coord_cartesian(ylim=c(0.0035, 0.006))
gender.group.plot
#ggsave(gender.group.plot, file="gender_groups.jpg")

```

## Performance Metrics

- These are the primary results of this study
- Two IV's: Cube Size and Interface
- DV's: accuracy, 3 time measures, errors (accidental drops)
- Main effect of cube size: shows cube sizes mattered
- Interaction effect: indicates Interfaces may be better or worse at cubes of different sizes

### Interface

#### All Performance t-tests
Here I re-did the t-tests that follow this section, but all in one place. Then I apply the Holm correction to all 5 tests per each interface, where as before I was applying it to 2 tests (2 interfaces per each of the 5 measures). The previous application resulted in the Holm correction essentially not being applied to the comparisons between the HHI_Leap and the B_Leap.
```{r performance_metrics_main}

# HHI vs. Oculus

Measure=c("Accuracy (m)","Total Time (s)","Grab Time (s)","Release Time (s)","Accidental Drops (#)")

temp_df <- subject_data_all_long %>% ungroup() %>% filter(Interface=="HHI_Leap")

hhi_leap_mean_sd <- #left_join(get_summary_stats(temp_df, Distance,))
  data.frame(Measure=Measure,
      HHI_Leap_Mean=c(mean(temp_df$Distance), mean(temp_df$totaltime), mean(temp_df$grabtime), mean(temp_df$releasetime), mean(temp_df$Drop_Count)),
      HHI_Leap_SD=c(sd(temp_df$Distance), sd(temp_df$totaltime), sd(temp_df$grabtime), sd(temp_df$releasetime), sd(temp_df$Drop_Count))
             )

temp_df <- subject_data_all_long %>% ungroup() %>% filter(Interface=="Oculus")

oculus_mean_sd <-
  data.frame(Measure=Measure,
      Oculus_Mean=c(mean(temp_df$Distance), mean(temp_df$totaltime), mean(temp_df$grabtime), mean(temp_df$releasetime), mean(temp_df$Drop_Count)),
      Oculus_SD=c(sd(temp_df$Distance), sd(temp_df$totaltime), sd(temp_df$grabtime), sd(temp_df$releasetime), sd(temp_df$Drop_Count))
             )

hhi_leap_oculus_mean_sd <- left_join(hhi_leap_mean_sd, oculus_mean_sd)

# Construct a data frame with all t-tests HHI_Leap vs. Oculus.
# Then apply the Holm adjustment at the end with the adjust_pvalue() function from rstatix
# (Holm is the default type of correction)
all_performance_ttests_oculus <- bind_rows(
  subject_data_all_long %>% t_test(Distance ~ Interface, comparisons = list(c("HHI_Leap","Oculus")), paired = TRUE),
  subject_data_all_long %>% t_test(totaltime ~ Interface, comparisons = list(c("HHI_Leap","Oculus")), paired = TRUE),
  subject_data_all_long %>% t_test(grabtime ~ Interface, comparisons = list(c("HHI_Leap","Oculus")), paired = TRUE),
  subject_data_all_long %>% t_test(releasetime ~ Interface, comparisons = list(c("HHI_Leap","Oculus")), paired = TRUE),
  subject_data_all_long %>% t_test(Drop_Count ~ Interface, comparisons = list(c("HHI_Leap","Oculus")), paired = TRUE)
) %>% adjust_pvalue(p.col="p", output.col="p.adj") %>% cbind(Measure) %>% select(Measure, t=statistic, df, `p(Holm)`=p.adj)

performance_ttests_hhi_leap_oculus <- left_join(hhi_leap_oculus_mean_sd, all_performance_ttests_oculus)

# then set p values to be "p < .001" (if true) and remove the *
performance_ttests_hhi_leap_oculus[which(performance_ttests_hhi_leap_oculus$p<.0001),"p(Holm)"] <- "p < .0001"


rm(temp_df, oculus_mean_sd, hhi_leap_oculus_mean_sd, all_performance_ttests_oculus)

stargazer(performance_ttests_hhi_leap_oculus, summary=FALSE, rownames = FALSE, title="Paired Samples t-tests: HHI_Leap and Oculus")

# HHI vs. B_Leap

temp_df <- subject_data_all_long %>% ungroup() %>% filter(Interface=="B_Leap")

b_leap_mean_sd <-
  data.frame(Measure=Measure,
      B_Leap_Mean=c(mean(temp_df$Distance), mean(temp_df$totaltime), mean(temp_df$grabtime), mean(temp_df$releasetime), mean(temp_df$Drop_Count)),
      B_Leap_SD=c(sd(temp_df$Distance), sd(temp_df$totaltime), sd(temp_df$grabtime), sd(temp_df$releasetime), sd(temp_df$Drop_Count))
             )

hhi_leap_b_leap_mean_sd <- left_join(hhi_leap_mean_sd, b_leap_mean_sd)

all_performance_ttests_b_leap <- bind_rows(
  subject_data_all_long %>% t_test(Distance ~ Interface, comparisons = list(c("HHI_Leap","B_Leap")), paired = TRUE),
  subject_data_all_long %>% t_test(totaltime ~ Interface, comparisons = list(c("HHI_Leap","B_Leap")), paired = TRUE),
  subject_data_all_long %>% t_test(grabtime ~ Interface, comparisons = list(c("HHI_Leap","B_Leap")), paired = TRUE),
  subject_data_all_long %>% t_test(releasetime ~ Interface, comparisons = list(c("HHI_Leap","B_Leap")), paired = TRUE),
  subject_data_all_long %>% t_test(Drop_Count ~ Interface, comparisons = list(c("HHI_Leap","B_Leap")), paired = TRUE)
) %>% adjust_pvalue(p.col="p", output.col="p.adj") %>% cbind(Measure) %>% select(Measure, t=statistic, df, `p(Holm)`=p.adj) %>% mutate(t=-1*t)

performance_ttests_hhi_leap_b_leap <- left_join(hhi_leap_b_leap_mean_sd, all_performance_ttests_b_leap)

rm(temp_df, hhi_leap_b_leap_mean_sd, b_leap_mean_sd, hhi_leap_mean_sd, all_performance_ttests_b_leap)

stargazer(performance_ttests_hhi_leap_b_leap, summary=FALSE, rownames = FALSE)

```

#### Accuracy

```{r Interface_plots}

# Distance/accuracy
  temp_plot_data <- subject_data_all_long %>%
    group_by(Interface) %>% get_summary_stats(Distance)
  
# run t test
stat.test <- subject_data_all_long %>%
  ungroup(.) %>%
  pairwise_t_test(Distance ~ Interface, paired=TRUE, comparisons=list(c("B_Leap","HHI_Leap"),c("HHI_Leap","Oculus"))) %>% add_significance(p.col="p.adj", output.col="p.adj.signif", symbols=mysymbols) %>%
  left_join(subject_data_all_long %>% ungroup(.) %>% cohens_d(Distance ~ Interface, paired=TRUE) %>% select(group1, group2, effsize, magnitude), by=c("group1", "group2")) %>%
  mutate(Interface=group1)
stat.test

stat.test.anova <-
  anova_summary(effect.size="pes",aov(Distance ~ Interface + Error(id/Interface), data=subject_data_all_long))
stat.test.anova
  
  distance_Interface_raincloud <- ggplot(subject_data_all_long, aes(x=Interface,y=Distance, fill = Interface, colour = Interface))+
    geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=myalpha, adjust = mysmoothing)+
    geom_point(position = position_jitter(width = .08), size = .25)+
    geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK")+
    stat_pvalue_manual(data=stat.test %>% filter(p.adj < 0.05), xmin="group1", xmax="group2", label = "p.adj.signif", step.increase=.1, y.position=.03, position=position_nudge(.25))+
    geom_label(data=temp_plot_data, aes(Interface, mean, label=round(mean,3)), alpha=.7, position=position_nudge(.5), color="white", label.size=.2)+
    geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 1)+
    ylab('Distance (meters) from target')+
    xlab("Interface")+
    #theme(title = element_text(size=30))+
    guides(fill = FALSE, colour = FALSE) + #coord_flip()+
    scale_color_manual(values=mycolors)+#scale_colour_brewer(palette = "Set2")+
    scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2", direction=1)+
    labs(title="Accuracy")+
    theme(plot.title = element_text(size=title_size), axis.title = element_text(size=axis_text_size), axis.text = element_text(size=axis_text_size*.75))
  distance_Interface_raincloud
  ggsave("accuracy_plot_main.jpg", width=10, height=7)

# ALMOST fails Levene's test for homogeneity of variance
leveneTest(Distance ~ Interface, data=subject_data_all_long %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap"))

# transform for data output
stat.test <- stat.test %>% select(-.y., -n1, -n2, -Interface)%>% mutate(p=round(p, 4), p.adj=round(p.adj, 4), effsize=round(effsize, 4))

#stat.test.anova <- stat.test.anova %>% mutate(p=round(p, 4))

# save for output later
anova.Interface.distance <- stat.test.anova


ttest.Interface.distance <- stat.test
descriptives.Interface.distance <- subject_data_all_long %>% group_by(Interface) %>% get_summary_stats(Distance) %>% select(Interface, variable, mean, sd, min, max, iqr)
descriptives.Interface.distance

oculus_diffs <- data.frame(Difference=round(temp_plot_data$mean[1]/temp_plot_data$mean[3], 3),
                           Type = "Ratio", row.names="Accuracy", stringsAsFactors = FALSE)
oculus_diffs["Accuracy","cohen's d"] <- round(stat.test[3,"effsize"], 3)

# equivalence: HHI Leap and B_Leap

# find correlation of dependent variable between HHI Leap and B_Leap
r_val <- cor.test(
  x = subject_data_all_long[which(subject_data_all_long$Interface=="HHI_Leap"),"Distance"],
  y = subject_data_all_long[which(subject_data_all_long$Interface=="B_Leap"),"Distance"],
  method = "pearson",
  alternative = "two.sided"
  )
r_val <- r_val$estimate[[1]]

TOSTaccuracy <- TOSTpaired(n=32,
  m1 = descriptives.Interface.distance[which(descriptives.Interface.distance$Interface=="HHI_Leap"),"mean"][[1]],
  m2 = descriptives.Interface.distance[which(descriptives.Interface.distance$Interface=="B_Leap"),"mean"][[1]],
  sd1 = descriptives.Interface.distance[which(descriptives.Interface.distance$Interface=="HHI_Leap"),"sd"][[1]],
  sd2 = descriptives.Interface.distance[which(descriptives.Interface.distance$Interface=="B_Leap"),"sd"][[1]],
  r12 = r_val,
  low_eqbound_dz = -.3,
  high_eqbound_dz = .3,
  alpha = .05,
  plot= TRUE,
  verbose = TRUE
)

TOSTaccuracy
```

#### Grab time

```{r grabtime_Interface_analysis}
# grab time
  # dot plot w/ error bars
  temp_plot_data <- subject_data_all_long %>%
      group_by(Interface) %>% get_summary_stats(grabtime)
  
stat.test <- subject_data_all_long %>%
  ungroup(.) %>%
  pairwise_t_test(grabtime ~ Interface, paired=TRUE, comparisons=list(c("B_Leap","HHI_Leap"),c("HHI_Leap","Oculus"))) %>% add_significance(p.col="p.adj", output.col="p.adj.signif", symbols=mysymbols) %>%
  left_join(subject_data_all_long %>% ungroup(.) %>% cohens_d(grabtime ~ Interface, paired=TRUE) %>% select(group1, group2, effsize, magnitude), by=c("group1", "group2")) %>%
  mutate(Interface=group1)
stat.test

stat.test.anova <-
  anova_summary(effect.size="pes",aov(grabtime ~ Interface + Error(id/Interface), data=subject_data_all_long))
stat.test.anova

  #raincloud grabtime
  grabtime_Interface_raincloud <- ggplot(subject_data_all_long,aes(x=Interface, y=grabtime, fill = Interface, colour = Interface))+
    geom_flat_violin(position = position_nudge(x = .25, y = 0),  alpha=myalpha, adjust = mysmoothing)+
    geom_point(position = position_jitter(width = .15), size = 3)+
    geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK", size=3)+
    geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 1.3)+
geom_label(data=temp_plot_data, aes(Interface, mean, label=round(mean,2)), alpha=1, position=position_nudge(.5), color="white", size=8)+
    ylab('Time (seconds)')+xlab('')+theme_cowplot()+guides(fill = FALSE, colour = FALSE)+#coord_flip()+
    scale_color_manual(values=mycolors)+#scale_colour_brewer(palette = "Set2")+
    scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2", direction=1)+
    labs(title="Grab time")+
    stat_pvalue_manual(data=stat.test %>% filter(p.adj < 0.05), xmin="group1", xmax="group2", label = "p.adj.signif", step.increase=.1, y.position=2*max(temp_plot_data$mean), position=position_nudge(.25), size=10, bracket.size = .5)+
    theme(plot.title = element_text(size=title_size), axis.title = element_text(size=axis_text_size), axis.text = element_text(size=axis_text_size*.75))
grabtime_Interface_raincloud
  ggsave("grabtime_plot_main.jpg", width=10, height=7)


# transform for data output
stat.test <- stat.test %>% select(-.y., -n1, -n2, -Interface)%>% mutate(p=round(p, 4), p.adj=round(p.adj, 4), effsize=round(effsize, 4))

#stat.test.anova <- stat.test.anova %>% mutate(p=round(p, 4))

# save for later
anova.Interface.grabtime <- stat.test.anova
ttest.Interface.grabtime <- stat.test
descriptives.Interface.grabtime <- subject_data_all_long %>% group_by(Interface) %>% get_summary_stats(grabtime) %>% select(Interface, variable, mean, sd, min, max, iqr)
descriptives.Interface.grabtime
oculus_diffs["Grab time","Difference"] <- round(temp_plot_data$mean[1]/temp_plot_data$mean[3], 3)
oculus_diffs["Grab time","Type"] <- "Ratio"
oculus_diffs["Grab time","cohen's d"] <- round(stat.test[3,"effsize"], 3)

r_val <- cor.test(
  x = subject_data_all_long[which(subject_data_all_long$Interface=="HHI_Leap"),"grabtime"],
  y = subject_data_all_long[which(subject_data_all_long$Interface=="B_Leap"),"grabtime"],
  method = "pearson",
  alternative = "two.sided"
  )
r_val <- r_val$estimate[[1]]

# TOSTpaired(n=32,
#   m1 = descriptives.Interface.grabtime[which(descriptives.Interface.grabtime$Interface=="HHI_Leap"),"mean"][[1]],
#   m2 = descriptives.Interface.grabtime[which(descriptives.Interface.grabtime$Interface=="B_Leap"),"mean"][[1]],
#   sd1 = descriptives.Interface.grabtime[which(descriptives.Interface.grabtime$Interface=="HHI_Leap"),"sd"][[1]],
#   sd2 = descriptives.Interface.grabtime[which(descriptives.Interface.grabtime$Interface=="B_Leap"),"sd"][[1]],
#   r12 = r_val,
#   low_eqbound_dz = -.3,
#   high_eqbound_dz = .3,
#   alpha = .05,
#   plot= TRUE,
#   verbose = TRUE
# )
```

#### Release time

```{r releasetime_Interface_analysis}
# release time
  temp_plot_data <- subject_data_all_long %>%
    group_by(Interface) %>% summarise(mean=mean(releasetime), sd=sd(releasetime), se=(sd/sqrt(sample_size)))

stat.test <- subject_data_all_long %>%
  ungroup(.) %>%
  pairwise_t_test(releasetime ~ Interface, paired=TRUE, comparisons=list(c("B_Leap","HHI_Leap"),c("HHI_Leap","Oculus"))) %>%
  add_significance(p.col="p.adj", output.col="p.adj.signif", symbols=mysymbols) %>%
  left_join(subject_data_all_long %>% ungroup(.) %>% cohens_d(releasetime ~ Interface, paired=TRUE) %>% select(group1, group2, effsize, magnitude), by=c("group1", "group2"))%>%
  mutate(Interface=group1)
stat.test

stat.test.anova <-
  anova_summary(effect.size="pes",aov(releasetime ~ Interface + Error(id/Interface), data=subject_data_all_long))
stat.test.anova

#raincloud releasetime
  releasetime_Interface_raincloud <- ggplot(subject_data_all_long,aes(x=Interface,y=releasetime, fill = Interface, colour = Interface))+
    geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=myalpha, adjust = mysmoothing)+
    geom_point(position = position_jitter(width = .15), size = 3)+
    geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK", size=3)+
    #stat_compare_means(comparisons=list(c("B_Leap", "HHI_Leap"), c("HHI_Leap", "Oculus"), c("B_Leap", "Oculus")), method="t.test", paired=TRUE, label="p.signif")+
    geom_label(data=temp_plot_data, aes(Interface, mean, label=round(mean,2)), alpha=1, position=position_nudge(.5), color="white", size=8)+
    geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 1.3)+
    ylab('Time (seconds)')+xlab('')+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
    scale_color_manual(values=mycolors)+#scale_colour_brewer(palette = "Set2")+
    scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2", direction=1)+
    labs(title="Release time")+
    stat_pvalue_manual(data=stat.test %>% filter(p.adj < 0.05), xmin="group1", xmax="group2", label = "p.adj.signif", step.increase=.1, y.position=.85*max(subject_data_all_long$releasetime), position=position_nudge(.25), size=10, bracket.size = .5)+
    theme(plot.title = element_text(size=title_size), axis.title = element_text(size=axis_text_size), axis.text = element_text(size=axis_text_size*.75))
  releasetime_Interface_raincloud
    ggsave("releasetime_plot_main.jpg", width=10, height=7)

  
# transform for data output
stat.test <- stat.test %>% select(-.y., -n1, -n2, -Interface)%>% mutate(p=round(p, 4), p.adj=round(p.adj, 4), effsize=round(effsize, 4))

#stat.test.anova <- stat.test.anova %>% mutate(p=round(p, 4))

anova.Interface.releasetime <- stat.test.anova
ttest.Interface.releasetime <- stat.test
descriptives.Interface.releasetime <- subject_data_all_long %>% group_by(Interface) %>% get_summary_stats(releasetime) %>% select(Interface, variable, mean, sd, min, max, iqr)
descriptives.Interface.releasetime
oculus_diffs["Release time","Difference"] <- round(temp_plot_data$mean[1]/temp_plot_data$mean[3], 3)
oculus_diffs["Release time","Type"] <- "Ratio"
oculus_diffs["Release time","cohen's d"] <- round(stat.test[3,"effsize"], 3)

```

#### Total time

```{r totaltime_Interface_analysis}
#total time
temp_plot_data <- subject_data_all_long %>%
    group_by(Interface) %>% summarise(mean=mean(totaltime), sd=sd(totaltime), se=(sd/sqrt(sample_size)))

stat.test.anova <-
  anova_summary(effect.size="pes",aov(totaltime ~ Interface + Error(id/Interface), data=subject_data_all_long))
stat.test.anova

stat.test <- subject_data_all_long %>%
  ungroup(.) %>%
  pairwise_t_test(totaltime ~ Interface, paired=TRUE, comparisons=list(c("B_Leap","HHI_Leap"),c("HHI_Leap","Oculus"))) %>%
  add_significance(p.col="p.adj", output.col="p.adj.signif", symbols=mysymbols) %>%
  left_join(subject_data_all_long %>% ungroup(.) %>% cohens_d(totaltime ~ Interface, paired=TRUE) %>% select(group1, group2, effsize, magnitude), by=c("group1", "group2"))%>%
  mutate(Interface=group1)
stat.test

  #raincloud totaltime
  totaltime_Interface_raincloud <- ggplot(subject_data_all_long,aes(x=Interface, y=totaltime, fill = Interface, colour = Interface))+
    geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=myalpha, adjust = mysmoothing)+
    geom_point(position = position_jitter(width = .1), size = .25)+
    geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK")+
    #stat_compare_means(comparisons=list(c("B_Leap", "HHI_Leap"), c("HHI_Leap", "Oculus"), c("B_Leap", "Oculus")), method="t.test", paired=TRUE, label="p.signif")+
    geom_label(data=temp_plot_data, aes(Interface, mean, label=round(mean,2)), alpha=1, position=position_nudge(.5), color="white", label.size=.2)+
    geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
    ylab('Time (seconds)')+xlab('Interface')+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
    scale_color_manual(values=mycolors)+#scale_colour_brewer(palette = "Set2")+
    scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2", direction=1)+
    labs(title="Total time (per trial)")+
    stat_pvalue_manual(data=stat.test %>% filter(p.adj < 0.05), xmin="group1", xmax="group2", label = "p.adj.signif", step.increase=.1, y.position=max(subject_data_all_long$totaltime), position=position_nudge(.25))+
    theme(plot.title = element_text(size=title_size), axis.title = element_text(size=axis_text_size), axis.text = element_text(size=axis_text_size*.75))
totaltime_Interface_raincloud
  ggsave("totaltime_plot_main.jpg", width=10, height=7)


# transform for data output
stat.test <- stat.test %>% select(-.y., -n1, -n2, -Interface)%>% mutate(p=round(p, 4), p.adj=round(p.adj, 4), effsize=round(effsize, 4))

#stat.test.anova <- stat.test.anova %>% mutate(p=round(p, 4))

anova.Interface.totaltime <- stat.test.anova
ttest.Interface.totaltime <- stat.test
descriptives.Interface.totaltime <- subject_data_all_long %>% group_by(Interface) %>% get_summary_stats(totaltime) %>% select(Interface, variable, mean, sd, min, max, iqr)
descriptives.Interface.totaltime
oculus_diffs["Total time","Difference"] <- round(temp_plot_data$mean[1]/temp_plot_data$mean[3], 3)
oculus_diffs["Total time","Type"] <- "Ratio"
oculus_diffs["Total time","cohen's d"] <- round(stat.test[3,"effsize"], 3)

# Interface order
Interface.order.anova <-
  anova_summary(effect.size="pes",aov(totaltime ~ Interface*InterfaceOrder + Error(id/Interface), data=subject_data_all_long))
Interface.order.anova

#Leap group
Interface.order.anova2 <-
  anova_summary(effect.size="pes",aov(totaltime ~ Interface*Leap_Group + Error(id/Interface), data=subject_data_all_long%>%ungroup%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap")))
Interface.order.anova2

r_val <- cor.test(
  x = subject_data_all_long[which(subject_data_all_long$Interface=="HHI_Leap"),"totaltime"],
  y = subject_data_all_long[which(subject_data_all_long$Interface=="B_Leap"),"totaltime"],
  method = "pearson",
  alternative = "two.sided"
  )
r_val <- r_val$estimate[[1]]

TOSTpaired(n=32,
  m1 = descriptives.Interface.totaltime[which(descriptives.Interface.totaltime$Interface=="HHI_Leap"),"mean"][[1]],
  m2 = descriptives.Interface.totaltime[which(descriptives.Interface.totaltime$Interface=="B_Leap"),"mean"][[1]],
  sd1 = descriptives.Interface.totaltime[which(descriptives.Interface.totaltime$Interface=="HHI_Leap"),"sd"][[1]],
  sd2 = descriptives.Interface.totaltime[which(descriptives.Interface.totaltime$Interface=="B_Leap"),"sd"][[1]],
  r12 = r_val,
  low_eqbound_dz = -.3,
  high_eqbound_dz = .3,
  alpha = .05,
  plot= TRUE,
  verbose = TRUE
)

```

#### Accidental drops

```{r Interface_accidental drops, warning=FALSE}
#temp_plot_data <- subject_data_all_long %>% group_by(Interface) %>% summarise(mean=mean(Drop_Rate), sd=sd(Drop_Rate), median=median(Drop_Rate), se=(sd/sqrt(sample_size)), IQR=IQR(Drop_Rate))

temp_plot_data <- subject_data_all_long %>% group_by(Interface) %>% get_summary_stats(Drop_Count)

stat.test.levene <- subject_data_all_long %>% levene_test(Drop_Count ~ Interface) %>% mutate(p=round(p, 4))
stat.test.levene

stat.test.shapiro <- subject_data_all_long %>% group_by(Interface) %>% shapiro_test(Drop_Count) %>% mutate(p=round(p, 4), normal=p>0.05)
stat.test.shapiro

stat.test.anova <- 
anova_summary(effect.size="pes",aov(Drop_Count ~ Interface + Error(id/Interface), data=subject_data_all_long))
stat.test.anova
#write.csv(stat.test.anova, file="dropcount_anova.csv")

stat.test <- subject_data_all_long %>%
  ungroup(.) %>%
  pairwise_t_test(Drop_Count ~ Interface, paired=TRUE, comparisons=list(c("B_Leap","HHI_Leap"),c("HHI_Leap","Oculus"))) %>%
  add_significance(p.col="p.adj", output.col="p.adj.signif", symbols=mysymbols) %>%
  left_join(subject_data_all_long %>% ungroup(.) %>% cohens_d(Drop_Count ~ Interface, paired=TRUE) %>% select(group1, group2, effsize, magnitude), by=c("group1", "group2"))%>%
  mutate(Interface=group1)
stat.test

  # plot
drops_raincloud <-  ggplot(subject_data_all_long, aes(Interface, Drop_Count, fill = Interface, color = Interface))+
    geom_flat_violin(position = position_nudge(x = .1, y = 0), alpha=myalpha, adjust = mysmoothing)+
    #geom_pointrange(data=temp_plot_data, aes(Interface, median, ymin=q1, ymax=q3), width=.1, position=position_nudge(x=.15), fill="transparent", linetype=1)+ # median pointrange
    #geom_boxplot(width=.1, alpha=.4)+
    #geom_bar(data=temp_plot_data, aes(y=mean), stat="identity", width=.2)+
    #geom_point(position = position_jitter(width = .1, height=.01), size = .25)+
    #geom_linerange(data=temp_plot_data, aes(x=Interface, y=NULL, ymin=q1, ymax=q3), color="black", size=1, position=position_nudge(x=.25))+ #IQR line
    #geom_label(data=temp_plot_data, aes(Interface, median, label=paste0(ceiling(median),"%")), color="white", position=position_nudge(.4), alpha=.9)+ # median label
   geom_label(data=temp_plot_data, aes(Interface, y=mean, label=round(mean, 2)), color="white", position=position_nudge(.3), alpha=.9, size=8)+ # mean label
    geom_dotplot(binaxis = "y", stackratio=1.3, binwidth = 1, stackdir="down", dotsize=.18, alpha=.8, position=position_nudge(x=.07))+
    geom_point(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.1), colour = "black", size=3)+
    geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.1), colour = "black", width = 0.05, size = 1.2)+ # mean error bar
    # geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(0), width = 0.05, size = 0.5)+ #error bar on bar
    ylab('Accidental Drops (of 30)')+xlab('')+theme_cowplot()+guides(fill = FALSE, colour = FALSE, shape=TRUE) + #coord_flip()+
    scale_color_manual(values=mycolors)+#scale_colour_brewer(palette = "Set2")+
    scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2", direction=1)+
    #geom_text(data=temp_plot_data, aes(label=mean),hjust=-.2, vjust=.2)+
    labs(title="Accidental Drops")+
    stat_pvalue_manual(data=stat.test %>% filter(p.adj < 0.05), xmin="group1", xmax="group2", label = "p.adj.signif", step.increase=.1, y.position=1.85*max(temp_plot_data$mean), position=position_nudge(.1), alpha = 1, size=10, bracket.size = .5)+
  theme(plot.title = element_text(size=title_size), axis.title = element_text(size=axis_text_size), axis.text = element_text(size=axis_text_size*.75))
drops_raincloud
  ggsave("accidental_drops_main.jpg", width=10, height=7)


  # plot 2 (nonparametric)
drops_plot <-  ggplot(subject_data_all_long, aes(Interface, Drop_Count, fill = Interface, color = Interface))+
    #geom_flat_violin(position = position_nudge(x = .1, y = 0), alpha=.7)+#)+#adjust=2)+
    #geom_pointrange(data=temp_plot_data, aes(Interface, median, ymin=q1, ymax=q3), width=.1, position=position_nudge(x=.15), fill="transparent", linetype=1)+ # median pointrange
    geom_boxplot(width=.15, alpha=.4)+
    #geom_bar(data=temp_plot_data, aes(y=mean), stat="identity", width=.2)+
    #geom_point(position = position_jitter(width = .1, height=.01), size = .25)+
    #geom_linerange(data=temp_plot_data, aes(x=Interface, y=NULL, ymin=q1, ymax=q3), color="black", size=1, position=position_nudge(x=.25))+ #IQR line
    geom_label(data=temp_plot_data, aes(Interface, median, label=round(median, 2)), color="white", position=position_nudge(.25), alpha=.9)+ # median label
   #geom_label(data=temp_plot_data, aes(Interface, y=mean, label=round(mean, 2)), color="white", position=position_nudge(.3), alpha=.9)+ # mean label
    geom_dotplot(binaxis = "y", stackratio=1.4, binwidth = 1, stackdir="center", dotsize=.1, alpha=.8, position=position_nudge(x=0))+
    #geom_point(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.1), colour = "black")+
    #geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.1), colour = "black", width = 0.05, size = 0.8)+ # mean error bar
    # geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(0), width = 0.05, size = 0.5)+ #error bar on bar
    ylab('Accidental Drops (of 30)')+xlab('Interface')+theme_cowplot()+guides(fill = FALSE, colour = FALSE, shape=TRUE) + #coord_flip()+
    scale_colour_brewer(palette = "Dark2")+
    scale_fill_brewer(palette = "Set2")+
    #geom_text(data=temp_plot_data, aes(label=mean),hjust=-.2, vjust=.2)+
    labs(title="Accidental Drops")#, caption = "Means, 95% CI; Within-subjects T-test, adj.: Holm")+
    #stat_pvalue_manual(data=stat.test, xmin="group1", xmax="group2", label = "p.adj.signif", step.increase=.1, y.position=2*max(temp_plot_data$mean), position=position_nudge(.1))
drops_plot

# plot the difference data
diff_set <- subject_data_all_long %>% select(Interface, id, Drop_Count) %>% spread(Interface, Drop_Count) %>% mutate(diff=B_Leap-HHI_Leap) %>% ungroup(.)

ggplot(diff_set, aes(diff)) +
  geom_density(fill="grey")+labs(title="Difference data - Leaps (density)", x="Differences: Leap - HHI_Leap")+theme_cowplot()+geom_label(aes(x=mean(diff), y=.01,  label=paste0("M=", mean(diff))), position=position_nudge(1))+
  geom_vline(aes(xintercept=mean(diff)))

cat("Leap diff data passes Shapiro test for normal distribution? ", (diff_set %>% shapiro_test(diff))$p>0.05)
describe(diff_set$diff)

# transform for data output
stat.test <- stat.test %>% select(-.y., -n1, -n2, -Interface)%>% mutate(p=round(p, 4), p.adj=round(p.adj, 4), effsize=round(effsize, 4))

#stat.test.anova <- stat.test.anova %>% mutate(p=round(p, 4))

# non-parametric
# stat.test.friedman <- subject_data_all_long %>% friedman_test(Drop_Count ~ Interface | id) %>% mutate(p=round(p, 4))
# stat.test.wilcox <- subject_data_all_long %>% wilcox_test(Drop_Count ~ Interface, paired=TRUE)
# stat.test.friedman
# stat.test.wilcox

anova.Interface.drops <- stat.test.anova
ttest.Interface.drops <- stat.test
descriptives.Interface.drops <- subject_data_all_long %>% group_by(Interface) %>% get_summary_stats(Drop_Count) %>% select(Interface, variable, mean, sd, median, mad, min, max, iqr)
descriptives.Interface.drops
oculus_diffs["Accidental drops","Difference"] <- round(temp_plot_data$mean[1]-temp_plot_data$mean[3], 3)
oculus_diffs["Accidental drops","Type"] <- "Mean difference"
oculus_diffs["Accidental drops","cohen's d"] <- round(stat.test[3,"effsize"], 3)

# #print to file
# sink("results_all.txt", append = TRUE)
# cat("\n|Accidental drops|\n\nT-Test\n")
# print(as.data.frame(stat.test))
# cat("\nANOVA\n")
# print(stat.test.anova)
# cat("\n---\n")
# sink()



```


### Cube size

#### Accuracy

```{r cube_size_accuracy, echo=TRUE}

temp_plot_data <- subject_data_cube_size %>%
  group_by(Interface, Cube_Size) %>%
  get_summary_stats(Distance)

stat.test <- subject_data_cube_size %>%
  group_by(Cube_Size) %>%
  pairwise_t_test(Distance ~ Interface, paired=TRUE, comparisons=list(c("B_Leap","HHI_Leap"),c("HHI_Leap","Oculus"))) %>%
  left_join(subject_data_cube_size %>% ungroup(.) %>% cohens_d(Distance ~ Interface, paired=TRUE) %>% select(group1, group2, effsize, magnitude), by=c("group1", "group2"))%>%
  mutate(Interface=group1) %>%
 left_join(subject_data_cube_size %>% group_by(Cube_Size) %>% summarise(y.position=max(Distance))) %>% mutate(rounded_p=round(p.adj, 4)) %>%
  adjust_pvalue() %>% add_significance(p.col="p.adj", output.col="p.adj.signif", symbols=mysymbols)
  
stat.test

# anova - all interfaces
stat.test.anova <- 
anova_summary(effect.size="pes",aov(Distance ~ Interface*Cube_Size + Error(id/(Interface*Cube_Size)), data=subject_data_cube_size))
stat.test.anova
#write.csv(stat.test.anova, file="accuracy_cubesize_anova.csv")

# anova (Leaps only)
stat.test.anova2 <- 
anova_summary(effect.size="pes",aov(Distance ~ Interface*Cube_Size + Error(id/(Interface*Cube_Size)), data=subject_data_cube_size%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap")))
stat.test.anova2
#write.csv(stat.test.anova, file="accuracy_cubesize_anova.csv")

  # create plot
distance_cubesize_plot <-
  #ggplot(temp_plot_data, aes(x=Cube_Size, y=mean, color=Interface, group=Interface)) +
  ggplot(subject_data_cube_size, aes(Interface, Distance, color=Interface, fill=Interface))+
    # theme(legend.position = legend_pos, legend.title=element_text(size=legend_title_size), 
    #       legend.text=element_text(size=legend_text_size),
    #       axis.text=element_text(size=axis_text_size),
    #       title = element_text(size=title_size, hjust=.5))+
    geom_point(position = position_jitter(width = .1, height=0), size = .25)+
    geom_violinhalf(position = position_nudge(x = .25, y = 0), alpha=myalpha, adjust = mysmoothing)+
    geom_point(data=temp_plot_data, aes(x=Interface, y=mean), position = position_nudge(.25), color="black")+
    geom_errorbar(data=temp_plot_data, aes(x=Interface, y=mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96), colour=Interface), width=.05, position=position_nudge(.25), linetype=1, color="black") + 
    geom_label(data=temp_plot_data, aes(x=Interface, y=0.04, label=round(mean, 3)), color="white", position=position_nudge(.25), alpha=.7)+ # median label
    theme_cowplot()+guides(fill=FALSE, color=FALSE)+#scale_x_discrete(labels=NULL)+
    #geom_point(aes(label=id), position=position_jitterdodge(jitter.width=.08, jitter.height=0.005, dodge.width=.4, alpha=.5))+# position=position_jitter(width=0.03, height=0.005))+
    #scale_size_manual(values=c(10,6,3))+
    #geom_path(data=temp_plot_data, aes(x=Cube_Size, y=mean, group=Interface, color=Interface),size=.5, position=position_dodge(width=.4), linetype=2)+
    scale_color_manual(values=mycolors)+#scale_colour_brewer(palette = "Set2")+
    scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2", direction=1)+
    labs(title="Accuracy by Cube Size", caption="Means, 95% CI; Test: Within-subjects T-test; Adj.: Holm", y="Distance from target (meters)", x=NULL)+
    stat_pvalue_manual(data=stat.test %>% filter(p.adj < 0.05), label = "p.adj.signif", position=position_nudge(.25), step.increase = .05, step.group.by = "Cube_Size")+
    facet_grid(. ~ Cube_Size)+
  theme(plot.title = element_text(size=title_size), axis.title = element_text(size=axis_text_size), axis.text = element_text(size=axis_text_size*.75))
  #  coord_cartesian(ylim=c(0.0035, 0.006))
distance_cubesize_plot
  ggsave("accuracy_plot_cubesize.jpg", width=10, height=7)


ggplot(temp_plot_data, aes(Cube_Size, mean, color=Interface))+
  geom_point(size=3, position=position_dodge(.2))+theme_cowplot()+
  scale_color_brewer(palette="Set2")+geom_errorbar(aes(ymin=mean-(se*1.96), ymax=mean+(se*1.96)), width=.05, size=.5, linetype=1, position=position_dodge(.2))+
  labs(title="Accuracy by cube size", caption="Means, 95% CI", y="Distance from target (meters)", x="Cube Size")
ggsave("distance_cubesize_interface_plot.jpg")

ggplot(subject_data_cube_size %>% group_by(Cube_Size) %>% get_summary_stats(Distance), aes(Cube_Size, mean))+
  geom_point(size=3, position=position_dodge(.2))+theme_cowplot()+
  scale_color_brewer(palette="Set2")+geom_errorbar(aes(ymin=mean-(se*1.96), ymax=mean+(se*1.96)), width=.05, size=.5, linetype=1, position=position_dodge(.2))+
  labs(title="Accuracy by cube size (all interfaces)", caption="Means, 95% CI", y="Distance from target (meters)", x="Cube Size")
ggsave("distance_cubesize_main_effect_plot.jpg")


# transform for data output
stat.test <- stat.test %>% mutate(p=round(p, 4), p.adj=round(p.adj, 4), statistic=round(statistic, 3), effsize=round(effsize, 4)) %>% select(Cube_Size, group1, group2, statistic, df, p, p.adj, "p.adj.sig"=p.adj.signif, eff=effsize, mag=magnitude)

stat.test.anova <- stat.test.anova %>% mutate(p=round(p, 4))

anova.Interface.cubesize.distance <- stat.test.anova
ttest.Interface.cubesize.distance <- stat.test
descriptives.Interface.cubesize.distance <- subject_data_cube_size %>% group_by(Interface, Cube_Size) %>% get_summary_stats(Distance) %>% select(Interface, Cube_Size, variable, mean, sd, min, max, iqr)
descriptives.Interface.cubesize.distance

```

####Grab time

```{r cube_size_grabtime}
# Time from spawn to grab: dot plot of Interface * cube size
  # create descriptives

stat.test.anova <- 
anova_summary(effect.size="pes",aov(grabtime ~ Interface*Cube_Size + Error(id/(Interface*Cube_Size)), data=subject_data_cube_size))
stat.test.anova

stat.test.anova2 <- 
anova_summary(effect.size="pes",aov(grabtime ~ Interface*Cube_Size + Error(id/(Interface*Cube_Size)), data=subject_data_cube_size %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap")))
stat.test.anova2
#write.csv(stat.test.anova, file="grabtime_cubesize_anova.csv")

stat.test <- subject_data_cube_size %>%
  group_by(Cube_Size) %>%
  pairwise_t_test(grabtime ~ Interface, paired=TRUE, comparisons=list(c("B_Leap","HHI_Leap"),c("HHI_Leap","Oculus"))) %>%
   left_join(subject_data_cube_size %>% ungroup(.) %>% cohens_d(grabtime ~ Interface, paired=TRUE) %>% select(group1, group2, effsize, magnitude), by=c("group1", "group2"))%>%
  mutate(Interface=group1, y.position=3, rounded_p=round(p.adj, 4)) %>%
  adjust_pvalue() %>% add_significance(p.col="p.adj", output.col="p.adj.signif", symbols=mysymbols) #%>% left_join(subject_data_cube_size %>% group_by(Cube_Size) %>% summarise(y.position=max(grabtime)))
stat.test

temp_plot_data <- subject_data_cube_size %>%
  group_by(Interface, Cube_Size) %>%
  get_summary_stats(grabtime)

  # create plot
  grabtime_cubesize_plot <-
    ggplot(temp_plot_data, aes(x=Interface, y=mean, color=Interface, fill=Interface)) +
    theme_cowplot() +
    # theme(legend.position = legend_pos, legend.title=element_text(size=legend_title_size), 
    #       legend.text=element_text(size=legend_text_size),
    #       axis.text=element_text(size=axis_text_size),
    #       title = element_text(size=title_size, hjust=.5)) +
    geom_point(data=subject_data_cube_size, aes(Interface, grabtime), position = position_jitter(width = .1, height=0), size = .25)+
    geom_violinhalf(data=subject_data_cube_size, aes(Interface, grabtime), position = position_nudge(x = .25, y = 0), alpha=myalpha, adjust = mysmoothing)+
    geom_point(position = position_nudge(.25), color="black")+#shape=15)+ 
    geom_errorbar(aes(ymin=mean-(se*1.96), ymax=mean+(se*1.96)), color="black", width=.05, size=.5, position=position_nudge(.25), linetype=1) +
    geom_label(aes(label=round(mean, 2), y=mean), color="white", position=position_nudge(.5))+
    scale_color_manual(values=mycolors)+#scale_colour_brewer(palette = "Set2")+
    scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2", direction=1)+
    labs(title="Grab time by cube size", caption="Means, 95% CI; Within-subjects T-test, adj.: Holm",
         y="Time (s)",
         x="")+
    guides(fill=FALSE, color=FALSE)+
    stat_pvalue_manual(data=stat.test %>% filter(p.adj < 0.05), label = "p.adj.signif", position=position_nudge(.25), step.increase = .05, step.group.by = "Cube_Size")+
    coord_cartesian(ylim=c(min(subject_data_cube_size$grabtime), 5))+
    facet_grid(. ~ Cube_Size)+#, scales="free", space="free", shrink=TRUE)+
    theme(plot.title = element_text(size=title_size), axis.title = element_text(size=axis_text_size), axis.text = element_text(size=axis_text_size*.75))
 grabtime_cubesize_plot
     ggsave("grabtime_plot_cubesize.jpg", width=10, height=7)

 
 
ggplot(subject_data_cube_size%>%group_by(Cube_Size)%>%get_summary_stats(grabtime), aes(Cube_Size, mean))+
  geom_point(size=3)+theme_cowplot()+scale_color_brewer(palette="Set2")+geom_errorbar(aes(ymin=mean-(se*1.96), ymax=mean+(se*1.96)), color="black", width=.05, size=.5, linetype=1)

ggplot(subject_data_cube_size%>%group_by(Cube_Size,Interface)%>%get_summary_stats(grabtime), aes(Cube_Size, mean, color=Interface))+
  geom_point(size=3, position=position_dodge(.2))+theme_cowplot()+scale_color_brewer(palette="Set2")+geom_errorbar(aes(ymin=mean-(se*1.96), ymax=mean+(se*1.96)), width=.05, size=.5, linetype=1, position=position_dodge(.2))+labs(title="Grab time by cube size", caption="Mean, 95% CI", y="Grab time (s)", x="Cube Size")
ggsave("grabtime_cubesize_plot.jpg")

# transform for data output
stat.test <- stat.test %>% mutate(p=round(p, 4), p.adj=round(p.adj, 4), statistic=round(statistic, 3), effsize=round(effsize, 4)) %>% select(Cube_Size, group1, group2, statistic, df, p, p.adj, "p.adj.sig"=p.adj.signif, eff=effsize, mag=magnitude)

stat.test.anova <- stat.test.anova %>% mutate(p=round(p, 4))

anova.Interface.cubesize.grabtime <- stat.test.anova
ttest.Interface.cubesize.grabtime <- stat.test
descriptives.Interface.cubesize.grabtime <- subject_data_cube_size %>% group_by(Interface, Cube_Size) %>% get_summary_stats(grabtime) %>% select(Interface, Cube_Size, variable, mean, sd, min, max, iqr)
descriptives.Interface.cubesize.grabtime


```

#### Release time

```{r cube_size_release_time}
# Time from grab to release: dot plot of Interface * cube size
  # create descriptives
stat.test.anova <- 
anova_summary(effect.size="pes", aov(releasetime ~ Interface*Cube_Size + Error(id/(Interface*Cube_Size)), data=subject_data_cube_size))
stat.test.anova
#write.csv(stat.test.anova, file="releasetime_cubesize_anova.csv")

stat.test.anova2 <- 
anova_summary(effect.size="pes",aov(releasetime ~ Interface*Cube_Size + Error(id/(Interface*Cube_Size)), data=subject_data_cube_size%>%filter(Interface=="B_Leap"|Interface=="HHI_Leap")))
stat.test.anova2

stat.test <- subject_data_cube_size %>%
  group_by(Cube_Size) %>%
  pairwise_t_test(releasetime ~ Interface, paired=TRUE, comparisons=list(c("B_Leap","HHI_Leap"),c("HHI_Leap","Oculus"))) %>%
   left_join(subject_data_cube_size %>% ungroup(.) %>% cohens_d(releasetime ~ Interface, paired=TRUE) %>% select(group1, group2, effsize, magnitude), by=c("group1", "group2"))%>%
  mutate(Interface=group1, y.position=5) %>%
  adjust_pvalue() %>% add_significance(p.col="p.adj", output.col="p.adj.signif", symbols=mysymbols)#%>% left_join(subject_data_cube_size %>% group_by(Cube_Size) %>% summarise(y.position=.max(releasetime)))

stat.test

  temp_plot_data <- subject_data_cube_size %>%
    group_by(Interface, Cube_Size) %>%
    get_summary_stats(releasetime)
  
  releasetime_cubesize_plot <-
    ggplot(temp_plot_data, aes(x=Interface, y=mean, color=Interface, fill=Interface)) +
    theme_cowplot() +
    geom_point(data=subject_data_cube_size, aes(Interface, releasetime), position = position_jitter(width = .1, height=0), size = .25)+
    geom_violinhalf(data=subject_data_cube_size, aes(Interface, releasetime), position = position_nudge(x = .25, y = 0),alpha=myalpha, adjust = mysmoothing)+
    geom_point(position = position_nudge(.25), color="black")+#shape=15)+ 
    geom_errorbar(aes(ymin=mean-(se*1.96), ymax=mean+(se*1.96)), color="black", width=.05, size=.5, position=position_nudge(.25), linetype=1) +
    geom_label(aes(label=round(mean, 2), y=mean), color="white", position=position_nudge(.55))+
    scale_color_manual(values=mycolors)+#scale_colour_brewer(palette = "Set2")+
    scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2", direction=1)+
    labs(title="Release time by cube size", y="Time (s)", x="", caption="Means w/ 95% CI; Within-subjects T-Tests, adj.: Holm")+
    stat_pvalue_manual(data=stat.test %>% filter(p.adj < 0.05), label = "p.adj.signif", position=position_nudge(.25), step.increase = .05, step.group.by = "Cube_Size")+coord_cartesian(ylim=c(min(subject_data_cube_size$releasetime), 7))+
    facet_grid(. ~ Cube_Size)+#, scales="free", space="free", shrink=TRUE)
    guides(fill=FALSE, color=FALSE)+
    theme(plot.title = element_text(size=title_size), axis.title = element_text(size=axis_text_size), axis.text = element_text(size=axis_text_size*.75))
    releasetime_cubesize_plot
    ggsave("releasetime_plot_cubesize.jpg", width=10, height=7)

# simplified cube size plots
ggplot(temp_plot_data, aes(Cube_Size, mean, color=Interface))+
  geom_point(size=3, position=position_dodge(.2))+theme_cowplot()+
  scale_color_brewer(palette="Set2")+geom_errorbar(aes(ymin=mean-(se*1.96), ymax=mean+(se*1.96)), width=.05, size=.5, linetype=1, position=position_dodge(.2))+
  labs(title="Release time by cube size", caption="Means, 95% CI", y="Time (s)", x="Cube Size")
ggsave("releasetime_cubesize_interface_plot.jpg")

ggplot(subject_data_cube_size %>% group_by(Cube_Size) %>% get_summary_stats(releasetime), aes(Cube_Size, mean))+
  geom_point(size=3, position=position_dodge(.2))+theme_cowplot()+
  scale_color_brewer(palette="Set2")+geom_errorbar(aes(ymin=mean-(se*1.96), ymax=mean+(se*1.96)), width=.05, size=.5, linetype=1, position=position_dodge(.2))+
  labs(title="Release time by cube size", caption="Means, 95% CI", y="Time (s)", x="Cube Size", x="Cube Size")
ggsave("releasetime_cubesize_main_effect_plot.jpg")
  
# transform for data output
stat.test <- stat.test %>% mutate(p=round(p, 4), p.adj=round(p.adj, 4), statistic=round(statistic, 3), effsize=round(effsize, 4)) %>% select(Cube_Size, group1, group2, statistic, df, p, p.adj, "p.adj.sig"=p.adj.signif, eff=effsize, mag=magnitude)

stat.test.anova <- stat.test.anova %>% mutate(p=round(p, 4))

anova.Interface.cubesize.releasetime <- stat.test.anova
ttest.Interface.cubesize.releasetime <- stat.test
descriptives.Interface.cubesize.releasetime <- subject_data_cube_size %>% group_by(Interface, Cube_Size) %>% get_summary_stats(releasetime) %>% select(Interface, Cube_Size, variable, mean, sd, min, max, iqr)
descriptives.Interface.cubesize.releasetime

```

#### Total time

```{r cube_size_total_time}
# Time: total: dot plot of Interface * cube size

stat.test.anova <- 
anova_summary(effect.size="pes",aov(totaltime ~ Interface*Cube_Size + Error(id/(Interface*Cube_Size)), data=subject_data_cube_size))
stat.test.anova

stat.test.anova2 <- 
anova_summary(effect.size="pes",aov(totaltime ~ Interface*Cube_Size + Error(id/(Interface*Cube_Size)), data=subject_data_cube_size%>%filter(Interface=="B_Leap"|Interface=="HHI_Leap")))
stat.test.anova2
#write.csv(stat.test.anova, file="totaltime_cubesize_anova.csv")

stat.test <- subject_data_cube_size %>%
  group_by(Cube_Size) %>%
  pairwise_t_test(totaltime ~ Interface, paired=TRUE, comparisons=list(c("B_Leap","HHI_Leap"),c("HHI_Leap","Oculus"))) %>%
   left_join(subject_data_cube_size %>% ungroup(.) %>% cohens_d(totaltime ~ Interface, paired=TRUE) %>% select(group1, group2, effsize, magnitude), by=c("group1", "group2"))%>%
  mutate(Interface=group1) %>% left_join(subject_data_cube_size %>% group_by(Cube_Size) %>% summarise(y.position=2.5*mean(totaltime))) %>%
  adjust_pvalue() %>% add_significance(p.col="p.adj", output.col="p.adj.signif", symbols=mysymbols)
stat.test

grand_stats <- subject_data_cube_size %>%
  group_by(id, Cube_Size) %>% get_summary_stats(totaltime, type="common") %>% group_by(Cube_Size) %>% get_summary_stats(mean)
  
grand_stats2 <- unity_data_clean %>% group_by(id, Cube_Size) %>% #summarise(mean=mean(TimeFromSpawnToGrabLoss))
  get_summary_stats(TimeFromSpawnToGrabLoss, type="common") %>% group_by(Cube_Size) %>%
  get_summary_stats(mean, type="common")

  temp_plot_data <- subject_data_cube_size %>%
    group_by(Interface, Cube_Size) %>%
    get_summary_stats(totaltime)
  
  totaltime_cubesize_plot <-
    ggplot(temp_plot_data, aes(x=Interface, y=mean, color=Interface, fill=Interface)) +
    theme_cowplot() +
    # theme(legend.position = legend_pos, legend.title=element_text(size=legend_title_size), 
    #       legend.text=element_text(size=legend_text_size),
    #       axis.text=element_text(size=axis_text_size),
    #       title = element_text(size=title_size, hjust=.5)) +
    geom_point(data=subject_data_cube_size, aes(Interface, totaltime), position = position_jitter(width = .1, height=0), size = .25)+
    geom_violinhalf(data=subject_data_cube_size, aes(Interface, totaltime), position = position_nudge(x = .25, y = 0),alpha=myalpha, adjust = mysmoothing)+
    geom_point(position = position_nudge(.25), color="black")+#shape=15)+ 
    geom_errorbar(aes(ymin=mean-(se*1.96), ymax=mean+(se*1.96)), color="black", width=.05, size=.5, position=position_nudge(.25), linetype=1) +
    geom_label(aes(label=round(mean, 2), y=mean), color="white", position=position_nudge(.55))+
    scale_color_manual(values=mycolors)+#scale_colour_brewer(palette = "Set2")+
    scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2", direction=1)+
    labs(title="Total time per trial by cube size", y="Time (s)", x="Cube Size", caption="Means w/ 95% CI; Within-subjects T-Tests, adj.: Holm")+
    guides(fill=FALSE, color=FALSE)+
    stat_pvalue_manual(data=stat.test %>% filter(p.adj < 0.05), label = "p.adj.signif", position=position_nudge(.25), step.increase = .05, step.group.by = "Cube_Size")+coord_cartesian(ylim=c(min(subject_data_cube_size$totaltime), 10))+
    facet_grid(. ~ Cube_Size)+#, scales="free", space="free", shrink=TRUE)
    theme(plot.title = element_text(size=title_size), axis.title = element_text(size=axis_text_size), axis.text = element_text(size=axis_text_size*.75))
  totaltime_cubesize_plot
  ggsave("totaltime_plot_cubesize.jpg", width=10, height=7)

  
# simplified cube size plots
  #ggplot(temp_plot_data, aes(Interface, mean, color=Interface))+
  ggplot(temp_plot_data, aes(Cube_Size, mean, color=Interface))+
  #facet_grid(. ~ Cube_Size)+
  geom_point(size=3, position=position_dodge(.2))+theme_cowplot()+
  scale_color_brewer(palette="Set2")+geom_errorbar(aes(ymin=mean-(se*1.96), ymax=mean+(se*1.96)), width=.05, size=.5, linetype=1, position=position_dodge(.2))+
  labs(title="Total time per trial by cube size", caption="Means, 95% CI", y="Time (s)", x="Cube Size")+
  #stat_pvalue_manual(data=stat.test, label = "p.adj.signif", step.increase = .05, step.group.by = "Cube_Size", y.position=5)
  ggsave("totaltime_cubesize_interface_plot.jpg")

ggplot(subject_data_cube_size %>% group_by(Cube_Size) %>% get_summary_stats(totaltime), aes(Cube_Size, mean))+
  geom_point(size=3, position=position_dodge(.2))+theme_cowplot()+
  scale_color_brewer(palette="Set2")+geom_errorbar(aes(ymin=mean-(se*1.96), ymax=mean+(se*1.96)), width=.05, size=.5, linetype=1, position=position_dodge(.2))+
  labs(title="Total time by cube size", caption="Means, 95% CI", y="Time (s)", x="Cube Size", x="Cube Size")+
ggsave("totaltime_cubesize_main_effect_plot.jpg")


# transform for data output
stat.test <- stat.test %>% mutate(p=round(p, 4), p.adj=round(p.adj, 4), statistic=round(statistic, 3), effsize=round(effsize, 4)) %>% select(Cube_Size, group1, group2, statistic, df, p, p.adj, "p.adj.sig"=p.adj.signif, eff=effsize, mag=magnitude)

stat.test.anova <- stat.test.anova %>% mutate(p=round(p, 4))

anova.Interface.cubesize.totaltime <- stat.test.anova
ttest.Interface.cubesize.totaltime <- stat.test
descriptives.Interface.cubesize.totaltime <- 
  subject_data_cube_size %>% group_by(Interface, Cube_Size) %>% get_summary_stats(totaltime) %>% 
  select(Interface, Cube_Size, variable, mean, sd, min, max, iqr)
descriptives.Interface.cubesize.totaltime

```

#### Accidental drops

```{r cube_size_accidental_drops}
# Accidental drops: total: dot plot of Interface * cube size
  temp_plot_data <- subject_data_cube_size %>%
    group_by(Interface, Cube_Size) %>%
    get_summary_stats(Drop_Count)  

  #print("ANOVA: accidental drops - Interface*cube size")
  # summary(aov(Drop_Count ~ Interface*Cube_Size + Error(id/(Interface*Cube_Size)), data=subject_data_cube_size %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap")))
  stat.test.anova <- anova_summary(effect.size="pes",aov(Drop_Count ~ Interface*Cube_Size + Error(id/(Interface*Cube_Size)), data=subject_data_cube_size))
  
    stat.test.anova2<-anova_summary(effect.size="pes",aov(Drop_Count ~ Interface*Cube_Size + Error(id/(Interface*Cube_Size)), data=subject_data_cube_size %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap")))

 # write.csv(stat.test.anova, "accidentaldrops_cubesize_anova.csv")

stat.test <- subject_data_cube_size %>%
  group_by(Cube_Size) %>%
pairwise_t_test(Drop_Count ~ Interface, paired=TRUE, comparisons=list(c("B_Leap","HHI_Leap"),c("HHI_Leap","Oculus"))) %>%
   left_join(subject_data_cube_size %>% ungroup(.) %>% cohens_d(Drop_Count ~ Interface, paired=TRUE) %>% select(group1, group2, effsize, magnitude), by=c("group1", "group2"))%>%
  mutate(Interface=group1) %>%
  left_join(subject_data_cube_size %>% group_by(Cube_Size) %>% summarise(y.position=.75*max(Drop_Count))) %>%
  adjust_pvalue() %>% add_significance(p.col="p.adj", output.col="p.adj.signif", symbols=mysymbols)
stat.test

  #summarise(mean=mean(Drop_Count), sd=sd(Drop_Count), se=(sd/sqrt(sample_size)), median=median(Drop_Count))

  # plot
  drop_count_cubesize_plot <-
    ggplot(subject_data_cube_size, aes(Interface, Drop_Count, fill = Interface, color = Interface))+
    facet_grid(. ~ Cube_Size)+
    #geom_violinhalf(position = position_nudge(x = .05, y = 0), alpha=.7)+#)+#adjust=2)+
    #geom_crossbar(data=temp_plot_data, aes(Interface, median, ymin=q1, ymax=q3), width=.05, position=position_nudge(x=.25), fill="transparent", linetype=1, color="black")+
    geom_point(position = position_jitter(width = .1, height=.05), size = .25)+
    #geom_label(data=temp_plot_data, aes(Interface, median, label=paste0(ceiling(median),"%")), color="white", position=position_nudge(.5), alpha=.7)+ # median label
    #geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.05), colour = "black")+
    geom_bar(stat="identity", data=temp_plot_data, aes(x=Interface, y=mean, fill=Interface), alpha=.5, position=position_nudge(.05), width=.5)+ # doesn't work w/ stat pvalue manual for some reason
    #geom_point(data = temp_plot_data, aes(x = Interface, y = median), shape=10, size= 5, position = position_nudge(.25), colour = "BLACK")+
    geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.05), width = 0.05, size = 0.8)+#,colour = "black")+
    geom_label(data=temp_plot_data, aes(Interface, y=mean, label=round(mean, 2)), color="white", position=position_nudge(.35), alpha=.9)+ # mean label
    #geom_dotplot(binaxis = "y", stackratio=1.4, binwidth = 1, stackdir="down", dotsize=.05, alpha=.8, position=position_nudge(x=0))+
    ylab('Accidental Drops (of 10)')+xlab(NULL)+theme_cowplot()+guides(fill = FALSE, colour = FALSE)+
    scale_x_discrete(labels=NULL)+
    scale_color_manual(values=mycolors)+#scale_colour_brewer(palette = "Set2")+
    scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2", direction=1)+
    stat_pvalue_manual(data=stat.test %>% filter(p.adj < 0.05), label = "p.adj.signif", position=position_nudge(.05), y.position = 5, step.increase = .05, step.group.by = "Cube_Size")+
    labs(title="Accidental Drops by cube size", caption="Means, 95% CI; Within-subjects T-test, adj.: Holm")+
    theme(plot.title = element_text(size=title_size), axis.title = element_text(size=axis_text_size), axis.text = element_text(size=axis_text_size*.75))
  #drop_count_cubesize_plot
  

  drop_count_cubesize_raincloud <-
    ggplot(subject_data_cube_size, aes(Interface, Drop_Count, fill = Interface, color = Interface))+
    facet_grid(. ~ Cube_Size)+
    geom_violinhalf(position = position_nudge(x = .05, y = 0), alpha=myalpha, adjust = mysmoothing)+
    #geom_crossbar(data=temp_plot_data, aes(Interface, median, ymin=q1, ymax=q3), width=.05, position=position_nudge(x=.25), fill="transparent", linetype=1, color="black")+
    #geom_point(position = position_jitter(width = .1, height=.05), size = .25)+
    #geom_label(data=temp_plot_data, aes(Interface, median, label=paste0(ceiling(median),"%")), color="white", position=position_nudge(.5), alpha=.7)+ # median label
    geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.05), colour = "black")+
    #geom_bar(stat="identity", data=temp_plot_data, aes(x=Interface, y=mean, fill=Interface), alpha=.5, position=position_nudge(.05), width=.5)+ # doesn't work w/ stat pvalue manual for some reason
    #geom_point(data = temp_plot_data, aes(x = Interface, y = median), shape=10, size= 5, position = position_nudge(.25), colour = "BLACK")+
    geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.05), width = 0.05, size = 0.8, colour = "black")+
    geom_label(data=temp_plot_data, aes(Interface, y=mean, label=round(mean, 2)), color="white", position=position_nudge(.35), alpha=.9)+ # mean label
    geom_dotplot(binaxis = "y", stackratio=1.4, binwidth = 1, stackdir="down", dotsize=.05, alpha=.8, position=position_nudge(x=0))+
    ylab('Accidental Drops (of 10)')+xlab(NULL)+theme_cowplot()+guides(fill = FALSE, colour = FALSE)+
    scale_x_discrete(labels=NULL)+
    scale_color_manual(values=mycolors)+#scale_colour_brewer(palette = "Set2")+
    scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2", direction=1)+
    stat_pvalue_manual(data=stat.test%>% filter(p.adj < 0.05), label = "p.adj.signif", position=position_nudge(.05), step.increase = .05, step.group.by = "Cube_Size")+
    labs(title="Accidental Drops by Cube Size", caption="Means, 95% CI; Within-subjects T-test, adj.: Holm")+
    theme(plot.title = element_text(size=title_size), axis.title = element_text(size=axis_text_size), axis.text = element_text(size=axis_text_size*.75))
  drop_count_cubesize_raincloud
  ggsave("accidental_drop_plot_cubesize.jpg", width=10, height=7)
  
  
  # box and whisker
ggplot(subject_data_cube_size, aes(Cube_Size, Drop_Count, color = Interface, fill=Interface))+
    #facet_grid(. ~ Cube_Size)+
    geom_boxplot(width=.5, alpha=.6, color="black", outlier.size=.25)+
    #geom_flat_violin(position = position_nudge(x = .25, y = 0), draw_quantiles=.5, alpha=.7)+#)+#adjust=2)+
    #geom_violin(draw_quantiles = .5)+#)+#adjust=2)+
    #geom_point(position = position_jitter(width = .15, height=.1), size = .25)+
    ylab('Accidental Drop Rate (%)')+xlab("Cube Size")+theme_cowplot()+guides(fill = FALSE, colour = FALSE) + #coord_flip()+
    #geom_point(data=temp_plot_data, aes(y=median), color="black", size=2)+
    scale_colour_brewer(palette = "Set2")+
    scale_fill_brewer(palette = "Set2")+
    labs(title="Accidental Drop Rate", caption="Medians and whiskers to 1.5 * IQR")+
    theme(plot.title = element_text(size=title_size), axis.title = element_text(size=axis_text_size))
    #stat_compare_means(comparisons=list(c("B_Leap", "HHI_Leap"), c("HHI_Leap", "Oculus")), method="wilcox", paired=TRUE, label="p.signif")
   # stat_compare_means(comparisons=list(c("B_Leap", "HHI_Leap"), c("HHI_Leap", "Oculus")), method="t.test", paired=TRUE, label="p.signif")

    ggplot(temp_plot_data, aes(x=Cube_Size, y=mean, color=Interface, group=Interface), position=position_dodge2(.5)) +
    theme_cowplot() +
    theme(legend.position = "right", legend.title=element_text(size=legend_title_size),
          legend.text=element_text(size=legend_text_size),
          axis.text=element_text(size=axis_text_size),
          title = element_text(size=title_size, hjust=.5)) +
    #geom_pointrange(aes(ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position=position_dodge2(.5))+
    geom_point(data=subject_data_cube_size, aes(Cube_Size, Drop_Count), size=.2, position=position_jitterdodge(dodge.width=.5, jitter.height=.1, jitter.width=.1))+
    geom_bar(stat="identity", aes(y=mean, fill=Interface), alpha=.5, position="dodge", width=.5)+
    geom_errorbar(aes(ymin=mean-(se*1.96), ymax=mean+(se*1.96)), width=.05, size=.5, position=position_dodge(width=.5), linetype=1) +
    scale_fill_brewer(palette="Set2")+
    scale_color_brewer(palette="Set2")+
    #geom_text(aes(y=mean, label=paste0(round(mean,2))), position=position_dodge2(7))+
    labs(title="Accidental drops",
         y="Drop rate (%)",
         x="Cube Size")
      #facet_grid(. ~ Cube_Size)+
  #  coord_cartesian(ylim=c(0.0035, 0.006))
    
# does data deviate from normal?
shapiro.test((subject_data_cube_size %>% filter(Interface=="HHI_Leap" & Cube_Size=="Medium"))$Drop_Count)$'p.value'>0.05


# save for output later
anova.Interface.cubesize.drops <- stat.test.anova
ttest.Interface.cubesize.drops <- stat.test
descriptives.Interface.cubesize.drops <- 
  subject_data_cube_size %>% group_by(Interface, Cube_Size) %>% get_summary_stats(Drop_Count) %>% 
  select(Interface, Cube_Size, variable, mean, sd, min, max, iqr)
descriptives.Interface.cubesize.drops


```

### Plot compilations - performance

```{r performance_plot_compilations, warning=FALSE}
# performance
# accuracy/distance
plot_grid(distance_Interface_raincloud, distance_cubesize_plot, nrow=2)
ggsave(filename = "accuracy_plots.jpg", width=10, height=12)

#grab time
plot_grid(grabtime_Interface_raincloud, grabtime_cubesize_plot, nrow=2)
ggsave(filename = "grabtime_plots.jpg", width=10, height=12)

# release time
plot_grid(releasetime_Interface_raincloud, releasetime_cubesize_plot, nrow=2)
ggsave("releasetime_plots.jpg", width=10, height=12)

# total time
plot_grid(totaltime_Interface_raincloud, totaltime_cubesize_plot, nrow=2)#, totaltime_subjects_clean_box)
ggsave("totaltime_plots.jpg", width=10, height=12)

plot_grid(drops_raincloud, drop_count_cubesize_plot, nrow=2)#, drops_subject)
ggsave("accidental_drop_plots.jpg", width=10, height=12)

# Interface level
plot_grid(distance_Interface_raincloud, grabtime_Interface_raincloud, releasetime_Interface_raincloud, totaltime_Interface_raincloud, drops_raincloud)
ggsave("Interface_level_plots.jpg", width=14, height=8.5)


# cube size level
plot_grid(distance_cubesize_plot, grabtime_cubesize_plot, releasetime_cubesize_plot, totaltime_cubesize_plot, drop_count_cubesize_plot)
ggsave("cube_size_level_plots.jpg", width=14, height=8.5)


```

## Subjective Metrics

### Overall preferred interface

```{r overall_preference}
stat.test <- table(subject_data_all_wide$PrefCondition)
stat.test
preference <- stat.test

# preferred condition
temp_plot_data <- subject_data_all_long %>%
    select(id, PrefCondition) %>% ungroup(.) %>% distinct(.) %>%
    count(PrefCondition) %>% mutate(PrefCondition=factor(PrefCondition, levels=c("B_Leap","HHI_Leap","Oculus")))
  # make bar plot of counts
preferred_plot <- ggplot(temp_plot_data, aes(PrefCondition, n, fill=PrefCondition, color=PrefCondition))+
    geom_bar(stat="identity", alpha=myalpha, width=.6)+
    scale_fill_manual(values=mycolors)+scale_color_manual(values=mycolors)+
    geom_label(aes(label=n), position=position_nudge(y=-2), color="white")+
    guides(fill=FALSE, color=FALSE)+labs(x="", y="Count")+theme_cowplot()+
    ggtitle("Overall preferred interface")+
    theme(plot.title = element_text(size=title_size*.6), axis.title = element_text(size=axis_text_size))
preferred_plot
#ggsave("preferred_interface.jpg")

```



### Likert data

#### Scores & Descriptives

```{r raw_likert_scores}
#collect scores
likert_scores <- subject_data_all_long %>%
  select(id, Interface, Q_1_Score:satisfaction, InterfaceOrder, Leap_Group, Oculus_Group) %>%
  rename(comfortable=Q_1_Score, precise=Q_2_Score, intuitive=Q_3_Score, tiring=Q_4_Score, gripping=Q_5_Score, releasing=Q_6_Score, natural=Q_7_Score, recommend=Q_8_Score) %>% gather(question, score, 3:12)

likert_5pt_grand_scores <- likert_scores %>% filter(question != "agency" & question != " satisfaction") %>%
  group_by(id, Interface) %>% summarise(grand_mean=mean(score)) %>% ungroup(.)

likert_7pt_grand_scores <- likert_scores %>% filter(question == "agency" | question == " satisfaction") %>%
  group_by(id, Interface) %>% summarise(grand_mean=mean(score)) %>% ungroup(.)

#descriptives
descriptives.subjective5pt <- likert_scores %>% 
  filter(question != "agency" & question != "satisfaction") %>% 
  group_by(question, Interface) %>% 
  get_summary_stats(type="common") %>%
  select(interface=Interface, question, n, mean, sd, median, iqr, min, max) %>%
   bind_rows(likert_scores %>% 
              group_by(question) %>% 
              filter(question != "agency" & question != "satisfaction") %>% 
              get_summary_stats(score, type="common") %>%
              mutate(interface="all") %>%
              select(interface, question, n, mean, sd, median, iqr, min, max)) %>%
  bind_rows(likert_scores %>% 
              ungroup(.) %>% 
              filter(question != "agency" & question != "satisfaction") %>% 
              get_summary_stats(score, type="common") %>%
              mutate(question="all", interface="all") %>%
              select(interface, question, n, mean, sd, median, iqr, min, max)) %>%
  bind_rows(likert_scores %>% 
              group_by(Interface) %>% 
              filter(question != "agency" & question != "satisfaction") %>% 
              get_summary_stats(score, type="common") %>%
              mutate(question="all", interface=Interface) %>%
              select(interface, question, n, mean, sd, median, iqr, min, max)) %>%
  bind_rows(likert_scores %>% 
              filter(question != "agency" & question != "satisfaction") %>% 
              group_by(question, Interface) %>% 
              get_summary_stats(type="common") %>%
              get_summary_stats(mean, type="common") %>%
              mutate(question="means", interface="means") %>%
              select(interface, question, n, mean, sd, median, iqr, min, max)
            ) %>%
  mutate(SDs_from_mid = sd*(mean-3))
#descriptives.subjective5pt

descriptives.subjective7pt <- likert_scores %>% 
  filter(question == "agency" | question == "satisfaction") %>% 
  group_by(question, Interface) %>% 
  get_summary_stats(type="common") %>% 
  select(interface=Interface, question, n, mean, sd, median, iqr, min, max) %>%
      bind_rows(likert_scores %>% 
              group_by(question) %>% 
              filter(question == "agency" | question == "satisfaction") %>% 
              get_summary_stats(score, type="common") %>%
              mutate(interface="all") %>%
              select(interface, question, n, mean, sd, median, iqr, min, max)) %>%
    bind_rows(likert_scores %>% 
              ungroup(.) %>% 
              filter(question == "agency" | question == "satisfaction") %>% 
              get_summary_stats(score, type="common") %>%
              mutate(question="all", interface="all") %>%
              select(interface, question, n, mean, sd, median, iqr, min, max)) %>%
    bind_rows(likert_scores %>% 
              group_by(Interface) %>% 
              filter(question == "agency" | question == "satisfaction") %>% 
              get_summary_stats(score, type="common") %>%
              mutate(question="all", interface=Interface) %>%
              select(interface, question, n, mean, sd, median, iqr, min, max)) %>%
    bind_rows(likert_scores %>% 
              filter(question == "agency" | question == "satisfaction") %>% 
              group_by(question, Interface) %>% 
              get_summary_stats(type="common") %>%
              get_summary_stats(mean, type="common") %>%
              mutate(question="means", interface="means") %>%
              select(interface, question, n, mean, sd, median, iqr, min, max)) %>%
 mutate(SDs_from_mid = sd*(mean-4))
descriptives.subjective7pt



# bar - 5 pt
# need to redo with counts if I want to add the means
ggplot(likert_scores %>% group_by(Interface, question) %>% filter(question!="agency" & question!="satisfaction"), aes(score, fill=Interface))+
  #geom_vline(aes(xintercept=mean(score)))+
  geom_bar(color="grey")+
  facet_grid(question ~ Interface)+
  theme(strip.text.y = element_text(angle = 360))+#geom_histogram(bins=32)+
  scale_fill_brewer(palette="Set2")+scale_color_manual(values = c("grey","black"))

# bar - 7 pt
# need to redo with counts if I want to add the means
ggplot(likert_scores %>% group_by(Interface, question) %>% filter(question=="agency" | question=="satisfaction"), aes(score, fill=Interface))+
  #geom_vline(aes(xintercept=mean(score)))+
  geom_bar(color="grey")+
  facet_grid(question ~ Interface)+
  theme(strip.text.y = element_text(angle = 360))+#geom_histogram(bins=32)+
  scale_fill_brewer(palette="Set2")+scale_color_manual(values = c("grey","black"))

# plot distributions - 5 point
ggplot(likert_scores %>% filter(Interface != "Oculus", question != "agency" & question != "satisfaction"), aes(score, fill=Interface, alpha=Interface))+
  geom_density()+
  facet_grid(question ~ .)+
  scale_alpha_manual(values=c(1,.2))+
  theme_cowplot()+ scale_fill_manual(values=c("green3", "orange"))+
  theme(strip.text.y = element_text(angle = 360))+#geom_histogram(bins=32)+
  labs(title="Distributions of scores on Likert questions (HHI Leap vs. B_Leap")+scale_y_continuous(labels=c())

ggplot(likert_scores %>% filter(Interface != "B_Leap", question != "agency" & question != "satisfaction"), aes(score, fill=Interface, alpha=Interface))+
  geom_density()+
  facet_grid(question ~ .)+
  scale_alpha_manual(values=c(1,.2))+
  theme_cowplot()+ scale_fill_manual(values=c("green3","blue"))+
  theme(strip.text.y = element_text(angle = 360))+#geom_histogram(bins=32)+
  labs(title="Distributions of scores on Likert questions (HHI Leap vs. Oculus")+scale_y_continuous(labels=c())

ggplot(likert_scores %>% filter(question != "agency" & question != "satisfaction"), aes(score, fill=Interface))+
  geom_density()+
  facet_grid(question ~ Interface)+ scale_fill_brewer(palette="Set2")+
  scale_alpha_manual(values=c(1,.2))+
  theme_cowplot()+
  theme(strip.text.y = element_text(angle = 360))+#geom_histogram(bins=32)+
  labs(title="Distributions of scores on Likert questions (HHI Leap vs. B_Leap")+scale_y_continuous(labels=c())

# plot distributions - 7 pt
ggplot(likert_scores %>% filter(Interface != "Oculus", question == "agency" | question == "satisfaction"), aes(score, fill=Interface, alpha=Interface))+
  geom_density()+
  facet_grid(question ~ .)+
  scale_alpha_manual(values=c(1,.2))+
  theme_cowplot()+ scale_fill_manual(values=c("green3", "orange"))+
  theme(strip.text.y = element_text(angle = 360))+#geom_histogram(bins=32)+
  labs(title="Distributions of scores on Likert questions (HHI Leap vs. B_Leap")+scale_y_continuous(labels=c())

ggplot(likert_scores %>% filter(Interface != "B_Leap", question == "agency" | question == "satisfaction"), aes(score, fill=Interface, alpha=Interface))+
  geom_density()+
  facet_grid(question ~ .)+
  scale_alpha_manual(values=c(1,.2))+
  theme_cowplot()+ scale_fill_manual(values=c("green3","blue"))+
  theme(strip.text.y = element_text(angle = 360))+#geom_histogram(bins=32)+
  labs(title="Distributions of scores on Likert questions (HHI Leap vs. Oculus")+scale_y_continuous(labels=c())

ggplot(likert_scores %>% filter(question == "agency" | question == "satisfaction"), aes(score, fill=Interface))+
  geom_density()+
  facet_grid(question ~ Interface)+ scale_fill_brewer(palette="Set2")+
  scale_alpha_manual(values=c(1,.2))+
  theme_cowplot()+
  theme(strip.text.y = element_text(angle = 360))+#geom_histogram(bins=32)+
  labs(title="Distributions of scores on Likert questions (HHI Leap vs. B_Leap")+scale_y_continuous(labels=c())

descriptives.subjective.all <-
  bind_rows(descriptives.subjective5pt, descriptives.subjective7pt) %>%
  filter(question != "all" & question != "means")
descriptives.subjective.all

# build df of mean and sd for t-test table
ttest_questions <- c("comfortable", "precise", "gripping", "releasing", "recommend", "satisfaction")

temp_df <- descriptives.subjective.all %>% filter(question %in% ttest_questions) %>%
  rename(Measure=question)

subjective_mean_sd <- data.frame(Measure=ttest_questions) %>%
  left_join(temp_df %>% filter(interface=="HHI_Leap") %>% select(Measure, mean), by="Measure") %>%
  rename(HHI_Leap_Mean=mean) %>%
  left_join(temp_df %>% filter(interface=="HHI_Leap") %>% select(Measure, sd), by="Measure") %>%
  rename(HHI_Leap_SD=sd) %>%
  left_join(temp_df %>% filter(interface=="B_Leap") %>% select(Measure, mean), by="Measure") %>%
  rename(B_Leap_Mean=mean) %>%
  left_join(temp_df %>% filter(interface=="B_Leap") %>% select(Measure, sd), by="Measure") %>%
  rename(B_Leap_SD=sd) %>%
  left_join(temp_df %>% filter(interface=="Oculus") %>% select(Measure, mean), by="Measure") %>%
  rename(Oculus_Mean=mean) %>%
  left_join(temp_df %>% filter(interface=="Oculus") %>% select(Measure, sd), by="Measure") %>%
  rename(Oculus_SD=sd)

descriptives.subjective.all %>% filter(interface=="HHI_Leap") %>% select(interface, question, mean, sd, SDs_from_mid)

```

#### Stat tests

```{r likert_stat_tests}

# t tests likert q's: hhi_leap vs. oculus
ttests.likert.oculus <- likert_scores %>%
  ungroup(.) %>% group_by(question) %>%
  filter(question %in% c("comfortable","precise", "gripping", "releasing", "recommend", "satisfaction")) %>%
  t_test(score ~ Interface, paired=TRUE, comparisons = list(c("HHI_Leap","Oculus"))) %>%
  adjust_pvalue() %>% add_significance(p.col="p.adj", output.col="p.adj.signif", symbols=mysymbols)

ttests.likert.leap <- likert_scores %>%
  ungroup(.) %>% group_by(question) %>%
  t_test(score ~ Interface, paired=TRUE, comparisons = list(c("HHI_Leap","B_Leap"))) %>%
  adjust_pvalue() %>% add_significance(p.col="p.adj", output.col="p.adj.signif", symbols=mysymbols) %>% mutate(group1="HHI_Leap", group2="B_Leap", statistic=-1*statistic)

#t.tests.likert.all.vs.hhi <- bind_rows(ttests.likert.oculus, ttests.likert.leap)

#t tests all vs. hhi - only for measures flagged as significant by ANOVA
ttests_subjective_all <- likert_scores %>%
  ungroup(.) %>% filter(question %in% c("comfortable","precise", "gripping", "releasing", "recommend", "satisfaction")) %>% group_by(question) %>%
  pairwise_t_test(score ~ Interface, paired=TRUE, ref.group="HHI_Leap") %>% add_significance(p.col="p.adj", output.col="p.adj.signif", symbols=mysymbols)

# sink("subjective_stats.csv")
# write.csv(t.tests.likert.all.vs.hhi)
# sink()

t.tests.likert.all.vs.hhi <- bind_rows(ttests.likert.oculus, ttests.likert.leap) %>%
  left_join(likert_scores %>% ungroup(.) %>% cohens_d(score ~ Interface, paired=TRUE, ref.group="HHI_Leap") %>% select(group1, group2, effsize, magnitude), by=c("group1", "group2")) %>%
  mutate(Interface=group1, test="t-test")
t.tests.likert.all.vs.hhi

# anova for 5 pt. q's w/ grand means
anova.Interface.5ptgrand <- anova_summary(effect.size="pes", aov(grand_mean ~ Interface + Error(id/Interface), data = likert_5pt_grand_scores))

# t-tests for 5pt q's w/ grand means
ttest.Interface.5ptgrand <- likert_5pt_grand_scores %>% ungroup(.) %>% 
  pairwise_t_test(grand_mean ~ Interface, paired = TRUE) %>% 
  adjust_pvalue() %>% left_join(likert_5pt_grand_scores %>% cohens_d(grand_mean ~ Interface, paired = TRUE))

# anova for 7 pt. q's w/ grand means
anova.Interface.7ptgrand <- anova_summary(effect.size="pes", aov(grand_mean ~ Interface + Error(id/Interface), data = likert_7pt_grand_scores))

# t-tests for 7 pt q's w/ grand means
ttest.Interface.7ptgrand <- likert_7pt_grand_scores %>% ungroup(.) %>%
  pairwise_t_test(grand_mean ~ Interface, paired = TRUE) %>%
  adjust_pvalue() %>% left_join(likert_7pt_grand_scores %>% cohens_d(grand_mean ~ Interface, paired = TRUE))


#wilcox vs. B_Leap
wilcox.tests.likert.vs.B_Leap <- likert_scores %>%
  ungroup(.) %>% group_by(question) %>%
  pairwise_wilcox_test(score ~ Interface, paired=TRUE, comparisons=list(c("HHI_Leap","B_Leap"))) %>%
  adjust_pvalue() %>% add_significance(p.col="p.adj", output.col="p.adj.signif")%>%
  mutate(Interface=group1, test="wilcox test")
wilcox.tests.likert.vs.B_Leap

#wilcox vs. oculus
wilcox.tests.likert.vs.oculus <- likert_scores %>%
  ungroup(.) %>% group_by(question) %>%
  pairwise_wilcox_test(score ~ Interface, paired=TRUE, comparisons=list(c("HHI_Leap","Oculus"))) %>%
  mutate(Interface=group1, test="wilcox test")
wilcox.tests.likert.vs.oculus

# transform for data output
stat.test <- t.tests.likert.all.vs.hhi
stat.test <- stat.test %>% mutate(p=round(p, 4), p.adj=round(p.adj, 4), statistic=round(statistic, 3), effsize=round(effsize, 4)) %>% select(question, group1, group2, stat=statistic, df, p, p.adj, p.a.sig=p.adj.signif, eff=effsize, mag=magnitude)

#anovas
anova.test <-
  anova_summary(effect.size="pes",aov(score ~ Interface*question + Error(id/(Interface*question)), data=likert_scores %>% filter(question!="agency", question!="satisfaction")))

anova.likert <-
  anova_summary(effect.size="pes",aov(score ~ Interface + Error(id/Interface), data=likert_scores %>% filter(question=="comfortable"))) %>%
  mutate(question="comfortable") %>%
  rbind(anova_summary(effect.size="pes",aov(score ~ Interface + Error(id/Interface), data=likert_scores %>% filter(question=="precise"))) %>% mutate(question="precise")) %>%
  rbind(anova_summary(effect.size="pes",aov(score ~ Interface + Error(id/Interface), data=likert_scores %>% filter(question=="intuitive"))) %>% mutate(question="intuitive")) %>%
  rbind(anova_summary(effect.size="pes",aov(score ~ Interface + Error(id/Interface), data=likert_scores %>% filter(question=="tiring"))) %>%
  mutate(question="tiring")) %>%
  rbind(anova_summary(effect.size="pes",aov(score ~ Interface + Error(id/Interface), data=likert_scores %>% filter(question=="gripping"))) %>%
  mutate(question="gripping")) %>%
  rbind(anova_summary(effect.size="pes",aov(score ~ Interface + Error(id/Interface), data=likert_scores %>% filter(question=="releasing"))) %>% mutate(question="releasing")) %>%
  rbind(anova_summary(effect.size="pes",aov(score ~ Interface + Error(id/Interface), data=likert_scores %>% filter(question=="natural"))) %>%
  mutate(question="natural")) %>%
  rbind(anova_summary(effect.size="pes",aov(score ~ Interface + Error(id/Interface), data=likert_scores %>% filter(question=="recommend"))) %>% mutate(question="recommend")) %>%
  rbind(anova_summary(effect.size="pes",aov(score ~ Interface + Error(id/Interface), data=likert_scores %>% filter(question=="agency"))) %>%
  mutate(question="agency")) %>%
  rbind(anova_summary(effect.size="pes",aov(score ~ Interface + Error(id/Interface), data=likert_scores %>% filter(question=="satisfaction"))) %>% mutate(question="satisfaction")) %>%
  select(question, everything(.))
          


```

#### Equivalence tests

```{r equivalence_likert}

# 
r_val <- cor.test(
  x = subject_data_all_long[which(subject_data_all_long$Interface=="HHI_Leap"),"totaltime"],
  y = subject_data_all_long[which(subject_data_all_long$Interface=="B_Leap"),"totaltime"],
  method = "pearson",
  alternative = "two.sided"
  )
r_val <- r_val$estimate[[1]]

TOSTpaired(n=32,
  m1 = descriptives.Interface.totaltime[which(descriptives.Interface.totaltime$Interface=="HHI_Leap"),"mean"][[1]],
  m2 = descriptives.Interface.totaltime[which(descriptives.Interface.totaltime$Interface=="B_Leap"),"mean"][[1]],
  sd1 = descriptives.Interface.totaltime[which(descriptives.Interface.totaltime$Interface=="HHI_Leap"),"sd"][[1]],
  sd2 = descriptives.Interface.totaltime[which(descriptives.Interface.totaltime$Interface=="B_Leap"),"sd"][[1]],
  r12 = r_val,
  low_eqbound_dz = -.3,
  high_eqbound_dz = .3,
  alpha = .05,
  plot= TRUE,
  verbose = TRUE
)

```

#### Likert Plots

```{r subjective_plots}

myquestions = c("satisfaction", "recommend", "agency", "natural", "intuitive", "releasing",  "gripping", "precise", "tiring", "comfortable")
question_labels=c("Satisfaction", "Recommend", "Agency", "Natural", "Intuitive", "Releasing",  "Gripping", "Precise", "Tiring", "Comfortable")

subjective_means <- likert_scores %>% group_by(Interface, question) %>% get_summary_stats(show=c("mean","sd","se")) %>% mutate(ci=1.96*se) %>% ungroup() %>%
  mutate(question=factor(question, levels=myquestions, labels=question_labels))

subjective_means[which(subjective_means$question %in% c("Agency","Satisfaction")),"scale"] <- "7pt"
subjective_means[which(not(subjective_means$question %in% c("Agency","Satisfaction"))),"scale"] <- "5pt"

# View(left_join(subjective_means, t.tests.likert.all.vs.hhi %>% mutate(question=factor(question, levels=myquestions, labels=question_labels)) %>% select(Interface, question, `p.adj`), by=c("Interface", "question")))

for (i in 1:nrow(subjective_means)){
  if (subjective_means[i,"scale"]=="7pt"){subjective_means[i,"converted_score"] <- subjective_means[i,"mean"]-4} else-if (subjective_means[i,"scale"]=="5pt"){subjective_means[i,"converted_score"] <- subjective_means[i,"mean"]-3}
}

#View(subjective_means)

# classify above or below avg.

# ggplot(subjective_means %>% filter(scale=="5pt"), aes(question, converted_score, color=Interface, fill=Interface))+
#   theme_minimal()+
#   geom_pointrange(aes(ymin=converted_score-ci, ymax=converted_score+ci), position=position_dodge(width=.5))+
#   #geom_point(data=likert_scores %>% mutate(question=factor(question, levels=myquestions, labels=question_labels)) %>% filter(not(question %in% c("Agency","Satisfaction"))), aes(question, score), size=.25, position=position_jitter(width=.1, height=.1))+
#   #geom_bar(stat="identity", position="dodge", alpha=myalpha)+
#   #geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), position="dodge", show.legend = FALSE)+
#   scale_color_manual(values=mycolors)+#, guide_legend(title="Interface", reverse = FALSE))+
#   scale_fill_manual(values=mycolors)+#, guide_legend(title="Interface", reverse=FALSE))+
#   coord_flip()+
#   theme(legend.position="bottom")+#, axis.text = element_text(size=likert_lab_size), plot.title = element_text(size=likert_title_size), axis.title = element_text(size=likert_lab_size))+
#   scale_y_continuous(limits=c(-2,2))+
#   #scale_x_discrete(position = "top")+
#   #theme(strip.text.y = element_text(angle=0))+
#   geom_hline(aes(yintercept = 0), linetype=2)+
#   labs(title="Subjective Questionnaire Scores", y="Response (Mean)", x="")
# ggsave("subjective_scores_new.jpg")

# ggplot(subjective_means %>% filter(question=="Agency"), aes(question, mean, color=Interface, fill=Interface))+
#   theme_minimal()+
#   geom_pointrange(aes(ymin=mean-ci, ymax=mean+ci), position=position_dodge(width=.5))+
#   #geom_bar(stat="identity", position="dodge", alpha=myalpha)+
#   #geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), position="dodge", show.legend = FALSE)+
#   scale_color_manual(values=mycolors)+#, guide_legend(title="Interface", reverse = FALSE))+
#   scale_fill_manual(values=mycolors)+#, guide_legend(title="Interface", reverse=FALSE))+
#   coord_flip()+
#   theme(legend.position="bottom", axis.text = element_text(size=likert_lab_size), plot.title = element_text(size=likert_title_size), axis.title = element_text(size=likert_lab_size))+
#   scale_y_continuous(limits=c(1,7), breaks=c(1:7))+
#   #theme(strip.text.y = element_text(angle=0))+
#   geom_hline(aes(yintercept = 4), linetype=2)+
#   labs(title="Subjective Questionnaire Scores", y="Response (Mean)", x="")
# ggsave("subjective_scores_agency_new.jpg")

# ggplot(subjective_means %>% filter(question=="Satisfaction"), aes(question, mean, color=Interface, fill=Interface))+
#   theme_minimal()+
#   geom_pointrange(aes(ymin=mean-ci, ymax=mean+ci), position=position_dodge(width=.5))+
#   #geom_bar(stat="identity", position="dodge", alpha=myalpha)+
#   #geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), position="dodge", show.legend = FALSE)+
#   scale_color_manual(values=mycolors)+#, guide_legend(title="Interface", reverse = FALSE))+
#   scale_fill_manual(values=mycolors)+#, guide_legend(title="Interface", reverse=FALSE))+
#   coord_flip()+
#   theme(legend.position="bottom", axis.text = element_text(size=likert_lab_size), plot.title = element_text(size=likert_title_size), axis.title = element_text(size=likert_lab_size))+
#   scale_y_continuous(limits=c(1,7), breaks=c(1:7))+
#   #theme(strip.text.y = element_text(angle=0))+
#   geom_hline(aes(yintercept = 4), linetype=2)+
#   labs(title="Subjective Questionnaire Scores", y="Response (Mean)", x="")
# #ggsave("subjective_scores_satisfaction_new.jpg")

# ggplot(subjective_means %>% filter(scale=="5pt"), aes(question, converted_score, color=Interface, fill=Interface))+
#   geom_bar(stat="identity", position="dodge", alpha=myalpha)+
#   geom_errorbar(aes(ymin=converted_score-ci, ymax=converted_score+ci), position=position_dodge(width=.9), width=.3, show.legend = FALSE)+
#   scale_color_manual(values=mycolors, guide_legend(title="Interface", reverse = TRUE))+
#   scale_fill_manual(values=mycolors, guide_legend(title="Interface", reverse=TRUE))+
#   scale_y_continuous(limits = c(-2,3))+
#   coord_flip()+
#   stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% mutate(question=factor(question, levels=myquestions, labels=question_labels)) %>% filter(question != "Agency", question != "Satisfaction"), x="question", label = "p.adj.signif", step.increase=.1, y.position=-2, size=star_size)+
#   scale_y_continuous(breaks=c(-2:3), limits=(c(-2,2)))+#labels = c(-2,-1,0,1,2,3))+
#   theme(legend.position = "bottom")+# strip.text.y = element_text(angle=0))+
#   geom_hline(aes(yintercept = 0), linetype=2)+
#   labs(title="Subjective Questionnaire Scores")#+facet_grid(question ~ .)

# good old fashioned bar chart
ggplot(subjective_means %>% mutate(question=fct_rev(question)) %>% filter(scale=="5pt"), aes(Interface, converted_score, color=Interface, fill=Interface))+
  #theme_minimal()+
  geom_bar(stat="identity", position="dodge", alpha=myalpha)+
  geom_errorbar(aes(ymin=converted_score-ci, ymax=converted_score+ci), position=position_dodge(width=.9), width=.3, show.legend = FALSE)+
  scale_color_manual(values=mycolors, guide_legend(title="Interface", reverse = TRUE))+
  scale_fill_manual(values=mycolors, guide_legend(title="Interface", reverse=TRUE))+
  coord_flip()+
  
  stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% mutate(question=factor(question, levels=myquestions, labels=question_labels), p.adj=round(p.adj, 3), y.position=1.9) %>% filter(question != "Agency", question != "Satisfaction"), x="group1", label = "p.adj.signif", step.increase=.1, size=5)+#y.position=statistic
  
  scale_y_continuous(breaks=c(-2:3), limits=(c(-2,2)))+#labels = c(-2,-1,0,1,2,3))+
  theme(legend.position = "left",  axis.text.y = element_blank(), axis.line.y=element_blank(), axis.ticks.y=element_blank(), strip.text.y = element_text(angle=0))+
  geom_hline(aes(yintercept = 0), linetype=2)+
  labs(title="Subjective Question Scores", y="Mean Likert-scale Rating", x=NULL)+
  guides(fill = guide_legend(reverse = TRUE), color=guide_legend(reverse=TRUE))+
  facet_grid(question ~ .)
ggsave("subjective_questions_new_bar.jpg")

ggplot(subjective_means %>% filter(question=="Agency"), aes(Interface, converted_score, color=Interface, fill=Interface))+
  #theme_minimal()+
  geom_bar(stat="identity", alpha=myalpha)+
  geom_errorbar(aes(ymin=converted_score-ci, ymax=converted_score+ci), width=.1, show.legend = FALSE)+
  scale_color_manual(values=mycolors, guide_legend(title="Interface", reverse = TRUE))+
  scale_fill_manual(values=mycolors, guide_legend(title="Interface", reverse=TRUE))+
  coord_flip()+
  #stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% mutate(question=factor(question, levels=myquestions, labels=question_labels), p.adj=paste0("p(Holm) = ", round(p.adj, 3)), y.position=2.9) %>% filter(question == "Agency"), label = "p.adj.signif", step.increase=.1, size=5)+#y.position=statistic
  scale_y_continuous(breaks=c(-3:3), limits=(c(-3,4)))+#labels = c(-2,-1,0,1,2,3))+
  theme(legend.position = "left",  axis.text.y = element_blank(), axis.line.y=element_blank(), axis.ticks.y=element_blank(), strip.text.y = element_text(angle=0))+
  geom_hline(aes(yintercept = 0), linetype=2)+
  labs(title="Agency", y="Mean Likert-scale Rating", x=NULL)+
  guides(fill = guide_legend(reverse = TRUE), color=guide_legend(reverse=TRUE))#+facet_grid(question ~ .)
ggsave("subjective_questions_new_bar_agency.jpg", height=2, width=7)

ggplot(subjective_means %>% filter(question=="Satisfaction"), aes(Interface, converted_score, color=Interface, fill=Interface))+
  #theme_minimal()+
  geom_bar(stat="identity", position="dodge", alpha=myalpha)+
  geom_errorbar(aes(ymin=converted_score-ci, ymax=converted_score+ci), position=position_dodge(width=.9), width=.1, show.legend = FALSE)+
  scale_color_manual(values=mycolors, guide_legend(title="Interface", reverse = TRUE))+
  scale_fill_manual(values=mycolors, guide_legend(title="Interface", reverse=TRUE))+
  coord_flip()+
  stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% mutate(question=factor(question, levels=myquestions, labels=question_labels), y.position=2.5) %>% filter(question == "Satisfaction"), label = "p.adj.signif", step.increase=.1, size=5, remove.bracket=TRUE)+#y.position=statistic
  scale_y_continuous(breaks=c(-3:3), limits=(c(-3,4)))+#labels = c(-2,-1,0,1,2,3))+
  theme(legend.position = "left",  axis.text.y = element_blank(), axis.line.y=element_blank(), axis.ticks.y=element_blank(), strip.text.y = element_text(angle=0))+
  geom_hline(aes(yintercept = 0), linetype=2)+
  labs(title="Overall Satisfaction", y="Mean Likert-scale Rating", x=NULL)+
  guides(fill = guide_legend(reverse = TRUE), color=guide_legend(reverse=TRUE))#+facet_grid(question ~ .)
ggsave("subjective_questions_new_bar_satisfaction.jpg", width=7, height=2)


# pointrange version
ggplot(subjective_means %>% mutate(question=fct_rev(question)) %>% filter(scale=="5pt"), aes(Interface, converted_score, color=Interface, fill=Interface))+
  #theme_minimal()+  
  geom_pointrange(aes(ymin=converted_score-ci, ymax=converted_score+ci), position=position_dodge(width=.5))+
  scale_color_manual(values=mycolors, guide_legend(title="Interface", reverse = TRUE))+
  scale_fill_manual(values=mycolors, guide_legend(title="Interface", reverse=TRUE))+
  coord_flip()+
  stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% mutate(question=factor(question, levels=myquestions, labels=question_labels), p.adj=round(p.adj, 3), y.position=1.9) %>% filter(question != "Agency", question != "Satisfaction"), x="group1", label = "p.adj.signif", step.increase=.1, size=5)+#y.position=statistic
  scale_y_continuous(breaks=c(-2:3), limits=(c(-2,2)))+#labels = c(-2,-1,0,1,2,3))+
  theme(legend.position = "left", axis.text.y = element_blank(), axis.line.y=element_blank(), axis.ticks.y=element_blank(), strip.text.y = element_text(angle=0))+
  geom_hline(aes(yintercept = 0), linetype=2)+
  labs(title="Subjective Question Scores", y="Mean Likert-scale Rating", x=NULL)+
  guides(fill = guide_legend(reverse = TRUE), color=guide_legend(reverse=TRUE))+
  facet_grid(question ~ .)
ggsave("subjective_questions_new_point.jpg")



```

### Raincloud plots
Dot plots, density distribution, means and CI's with a middle score indicated by a dotted line.
Note: Using the R commind "adjust=" to smooth density plots (otherwise they would show divets in between points on the Likert scale). Adjustment is set by "mysmoothing" variable near the top of this code block.

```{r subjective_plots_clouds, eval=FALSE}

# plot configs (local)
star_size=6


# SUBJECTIVE QUESTIONS
# question_text <-
#   c("Q1 - Comfortable","Q2 - Precise","Q3 - Intuitive",
#   "Q4 - Tiring for the hand (-)", "Q5 - Difficulty gripping (-)",
#   "Q6 - Difficulty releasing (-)", "Q7 - Gripping and releasing were natural",
#   "Q8 - Would recommend to friends")

# Comfortable
temp_plot_data <- subject_data_all_long %>%
  group_by(Interface)%>%
  get_summary_stats(Q_1_Score)

comfortable_raincloud <- ggplot(subject_data_all_long, aes(x=Interface,y=Q_1_Score, fill=Interface, color=Interface), colour="black")+
  geom_hline(aes(yintercept=3), linetype=3, alpha=.5)+
  geom_violinhalf(position = position_nudge(x = 0, y = 0), alpha=myalpha, adjust=mysmoothing)+
  #geom_point(position = position_jitter(width = .15, height=.08), size = .25)+
  geom_dotplot(binaxis = "y", binwidth = 1, position=position_nudge(x=-.05), stackdir="down", dotsize=0.06, stackratio=1.4)+
  geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(0), colour = "BLACK", size=2)+
  geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean,2)), position = position_nudge(.2), alpha=1, colour = "white")+
  geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(0), colour = "BLACK", width = 0.05, size = 1)+
  ylab('Response (1-5)')+xlab(NULL)+theme_cowplot()+guides(fill = FALSE, colour = FALSE)+
  scale_color_manual(values=c(mycolors))+ #scale_colour_brewer(palette = "Set2")+
  scale_fill_manual(values=c(mycolors))+ #scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(breaks=c(1:5), labels=c("1","2","3","4","5"))+
  #coord_flip()+
  #stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% filter(question == "comfortable", p.adj < 0.05), label = "p.adj.signif", step.increase=.1, y.position=5.5, size=4, position=position_nudge(0))+
  theme(plot.title = element_text(size=title_size*.75), axis.title = element_text(size=axis_text_size))+
  labs(title="Comfortable")
comfortable_raincloud
ggsave("likert_comfortable.jpg")

# Q2 - Precise
temp_plot_data <- subject_data_all_long %>%
  group_by(Interface)%>% 
  get_summary_stats(Q_2_Score)

precise_raincloud <- ggplot(subject_data_all_long, aes(x=Interface,y=Q_2_Score, fill=Interface, color=Interface), colour="black")+
  geom_hline(aes(yintercept=3), linetype=3, alpha=.5)+
  geom_flat_violin(position = position_nudge(x = 0, y = 0), alpha=myalpha, adjust=mysmoothing)+
  #geom_point(position = position_jitter(width = .15, height=.08), size = .25)+
  geom_dotplot(binaxis = "y", binwidth = 1, position=position_nudge(x=-.05), stackdir="down", dotsize=0.06, stackratio=1.4)+
  geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(0), colour = "BLACK", size=2)+
  geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean,2)), position = position_nudge(.2), alpha=1, colour = "white")+
  geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(0), colour = "BLACK", width = 0.05, size = 1)+
  ylab('Response (1-5)')+xlab(NULL)+theme_cowplot()+guides(fill = FALSE, colour = FALSE)+
  scale_color_manual(values=c(mycolors))+ #scale_colour_brewer(palette = "Set2")+
  scale_fill_manual(values=c(mycolors))+ #scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(breaks=c(1:5), labels=c("1","2","3","4","5"))+
  #coord_flip()+
  stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% filter(question == "precise", p.adj < 0.05), label = "p.adj.signif", step.increase=.1, y.position=5.5, size=4, position=position_nudge(0))+
  theme(plot.title = element_text(size=title_size*.75), axis.title = element_text(size=axis_text_size))+
  labs(title="Precise")
precise_raincloud
ggsave("likert_precise.jpg")


# Q3 - Intuitive
temp_plot_data <- subject_data_all_long %>%
  group_by(Interface)%>% 
  get_summary_stats(Q_3_Score)

intuitive_raincloud <- ggplot(subject_data_all_long, aes(x=Interface,y=Q_3_Score, fill=Interface, color=Interface), colour="black")+
  geom_hline(aes(yintercept=3), linetype=3, alpha=.5)+
  geom_flat_violin(position = position_nudge(x = 0, y = 0), alpha=myalpha, adjust=mysmoothing)+
  #geom_point(position = position_jitter(width = .15, height=.08), size = .25)+
  geom_dotplot(binaxis = "y", binwidth = 1, position=position_nudge(x=-.05), stackdir="down", dotsize=0.06, stackratio=1.4)+
  geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(0), colour = "BLACK", size=2)+
  geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean,2)), position = position_nudge(.2), alpha=1, colour = "white")+
  geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(0), colour = "BLACK", width = 0.05, size = 1)+
  ylab('Response (1-5)')+xlab(NULL)+theme_cowplot()+guides(fill = FALSE, colour = FALSE)+
  scale_color_manual(values=c(mycolors))+ #scale_colour_brewer(palette = "Set2")+
  scale_fill_manual(values=c(mycolors))+ #scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(breaks=c(1:5), limits=c(1,5), labels=c("1","2","3","4","5"))+
  #coord_flip()+
  #stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% filter(question == "intuitive", p.adj < 0.05), label = "p.adj.signif", step.increase=.1, y.position=5.5, size=4, position=position_nudge(0))+
  theme(plot.title = element_text(size=title_size*.75), axis.title = element_text(size=axis_text_size))+
  labs(title="Intuitive")
intuitive_raincloud
ggsave("likert_intuitive.jpg")

# Q4 - tiring for hand
temp_plot_data <- subject_data_all_long %>%
  group_by(Interface)%>% 
  get_summary_stats(Q_4_Score)

tiring_raincloud <- ggplot(subject_data_all_long, aes(x=Interface,y=Q_4_Score, fill=Interface, color=Interface), colour="black")+
  geom_hline(aes(yintercept=3), linetype=3, alpha=.5)+
  geom_flat_violin(position = position_nudge(x = 0, y = 0), alpha=myalpha, adjust=mysmoothing)+
  #geom_point(position = position_jitter(width = .15, height=.08), size = .25)+
  geom_dotplot(binaxis = "y", binwidth = 1, position=position_nudge(x=-.05), stackdir="down", dotsize=0.06, stackratio=1.4)+
  geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(0), colour = "BLACK", size=2)+
  geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean,2)), position = position_nudge(.2), alpha=1, colour = "white")+
  geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(0), colour = "BLACK", width = 0.05, size = 1)+
  ylab('Response (5 = least tiring)')+xlab(NULL)+theme_cowplot()+guides(fill = FALSE, colour = FALSE)+
  scale_color_manual(values=c(mycolors))+ #scale_colour_brewer(palette = "Set2")+
  scale_fill_manual(values=c(mycolors))+ #scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(breaks=c(1:5), labels=c("1","2","3","4","5"))+
  #coord_flip()+
  #stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% filter(question == "tiring", p.adj < 0.05), label = "p.adj.signif", step.increase=.1, y.position=5.5, size=4, position=position_nudge(0))+
  theme(plot.title = element_text(size=title_size*.75), axis.title = element_text(size=axis_text_size))+
  labs(title="Tiring for the hand")
tiring_raincloud
ggsave("likert_tiring.jpg")

# Q5 - gripping
temp_plot_data <- subject_data_all_long %>%
  group_by(Interface)%>% 
  get_summary_stats(Q_5_Score)

gripping_raincloud <- ggplot(subject_data_all_long, aes(x=Interface,y=Q_5_Score, fill=Interface, color=Interface), colour="black")+
  geom_hline(aes(yintercept=3), linetype=3, alpha=.5)+
  geom_flat_violin(position = position_nudge(x = 0, y = 0), alpha=myalpha, adjust=mysmoothing)+
  #geom_point(position = position_jitter(width = .15, height=.08), size = .25)+
  geom_dotplot(binaxis = "y", binwidth = 1, position=position_nudge(x=-.05), stackdir="down", dotsize=0.06, stackratio=1.4)+
  geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(0), colour = "BLACK", size=2)+
  geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean,2)), position = position_nudge(.2), alpha=1, colour = "white")+
  geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(0), colour = "BLACK", width = 0.05, size = 1)+
  ylab('Response (1-5)')+xlab(NULL)+theme_cowplot()+guides(fill = FALSE, colour = FALSE)+
  scale_color_manual(values=c(mycolors))+ #scale_colour_brewer(palette = "Set2")+
  scale_fill_manual(values=c(mycolors))+ #scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(breaks=c(1:5), labels=c("1","2","3","4","5"))+
  #coord_flip()+
  stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% filter(question == "gripping", p.adj < 0.05), label = "p.adj.signif", step.increase=.1, y.position=5.5, size=4, position=position_nudge(0))+
  theme(plot.title = element_text(size=title_size*.75), axis.title = element_text(size=axis_text_size))+
  labs(title="Gripping")
gripping_raincloud
ggsave("likert_gripping.jpg")

# Q6 - difficulty releasing
temp_plot_data <- subject_data_all_long %>%
  group_by(Interface)%>% 
  get_summary_stats(Q_6_Score)

releasing_raincloud <- ggplot(subject_data_all_long, aes(x=Interface,y=Q_6_Score, fill=Interface, color=Interface), colour="black")+
  geom_hline(aes(yintercept=3), linetype=3, alpha=.5)+
  geom_flat_violin(position = position_nudge(x = 0, y = 0), alpha=myalpha, adjust=mysmoothing)+
  #geom_point(position = position_jitter(width = .15, height=.08), size = .25)+
  geom_dotplot(binaxis = "y", binwidth = 1, position=position_nudge(x=-.05), stackdir="down", dotsize=0.06, stackratio=1.4)+
  geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(0), colour = "BLACK", size=2)+
  geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean,2)), position = position_nudge(.2), alpha=1, colour = "white")+
  geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(0), colour = "BLACK", width = 0.05, size = 1)+
  ylab('Response (1-5)')+xlab(NULL)+theme_cowplot()+guides(fill = FALSE, colour = FALSE)+
  scale_color_manual(values=c(mycolors))+ #scale_colour_brewer(palette = "Set2")+
  scale_fill_manual(values=c(mycolors))+ #scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(breaks=c(1:5), labels=c("1","2","3","4","5"))+
  #coord_flip()+
  stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% filter(question == "releasing", p.adj < 0.05), label = "p.adj.signif", step.increase=.1, y.position=5.5, size=4, position=position_nudge(0))+
  theme(plot.title = element_text(size=title_size*.75), axis.title = element_text(size=axis_text_size))+
  labs(title="Releasing")
releasing_raincloud
ggsave("likert_releasing.jpg")

# Q7 - grip and release was natural
temp_plot_data <- subject_data_all_long %>%
  group_by(Interface)%>% 
  get_summary_stats(Q_7_Score)

natural_raincloud <- ggplot(subject_data_all_long, aes(x=Interface,y=Q_7_Score, fill=Interface, color=Interface), colour="black")+
  geom_hline(aes(yintercept=3), linetype=3, alpha=.5)+
  geom_flat_violin(position = position_nudge(x = 0, y = 0), alpha=myalpha, adjust=mysmoothing)+
  #geom_point(position = position_jitter(width = .15, height=.08), size = .25)+
  geom_dotplot(binaxis = "y", binwidth = 1, position=position_nudge(x=-.05), stackdir="down", dotsize=0.06, stackratio=1.4)+
  geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(0), colour = "BLACK", size=2)+
  geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean,2)), position = position_nudge(.2), alpha=1, colour = "white")+
  geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(0), colour = "BLACK", width = 0.05, size = 1)+
  ylab('Response (1-5)')+xlab(NULL)+theme_cowplot()+guides(fill = FALSE, colour = FALSE)+
  scale_color_manual(values=c(mycolors))+ #scale_colour_brewer(palette = "Set2")+
  scale_fill_manual(values=c(mycolors))+ #scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(breaks=c(1:5), labels=c("1","2","3","4","5"))+
  #coord_flip()+
  #stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% filter(question == "natural", p.adj < 0.05), label = "p.adj.signif", step.increase=.1, y.position=5.5, size=4, position=position_nudge(0))+
  theme(plot.title = element_text(size=title_size*.75), axis.title = element_text(size=axis_text_size))+
  labs(title="Natural")
natural_raincloud
ggsave("likert_natural.jpg")

# Q8 - would recommend to friends
temp_plot_data <- subject_data_all_long %>%
  group_by(Interface)%>% 
  get_summary_stats(Q_8_Score)

recommend_raincloud <- ggplot(subject_data_all_long, aes(x=Interface,y=Q_8_Score, fill=Interface, color=Interface), colour="black")+
  #geom_point(position = position_jitter(width = .15, height=.08), size = .25)+
  geom_hline(aes(yintercept=3), linetype=3, alpha=.5)+
  geom_flat_violin(position = position_nudge(x = 0, y = 0), alpha=myalpha, adjust=mysmoothing)+
  geom_dotplot(binaxis = "y", binwidth = 1, position=position_nudge(x=-.05), stackdir="down", dotsize=0.06, stackratio=1.4)+
  geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(0), colour = "BLACK", size=2)+
  geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean,2)), position = position_nudge(.2), alpha=1, colour = "white")+
  geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(0), colour = "BLACK", width = 0.05, size = 1)+
  ylab('Response (1-5)')+xlab(NULL)+theme_cowplot()+guides(fill = FALSE, colour = FALSE)+
  scale_color_manual(values=c(mycolors))+ #scale_colour_brewer(palette = "Set2")+
  scale_fill_manual(values=c(mycolors))+ #scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(breaks=c(1:5), labels=c("1","2","3","4","5"))+
  #coord_flip()+
  #stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% filter(question == "recommend", p.adj < 0.05), label = "p.adj.signif", step.increase=.1, y.position=5.5, size=4, position=position_nudge(0))+
  theme(plot.title = element_text(size=title_size*.75), axis.title = element_text(size=axis_text_size))+
  labs(title="Recommend")
recommend_raincloud
ggsave("likert_recommend.jpg")

# agency
temp_plot_data <- subject_data_all_long %>%
  group_by(Interface) %>% 
  get_summary_stats(agency)

agency_raincloud <- ggplot(subject_data_all_long, aes(x=Interface,y=agency, fill=Interface, color=Interface), colour="black")+
  geom_hline(aes(yintercept=4), linetype=3, alpha=.5)+
  geom_flat_violin(position = position_nudge(x = 0, y = 0), alpha=myalpha, adjust=mysmoothing)+
  #geom_point(position = position_jitter(width = .15, height=.08), size = .25)+
  geom_dotplot(binaxis = "y", binwidth = 1, position=position_nudge(x=-.05), stackdir="down", dotsize=0.06, stackratio=1.4)+
  geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(0), colour = "BLACK", size=2)+
  geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean,2)), position = position_nudge(.2), alpha=1, colour = "white")+
  geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(0), colour = "BLACK", width = 0.05, size = 1)+
  ylab('Response (1-7)')+xlab(NULL)+theme_cowplot()+guides(fill = FALSE, colour = FALSE)+
  scale_color_manual(values=c(mycolors))+ #scale_colour_brewer(palette = "Set2")+
  scale_fill_manual(values=c(mycolors))+ #scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(breaks=c(1:7), labels=c("1","2","3","4","5","6","7"))+
  #coord_flip()+
  #stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% filter(question == "agency", p.adj < 0.05), label = "p.adj.signif", step.increase=.1, y.position=7, size=star_size, position=position_nudge(0))+
  theme(plot.title = element_text(size=title_size*.75), axis.title = element_text(size=axis_text_size))+ #, axis.text = element_text(size=axis_text_size-1))+
  labs(title="Agency")
agency_raincloud
ggsave(file="likert_agency.jpg", width=9, height=6)

# overall satisfaction
temp_plot_data <- subject_data_all_long %>%
  group_by(Interface)%>% 
  get_summary_stats(satisfaction)

satisfaction_raincloud <- ggplot(subject_data_all_long, aes(x=Interface,y=satisfaction, fill=Interface, color=Interface), colour="black")+
  geom_hline(aes(yintercept=4), linetype=3, alpha=.5)+
  geom_flat_violin(position = position_nudge(x = 0, y = 0), alpha=.4, adjust=1.5)+
  #geom_point(position = position_jitter(width = .15, height=.08), size = .25)+
  geom_dotplot(binaxis = "y", binwidth = 1, position=position_nudge(x=-.05), stackdir="down", dotsize=0.06, stackratio=1.4)+
  geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(0), colour = "BLACK", size=2)+
  geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean,2)), position = position_nudge(.2), alpha=1, colour = "white")+
  geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(0), colour = "BLACK", width = 0.05, size = 1)+
  ylab('Response (1-7)')+xlab(NULL)+theme_cowplot()+guides(fill = FALSE, colour = FALSE)+
  scale_color_manual(values=c(mycolors))+ #scale_colour_brewer(palette = "Set2")+
  scale_fill_manual(values=c(mycolors))+ #scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(breaks=c(1:7), limits=c(1,8.5), labels=c("1","2","3","4","5","6","7"))+
  #coord_flip()+
  #stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% filter(question == "satisfaction", p.adj < 0.05), label = "p.adj.signif", step.increase=.1, y.position=7.5, size=4, position=position_nudge(0))+
  theme(plot.title = element_text(size=title_size*.75), axis.title = element_text(size=axis_text_size))+
  labs(title="Overall satisfaction")
satisfaction_raincloud
#ggsave(raincloud_satisfaction, file="raincloud_satisfaction.jpg")
ggsave("likert_satisfaction.jpg")

# preferred condition (code is in an earlier section)
preferred_plot
ggsave("preferred.jpg")


# all
plot_grid(comfortable_raincloud, tiring_raincloud, ncol=1, labels=c("A","B"))
ggsave("likert_plots1.jpg", width=8, height=8)
plot_grid(precise_raincloud, gripping_raincloud, releasing_raincloud, ncol=1, labels=c("C","D","E"))
ggsave("likert_plots2.jpg", width=8, height=12)
plot_grid(intuitive_raincloud, natural_raincloud, agency_raincloud, ncol=1, labels=c("F","G","H"))
ggsave("likert_plots3.jpg", width=8, height=12)
plot_grid(satisfaction_raincloud, recommend_raincloud, preferred_plot, ncol = 1, labels=c("I","J","K"))
ggsave("likert_plots4.jpg", width=8, height=12)

plot_grid(intuitive_raincloud, natural_raincloud, agency_raincloud, ncol=1, labels=c("A","B","C"))
ggsave("likert_naturalness_main.jpg", width=8, height=12)

```


#### Difference Scores & Plots

```{r subjective_diff_scores, eval=FALSE}

myquestions = c("satisfaction", "recommend", "agency", "natural", "intuitive", "releasing",  "gripping", "precise", "tiring", "comfortable")


#plot difference scores

# compile difference scores
diff_scores <- subject_data_all_long %>% group_by(id) %>% select(id, Interface, Q_1_Score) %>% spread(Interface, Q_1_Score) %>% transmute(vs_Leap=HHI_Leap-B_Leap, vs_Oculus=HHI_Leap-Oculus) %>% gather(Interface, diff_score, 2:3) %>% rename(comfortable=diff_score) %>% 
  left_join(subject_data_all_long %>% group_by(id) %>% select(id, Interface, Q_2_Score) %>% spread(Interface, Q_2_Score) %>% transmute(vs_Leap=HHI_Leap-B_Leap, vs_Oculus=HHI_Leap-Oculus) %>% gather(Interface, diff_score, 2:3) %>% rename(precise=diff_score)) %>% 
  left_join(subject_data_all_long %>% group_by(id) %>% select(id, Interface, Q_3_Score) %>% spread(Interface, Q_3_Score) %>% transmute(vs_Leap=HHI_Leap-B_Leap, vs_Oculus=HHI_Leap-Oculus) %>% gather(Interface, diff_score, 2:3) %>% rename(intuitive=diff_score)) %>%
  left_join(subject_data_all_long %>% group_by(id) %>% select(id, Interface, Q_4_Score) %>% spread(Interface, Q_4_Score) %>% transmute(vs_Leap=HHI_Leap-B_Leap, vs_Oculus=HHI_Leap-Oculus) %>% gather(Interface, diff_score, 2:3) %>% rename(tiring=diff_score)) %>% 
  left_join(subject_data_all_long %>% group_by(id) %>% select(id, Interface, Q_5_Score) %>% spread(Interface, Q_5_Score) %>% transmute(vs_Leap=HHI_Leap-B_Leap, vs_Oculus=HHI_Leap-Oculus) %>% gather(Interface, diff_score, 2:3) %>% rename(gripping=diff_score)) %>%
  left_join(subject_data_all_long %>% group_by(id) %>% select(id, Interface, Q_6_Score) %>% spread(Interface, Q_6_Score) %>% transmute(vs_Leap=HHI_Leap-B_Leap, vs_Oculus=HHI_Leap-Oculus) %>% gather(Interface, diff_score, 2:3) %>% rename(releasing=diff_score)) %>%
  left_join(subject_data_all_long %>% group_by(id) %>% select(id, Interface, Q_7_Score) %>% spread(Interface, Q_7_Score) %>% transmute(vs_Leap=HHI_Leap-B_Leap, vs_Oculus=HHI_Leap-Oculus) %>% gather(Interface, diff_score, 2:3) %>% rename(natural=diff_score)) %>%
  left_join(subject_data_all_long %>% group_by(id) %>% select(id, Interface, Q_8_Score) %>% spread(Interface, Q_8_Score) %>% transmute(vs_Leap=HHI_Leap-B_Leap, vs_Oculus=HHI_Leap-Oculus) %>% gather(Interface, diff_score, 2:3) %>% rename(recommend=diff_score)) %>%
  left_join(subject_data_all_long %>% group_by(id) %>% select(id, Interface, agency) %>% spread(Interface, agency) %>% transmute(vs_Leap=HHI_Leap-B_Leap, vs_Oculus=HHI_Leap-Oculus) %>% gather(Interface, diff_score, 2:3) %>% rename(agency=diff_score)) %>%
  left_join(subject_data_all_long %>% group_by(id) %>% select(id, Interface, satisfaction) %>% spread(Interface, satisfaction) %>% transmute(vs_Leap=HHI_Leap-B_Leap, vs_Oculus=HHI_Leap-Oculus) %>% gather(Interface, diff_score, 2:3) %>% rename(satisfaction=diff_score))

# plots
# generate descriptives; add in t-test results

temp_plot_data <- diff_scores %>% group_by(Interface) %>% select(-id, -Interface) %>% get_summary_stats() %>% rename(question=variable)

diff_scores_vs_leap <- temp_plot_data %>% filter(Interface=="vs_Leap") %>% left_join(t.tests.likert.all.vs.hhi %>% filter(group2=="B_Leap")%>%select(question, p.adj, test), by=c("question")) %>%
  mutate(question = factor(question, levels=myquestions))

# reorder question labels

diff_scores_vs_oculus <- temp_plot_data %>% filter(Interface=="vs_Oculus") %>% left_join(t.tests.likert.all.vs.hhi %>% filter(group2=="Oculus") %>% select(question, p.adj, test), by=c("question")) %>%
  mutate(question = factor(question, levels=myquestions))

likert_lab_size = 25
likert_title_size = 30
likert_interface_lab = 12
pointrange_size = 1.2
star_size=8


# plot difference scores vs. B_Leap -- note stat_pvalue_manual
ggplot(diff_scores_vs_leap %>% filter(question != "agency", question != "satisfaction"), aes(question, mean, color=p.adj<0.05))+
  geom_pointrange(aes(ymax=mean+1.96*se, ymin=mean-1.96*se), size=pointrange_size)+
  theme_cowplot()+
  theme(axis.text = element_text(size=likert_lab_size), axis.title = element_text(size=likert_lab_size), plot.title = element_text(size=likert_title_size))+
  labs(title="Individual subjective questions (5-point)", y="Mean difference score", x="Question")+
  coord_flip()+guides(color=FALSE, fill=FALSE)+
  scale_y_continuous(limits=c(-2,2))+
  scale_color_manual(values=c("black", "orange"))+
  #scale_color_brewer(palette="Paired")+
  #stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% filter(question != "agency", question != "satisfaction", group2=="B_Leap"), x="question", label = "p.adj.signif", step.increase=.1, y.position=-2, size=star_size)+
  geom_hline(yintercept=0, linetype=2)+
  geom_label(aes(x=8.3, y=-1, label="B_Leap"), fill=mycolors[1], alpha=.4, color="white", size=likert_interface_lab)+
  geom_label(aes(x=8.3, y=1.2, label="HHI Leap"), fill=mycolors[2], alpha=.4,color="white", size=likert_interface_lab)
#ggsave("diff_scores_vs_leap.jpg", width=12, height =10)

# plot all difference scores vs. B_Leap
  x_guide = 10.35
ggplot(diff_scores_vs_leap, aes(question, mean))+
  geom_pointrange(aes(ymax=mean+1.96*se, ymin=mean-1.96*se), size=pointrange_size)+
  theme_cowplot()+
  theme(axis.text = element_text(size=likert_lab_size), axis.title = element_text(size=likert_lab_size), plot.title = element_text(size=likert_title_size))+
  labs(title="Individual subjective questions", y="Mean difference score", x="Question")+
  coord_flip()+guides(color=FALSE, fill=FALSE)+
  scale_y_continuous(limits=c(-2,2))+
  scale_color_manual(values=c("black", "orange"))+
  #scale_color_brewer(palette="Paired")+
  stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% filter (group2=="B_Leap"), x="question", label = "p.adj.signif", y.position=-2, size=star_size)+
  geom_hline(yintercept=0, linetype=2)+
  geom_label(aes(x=x_guide, y=-1, label="B_Leap"), fill=mycolors[1], alpha=.4, color="white", size=likert_interface_lab)+
  geom_label(aes(x=x_guide, y=1.2, label="HHI Leap"), fill=mycolors[2], alpha=.4,color="white", size=likert_interface_lab)
ggsave("diff_scores_vs_leap.jpg", width=12, height =10)


# plot difference scores vs. Oculus
ggplot(diff_scores_vs_oculus %>% filter(question != "agency", question != "satisfaction"), aes(question, mean))+
  geom_pointrange(aes(ymax=mean+1.96*se, ymin=mean-1.96*se), size=pointrange_size)+
  #geom_pointrange(aes(ymax=mean+1.96*se, ymin=mean-1.96*se, color=p.adj<0.05), size=pointrange_size)+
  theme_cowplot()+
  theme(axis.text = element_text(size=likert_lab_size), axis.title = element_text(size=likert_lab_size), plot.title = element_text(size=likert_title_size))+
  labs(title="Individual subjective questions (5-point)", y="Mean difference score", x="Question")+
  coord_flip(ylim=c(-2.5,2))+
  guides(color=FALSE)+
  scale_color_manual(values=c("black", "blue"))+
  scale_fill_manual(values=c("green3","blue"))+
  #scale_color_brewer(palette="Paired")+
  stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% filter(question != "agency", question != "satisfaction", group2=="Oculus"), x="question", label = "p.adj.signif", step.increase=.1, y.position=-2.5, size=star_size)+
  geom_hline(yintercept=0, linetype=2)+
  geom_label(aes(x=8.3, y=-1.5, label="Oculus"), fill=mycolors[3], alpha=.4, color="white",size=likert_interface_lab)+
  geom_label(aes(x=8.3, y=1.2, label="HHI Leap"), fill=mycolors[2], alpha=.4, color="white",size=likert_interface_lab)#+scale_y_reverse()
#ggsave("diff_scores_vs_oculus.jpg", width=12, height = 10)

# plot all difference scores vs. Oculus
    x_guide = 10.35
ggplot(diff_scores_vs_oculus, aes(question, mean))+
  geom_pointrange(aes(ymax=mean+1.96*se, ymin=mean-1.96*se), size=pointrange_size)+
  theme_cowplot()+
  theme(axis.text = element_text(size=likert_lab_size), axis.title = element_text(size=likert_lab_size), plot.title = element_text(size=likert_title_size))+
  labs(title="Individual subjective questions", y="Mean difference score", x="Question")+
  coord_flip(ylim=c(-2.5,2))+
  guides(color=FALSE)+
  stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% filter(group2=="Oculus"), x="question", label = "p.adj.signif", y.position=-2.5, size=star_size, step.increase = 0)+
  geom_hline(yintercept=0, linetype=2)+
  geom_label(aes(x=x_guide, y=-1.5, label="Oculus"), fill=mycolors[3], alpha=.4, color="white",size=likert_interface_lab)+
  geom_label(aes(x=x_guide, y=1.2, label="HHI Leap"), fill=mycolors[2], alpha=.4, color="white",size=likert_interface_lab)#+scale_y_reverse()
ggsave("diff_scores_vs_oculus.jpg", width=12, height = 10)


# agency and satisfaction vs leap
ggplot(diff_scores_vs_leap %>% filter(question=="agency" | question=="satisfaction"), aes(question, mean))+
  geom_pointrange(aes(ymax=mean+1.96*se, ymin=mean-1.96*se), size = pointrange_size)+
  theme_cowplot()+
  theme(axis.text = element_text(size=likert_lab_size), plot.title = element_text(size=likert_title_size), axis.title = element_text(size=likert_lab_size))+
  labs(title="Individual subjective questions (7-point)", y="Mean difference score", x="Question")+coord_flip()+guides(color=FALSE, fill=FALSE)+
  scale_color_manual(values=c("black", "orange"))+
  scale_y_continuous(limits=c(-2,2))+
  #scale_color_brewer(palette="Paired")+
  stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% filter(question=="agency" | question=="satisfaction", group2=="B_Leap"), x="question", label = "p.adj.signif", step.increase=.1, y.position=-2, size=star_size)+
  geom_hline(yintercept=0, linetype=2)+
  geom_label(aes(x=2.4, y=-.9, label="B_Leap"), fill=mycolors[1], alpha=.7, color="white", size=likert_interface_lab)+
  geom_label(aes(x=2.4, y=.8, label="HHI Leap"), fill=mycolors[2], alpha=.7, color="white",size=likert_interface_lab)
#ggsave("diff_scores_agency_satisfaction_vs_leap.jpg", width=12, height=4.5)


# agency and satisfaction vs oculus
ggplot(diff_scores_vs_oculus %>% filter(question == "agency" | question == "satisfaction"), aes(question, mean))+
  #geom_boxplot(outlier.size = .25, outlier.alpha = .6)+
  geom_pointrange(aes(color=p.adj<0.05, ymax=mean+1.96*se, ymin=mean-1.96*se), size=pointrange_size)+
  #geom_violinhalf(data=likert_scores %>% filter(question == "agency" | question == "satisfaction", Interface!="B_Leap") %>% mutate(score=score-4), aes(question, score, fill=Interface))+
   #geom_flat_violin(data=diff_scores %>% filter(Interface=="vs_Oculus") %>% gather(question, score, c(11,12)) %>% select(question, score), aes(question, score), position=position_nudge(x=.1), fill="transparent")+
  theme_cowplot()+
  theme(axis.text = element_text(size=likert_lab_size), plot.title = element_text(size=likert_title_size), axis.title = element_text(size=likert_lab_size))+
  labs(title="Individual subjective questions (7-point)", y="Mean difference score", x="Question")+coord_flip(ylim=c(-2,2))+
  guides(color=FALSE, fill=FALSE)+
  scale_color_manual(values=c("black", "blue"))+#scale_fill_manual(values=c("grey","lightblue"))+
  #scale_fill_brewer(palette="Set2")+
  stat_pvalue_manual(data=t.tests.likert.all.vs.hhi %>% filter(question=="agency" | question=="satisfaction", group2=="Oculus"), x="question", label = "p.adj.signif", step.increase=.1, y.position=-2, size=star_size)+
  geom_hline(yintercept=0, linetype=2)+
  geom_label(aes(x=2.4, y=-.9, label="Oculus"), fill=mycolors[3], alpha=.7, color="white",size=likert_interface_lab)+
  scale_y_continuous(limits=c(-2,2))+
  geom_label(aes(x=2.4, y=.9, label="HHI Leap"), fill=mycolors[2], alpha=.7, color="white", size=likert_interface_lab)
#ggsave("diff_scores_agency_satisfaction_vs_oculus.jpg", width=12, height =4.5)



```

### SUS

Statistical test: Looks like the SUS scores are close enough to a normal distribution so that the means and medians are not radically different. While the Oculus data fails the shapiro test (probably due to its extreme outlier) and the data is generally very skewed, the mean and median are nearly the same. Therefore, we'll use the mean as the measure of central tendency for this data.

The scores are normally distributed. Therefore, even though the dependent variable is not continuous, a T-Test seems appropriate. T-Tests have been found to be more robust than Wilcox tests, even when some assumptions are violated (Norman, 2010; Meed et al., 2010).

We can use the guidelines offered by Bangor, Kortum and Miller (2009):
<50: Not acceptable  
5070: Marginal
>70: Acceptable

4 out of 32 people rated the HHI Leap as "not acceptable" on the SUS. Only 1 out of 32 did this for the Leap. How do I tell if this is statistically significant?

```{r SUS}
#SUS score means and medians
temp_plot_data <- subject_data_all_long %>%
  group_by(Interface) %>%
  summarise(mean=mean(SUS), sd=sd(SUS), se=sd/sqrt(sample_size), median=median(SUS))

stat.test <- subject_data_all_long %>%
  ungroup(.) %>%
  t_test(SUS ~ Interface, paired=TRUE, comparisons=list(c("B_Leap","HHI_Leap"),c("HHI_Leap","Oculus"))) %>%
  adjust_pvalue() %>% mutate(Interface=group1) %>%
  left_join(subject_data_all_long %>% ungroup(.) %>% cohens_d(SUS ~ Interface, paired=TRUE) %>% select(group1, group2, effsize, magnitude), by=c("group1", "group2"))
stat.test

anova.test <- 
  anova_summary(effect.size="pes",aov(SUS ~ Interface + Error(id/Interface), data=subject_data_all_long))
anova.test

# for export
ttest.SUS <- stat.test %>% select(-Interface)
anova.SUS <- anova.test
descriptives.sus <- subject_data_all_long %>% group_by(Interface) %>% get_summary_stats(SUS, type = "common") %>% select(Interface, variable, n, mean, sd, min, max, iqr)


# SUS scoring bin
SUS_scoring_bins <- subject_data_all_long %>%
  filter(SUS<50) %>% mutate(SUS_bin="Not acceptable") %>%
  bind_rows(subject_data_all_long %>%
              filter(SUS>=50 & SUS < 70) %>% mutate(SUS_bin="Marginal")) %>%
  bind_rows(subject_data_all_long %>%
             filter(SUS>=70) %>% mutate(SUS_bin="Acceptable")) %>%
  select(id, Interface, SUS, SUS_bin) %>%
  group_by(Interface) %>%
  count(SUS_bin) %>% mutate(SUS_bin_ratio=n/sample_size)
  # add plot position
  SUS_scoring_bins <- SUS_scoring_bins %>%
  filter(SUS_bin=="Not acceptable") %>% mutate(plot_pos=40) %>%
  bind_rows(SUS_scoring_bins %>% filter(SUS_bin=="Marginal") %>% mutate(plot_pos=60)) %>%
    bind_rows(SUS_scoring_bins %>% filter(SUS_bin=="Acceptable") %>% mutate(plot_pos=85))

# plot
SUS_raincloud <- ggplot(subject_data_all_long, aes(x=Interface, y=SUS, fill=Interface, color=Interface))+
  geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=myalpha,adjust=mysmoothing)+
  geom_dotplot(binaxis = "y", stackratio=1.4, binwidth = 1, position=position_nudge(x=.2), stackdir="down", dotsize=2, alpha=.8)+
  scale_color_manual(values=mycolors)+#scale_color_brewer(palette="Set2")+
  scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2")+#coord_flip()+
  geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK", size=4)+
  geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=paste0("M = ",round(mean,1))), position = position_nudge(x=.5, y=-2), alpha=1, colour = "white", size=9, )+ # mean label
  geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.06, size=1.5)+
  ylab('SUS score')+xlab('')+theme_cowplot()+guides(colour = FALSE, label = FALSE, text=FALSE)+
  labs(title="SUS")+
  geom_hline(aes(yintercept=50), linetype=2, alpha=.5)+geom_hline(aes(yintercept=70), linetype=2, alpha=.5)+
  geom_label(data=SUS_scoring_bins %>% filter(Interface=="B_Leap"), aes(x=.7, y=plot_pos, label=SUS_bin), color="black", fill="white", alpha=1, size=9)+ # scoring bin name label
  #geom_label(data=SUS_scoring_bins, aes(x=Interface, y=plot_pos, label=n), alpha=.6, size=9, color="white")+ #scoring bin label #label=paste0(SUS_bin_percent,"%")),)+
  stat_pvalue_manual(data=stat.test %>% filter(p.adj < 0.05), xmin="group1", xmax="group2", label = "p.adj.signif", step.increase=.1, y.position=1.05*max(subject_data_all_long$SUS), position=position_nudge(.25), size=12, bracket.size=.5)+
  theme(plot.title = element_text(size=title_size*1.25), axis.title = element_text(size=axis_text_size*1.5), axis.text=element_text(size=axis_text_size*1.5), legend.position = "none")#,  axis.text.x = element_blank())

# export
SUS_raincloud
ggsave(last_plot(), filename = "SUS_plot.jpg", width=14, height=8)

# are they normally distributed?
#B_Leap: yes
shapiro <- subject_data_all_long %>% filter(Interface=="B_Leap") %>%
ungroup(.) %>%
shapiro_test(SUS)
cat("\nShapiro says Leap data are normally distributed: ", shapiro$p>.05, "\n")

#HHI_Leap: no
shapiro <- subject_data_all_long %>% filter(Interface=="HHI_Leap") %>%
ungroup(.) %>%
shapiro_test(SUS)
cat("\nShapiro says HHI data are normally distributed: ", shapiro$p>.05, "\n")

#Oculus
shapiro <- subject_data_all_long %>% filter(Interface=="Oculus") %>%
ungroup(.) %>%
shapiro_test(SUS)
cat("\nShapiro says Oculus data are normally distributed: ", shapiro$p>.05, "\n")

# check out summary stats, including skewness and kurtosis
describeBy(subject_data_all_long %>% ungroup(.) %>% select(Interface, SUS), group = "Interface")

# do Interfaces have equal variances?
levene <- subject_data_all_long %>% ungroup(.) %>%
levene_test(SUS ~ Interface, center=mean)
cat("\nLevene says data have equal variances: ", levene$p>.05, "\n")

# anova
print("ANOVA: SUS - Interface")
summary(aov(SUS ~ Interface + Error(id/Interface), data=subject_data_all_long))

anova_summary(effect.size="pes",aov(SUS ~ Interface + Error(id/Interface), data=subject_data_all_long))

# t test and wilcox
compare_means(SUS ~ Interface, data=subject_data_all_long, method = "t.test", paired = TRUE)
compare_means(SUS ~ Interface, data=subject_data_all_long, method = "wilcox", paired = TRUE)

# normality check for t test
# leap HHI vs. B_Leap
group1<-"HHI_Leap"
group2<-"B_Leap"
t_test_dataset <- subject_data_all_long %>%
  filter(Interface==group1 | Interface==group2) %>%
  select(id, Interface, SUS)
# Shapiro-Wilk normality test for the differences
t_diff_dataset <- with(t_test_dataset, 
        SUS[Interface == group1] - SUS[Interface == group2])
#hist(t_diff_dataset)
shapiro.test(t_diff_dataset)
# t test
#t.test(SUS ~ Interface, data = t_test_dataset, paired = TRUE)

# leap HHI vs. Oculus
group1<-"HHI_Leap"
group2<-"Oculus"
t_test_dataset <- subject_data_all_long %>%
  filter(Interface==group1 | Interface==group2) %>%
  select(id, Interface, SUS)
# Shapiro-Wilk normality test for the differences
t_diff_dataset <- with(t_test_dataset, 
        SUS[Interface == group1] - SUS[Interface == group2])
#hist(t_diff_dataset)
shapiro.test(t_diff_dataset)
# t test
#t.test(SUS ~ Interface, data = t_test_dataset, paired = TRUE)

# individual subject sus scores
  SUS_subject_plot <- ggplot(subject_data_all_long, aes(id, SUS, fill=Interface, color=Interface))+
    #geom_bar(stat="identity", position="dodge")+
    geom_point(aes(shape=Interface), size=3)+
    scale_fill_brewer(palette="Set2")+scale_color_brewer(palette="Set2")+theme_minimal()+
    #facet_grid(. ~ Interface)+
    ggtitle("SUS scores by subject")
#  SUS_subject_plot
  
# chi sq goodness of fit using oculus as expected counts
SUS_scoring_bins %>% arrange(Interface)
chi_counts <- SUS_scoring_bins %>% filter(Interface=="HHI_Leap")
chi_expected <- SUS_scoring_bins %>% filter(Interface=="Oculus")
chisq.test(chi_counts$n, chi_expected$SUS_bin_ratio)

# build df of mean and sd for HHI Leap
SUS_mean_sd <- #left_join(get_summary_stats(temp_df, Distance,))
  data.frame(Measure="SUS",
      HHI_Leap_Mean = mean(subject_data_all_long[which(subject_data_all_long$Interface=="HHI_Leap"),"SUS"]),
      HHI_Leap_SD = sd(subject_data_all_long[which(subject_data_all_long$Interface=="HHI_Leap"),"SUS"]),
      B_Leap_Mean = mean(subject_data_all_long[which(subject_data_all_long$Interface=="B_Leap"),"SUS"]),
      B_Leap_SD = sd(subject_data_all_long[which(subject_data_all_long$Interface=="HHI_Leap"),"SUS"]),
      Oculus_Mean = mean(subject_data_all_long[which(subject_data_all_long$Interface=="Oculus"),"SUS"]),
      Oculus_SD = sd(subject_data_all_long[which(subject_data_all_long$Interface=="Oculus"),"SUS"])) %>% mutate(Measure=as.character(Measure))

```  

### Plot compilation export

```{r main_results_subjective, eval=FALSE}

# intuitive
plot_grid(intuitive_raincloud, natural_raincloud, agency_raincloud)#, trainingtime_raincloud)
ggsave(last_plot(), filename="intuitive_plots.jpg", width=14, height=8.5)

# ease of use w/ grab and release times
#plot_grid(tiring_raincloud, gripping_raincloud, releasing_raincloud, comfortable_raincloud,  grabtime_raincloud, releasetime_Interface_raincloud)
# ggsave(last_plot(), filename="ease_of_use_plots.jpg", width=14, height=8.5)

# ease of use w / only subjective metrics
plot_grid(tiring_raincloud, gripping_raincloud, releasing_raincloud, comfortable_raincloud, SUS_raincloud)
ggsave(last_plot(), filename="ease_of_use_plots.jpg", width=14, height=8.5)

# preference
plot_grid(recommend_raincloud, satisfaction_raincloud, preferred_plot)
ggsave(last_plot(), filename="preference_plots.jpg", width=14, height=8.5)

# perception of performance
plot_grid(precise_raincloud, distance_Interface_raincloud+scale_y_reverse(),
          gripping_raincloud, grabtime_Interface_raincloud,
          releasing_raincloud, releasetime_Interface_raincloud, nrow = 3, ncol = 2)
ggsave(last_plot(), filename="perception_of_performance_plots.jpg", width=14, height=8.5)

#SUS
SUS_raincloud
ggsave(last_plot(), filename = "SUS_plot.jpg", width=14, height=8)

```


## Post-hoc exploratory

### Non-equivalence
```{r equivalence}

#TOSTpaired(32, m1, m2, sd1, sd2, r12, low_eqbound_dz, high_eqbound_dz, alpha, plot = TRUE, verbose = TRUE)

```

### Time to learn

#### Practice time

```{r practice_time, warning=FALSE}

# generate descriptives for raincloud
temp_plot_data <- subject_data_all_long %>% group_by(Interface) %>% get_summary_stats(practice_time)

stat.test.anova <- 
anova_summary(effect.size="pes",aov(practice_time ~ Interface + Error(id/Interface), data=subject_data_all_long))
stat.test.anova
#write.csv(stat.test.anova, file="dropcount_anova.csv")

stat.test.anova2 <- 
anova_summary(effect.size="pes",aov(practice_time ~ Interface + Error(id/Interface), data=subject_data_all_long%>%filter(Interface=="B_Leap"|Interface=="HHI_Leap")))
stat.test.anova2


stat.test <- subject_data_all_long %>%
  ungroup(.) %>%
  pairwise_t_test(practice_time ~ Interface, paired=TRUE, comparisons=list(c("B_Leap","HHI_Leap"),c("HHI_Leap","Oculus"))) %>%
  mutate(Interface=group1, test="T-test")
stat.test
 
# raincloud training time
trainingtime_raincloud<-ggplot(subject_data_all_long, aes(x=Interface, y=practice_time, fill=Interface, colour = Interface))+
  #geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=.7, draw_quantiles=c(.25, .75))+#,adjust =2)+
  geom_violinhalf(position = position_nudge(x = .25, y = 0), alpha=myalpha, draw_quantiles=c(.25, .75), adjust = mysmoothing)+
  geom_point(position = position_jitter(width = 0.1, height=0), size = .25)+ # the "rain"
geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean,1)), position = position_nudge(.4), alpha=1, colour = "white", size=5)+
  geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK")+
  geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
  ylab('Time (seconds)')+xlab('Interface')+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
  scale_color_manual(values=mycolors)+#scale_colour_brewer(palette = "Set2")+
  scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2", direction=1)+
  stat_pvalue_manual(data=stat.test, xmin="group1", xmax="group2", label = "p.adj", step.increase=.1, y.position=2.5*max(temp_plot_data$mean), position=position_nudge(0.25))+
  labs(title="Practice round time", caption="Means, 95% CI; Within-subjects T-test (adj.: Holms)")+
  theme(plot.title = element_text(size=title_size), axis.title = element_text(size=axis_text_size))
trainingtime_raincloud
ggsave(last_plot(), filename="trainingtime_plot.jpg", width=12, height=7)

# transform for data output
stat.test <- stat.test %>% select(-.y., -n1, -n2, -Interface)%>% mutate(p=round(p, 4), p.adj=round(p.adj, 4))

stat.test.anova <- stat.test.anova %>% mutate(p=round(p, 4))

anova.Interface.trainingtime <- stat.test.anova
ttest.Interface.trainingtime <- stat.test
descriptives.Interface.trainingtime <- subject_data_all_long %>% group_by(Interface) %>% get_summary_stats(practice_time) %>% select(Interface, variable, mean, sd, min, max, iqr)
descriptives.Interface.trainingtime

```

#### Learning Curve (slope)

```{r downsample}

# What is the lowest number of trials remaining?
min_n <- unity_data_clean %>% group_by(id, Interface) %>% summarise(n=n()) %>% ungroup %>% summarise(min(n))
min_n <- min_n[[1]]
min_n

# # Resample all to that number, but keep order of SpawnOrder
# unity_data_downsampled <- unity_data_clean %>% group_by(id, Interface) %>% sample_n(min_n) %>%
# # Change SpawnOrder to 1-20
# mutate(SpawnOrder=dense_rank(SpawnOrder))

# the problem with resampling is that it is inconsistent, you get a different statistical result each time you downsample. I need a better way.

# Instead of downsampling, just pick first min_n data points
unity_data_downsampled <- unity_data_clean %>% group_by(id, Interface) %>% 
  mutate(SpawnOrder=dense_rank(SpawnOrder)) %>% #re-number starting at 1
  filter(SpawnOrder <= min_n) %>%
  ungroup %>% mutate(Interface=as.factor(Interface))#, SpawnOrder=as.factor(SpawnOrder))

```

##### Learning curve: Accuracy

```{r learning_curve_accuracy}

# anova to see if there is an effect of SpawnOrder*Interface
#summary(aov(Distance ~ Interface*SpawnOrder + Error(id/(Interface*SpawnOrder)), data=unity_data_downsampled))

anova_summary(aov(Distance ~ Interface*SpawnOrder + Error(id/(Interface*SpawnOrder)), data=unity_data_downsampled))

# correlation test - do people get more accurate as they go?
corr_data <- unity_data_downsampled %>% select(SpawnOrder, Distance) %>% arrange(SpawnOrder)
cor.test(corr_data$SpawnOrder, corr_data$Distance)

# linear regression modeling
summary(lm(Distance ~ SpawnOrder*Interface, data=unity_data_downsampled))
#summary(glm(Distance ~ Interface + SpawnOrder + Interface:SpawnOrder, data=unity_data_downsampled))

plot_data <- unity_data_downsampled %>%
  #filter(TimeFromSpawnToGrabLoss < 15) %>% # get rid of absurd times
  group_by(Interface, SpawnOrder) %>% summarise(mean=mean(Distance))

learning_curve_accuracy <- ggplot(plot_data, aes(SpawnOrder, mean, color=Interface)) +
  geom_point()+#geom_line()+
  geom_smooth(method="lm")+
  labs(title="Learning Curve: Accuracy")
learning_curve_accuracy

sink("learning_curve_stat_output.csv")
cat("ANOVA: Learning Curve: Accuracy")
write.csv(anova_summary(aov(Distance ~ Interface*SpawnOrder + Error(id/(Interface*SpawnOrder)), data=unity_data_downsampled)))
sink()
```

##### Learning Curve: Total time
```{r learning_curve_total_time}

# anova to see if there is an effect of SpawnOrder*Interface
#summary(aov(TimeFromSpawnToGrabLoss ~ Interface*SpawnOrder + Error(id/(Interface*SpawnOrder)), data=unity_data_downsampled))

anova_summary(aov(TimeFromSpawnToGrabLoss ~ Interface*SpawnOrder + Error(id/(Interface*SpawnOrder)), data=unity_data_downsampled))

# correlation test - do times get faster as they go?
corr_data <- unity_data_downsampled %>% select(SpawnOrder, TimeFromSpawnToGrabLoss) %>% arrange(SpawnOrder)
cor.test(corr_data$SpawnOrder, corr_data$TimeFromSpawnToGrabLoss)

# linear regression modeling
summary(lm(TimeFromSpawnToGrabLoss ~ SpawnOrder*Interface, data=unity_data_downsampled))
#summary(glm(Distance ~ Interface + SpawnOrder + Interface:SpawnOrder, data=unity_data_downsampled))

plot_data <- unity_data_downsampled %>%
  #filter(TimeFromSpawnToGrabLoss < 15) %>% # get rid of absurd times
  group_by(Interface, SpawnOrder) %>% summarise(mean=mean(TimeFromSpawnToGrabLoss))

learning_curve_total_time <- ggplot(plot_data, aes(SpawnOrder, mean, color=Interface)) +
  geom_point()+#geom_line()+
  geom_smooth(method="lm")+labs(title="Learning Curve: Total Time")
learning_curve_total_time

sink("learning_curve_stat_output.csv", append = TRUE)
cat("\nANOVA: Learning Curve: Total Time")
write.csv(anova_summary(aov(TimeFromSpawnToGrabLoss ~ Interface*SpawnOrder + Error(id/(Interface*SpawnOrder)), data=unity_data_downsampled)))
sink()

#------#------#

# # Bin method: bin into 5 bins --> find means of bins --> use as data points
# unity_data_downsampled <- unity_data_clean %>% group_by(id, Interface) %>% mutate(bin=ntile(SpawnOrder, 3)) %>%
#   # transform times into mean of bins
#   group_by(id, Interface, bin) %>% summarise_at(c("TimeFromSpawnToGrabLoss", "Distance"), mean) %>%
#       # can use the above for a more general data set using the binning method later
#   rename(SpawnOrder = bin) # rename for use with ANOVA
# 
# # anova to see if there is an effect of SpawnOrder*Interface
# summary(aov(TimeFromSpawnToGrabLoss ~ Interface*SpawnOrder + Error(id/(Interface*SpawnOrder)), data=unity_data_downsampled))
# 
# anova_summary(aov(TimeFromSpawnToGrabLoss ~ Interface*SpawnOrder + Error(id/(Interface*SpawnOrder)), data=unity_data_downsampled))
# 
# ggplot(unity_data_downsampled, aes(SpawnOrder, TimeFromSpawnToGrabLoss, color=Interface)) +
#   geom_point()+#geom_line()+
#   geom_smooth(method="lm")

# # make a data set of average total time per trial for each interface
# trial_data_means <- unity_data_downsampled %>%
#   #filter(TimeFromSpawnToGrabLoss < 15) %>% # get rid of absurd times
#   group_by(Interface, SpawnOrder) %>% summarise(Total_Time=mean(TimeFromSpawnToGrabLoss))
# 
# ggplot(trial_data_means, aes(SpawnOrder, Total_Time, color=Interface)) +
#   geom_point()+#geom_line()+
#   geom_smooth(method="lm")
# 
# 
# # only small cubes
# small_cubes <- unity_data_clean %>% filter(Cube_Size=="Small") %>% 
#   select(id, Interface, SpawnOrder, Cube_Size, TimeFromSpawnToGrabLoss) 
#   
# ggplot(small_cubes %>% filter(Interface=="B_Leap", TimeFromSpawnToGrabLoss<12, id%in%c(1,2,3)),
#        aes(SpawnOrder, TimeFromSpawnToGrabLoss, color=id))+
#   geom_point()+geom_line()
# 
# # renumber spawnorder to start at 1
# small_cubes <- small_cubes %>% group_by(Interface, id) %>% mutate(Order=dense_rank(SpawnOrder))
#   
#   # filter(SpawnOrder==max(SpawnOrder) | SpawnOrder==min(SpawnOrder)) %>%
#   # mutate(SpawnOrder=c(1,2))
# 
# ggplot(small_cubes %>% filter(Interface=="B_Leap", TimeFromSpawnToGrabLoss < 13, as.integer(id)<10), aes(Order, TimeFromSpawnToGrabLoss, color=id))+
#   geom_point()+geom_line()

```

##### Learning Curve - grab time

```{r learning_curve_grab_time}

# summary(aov(TimeFromSpawnToGrab ~ Interface*SpawnOrder + Error(id/(Interface*SpawnOrder)), data=unity_data_downsampled))

anova_summary(aov(TimeFromSpawnToGrab ~ Interface*SpawnOrder + Error(id/(Interface*SpawnOrder)), data=unity_data_downsampled))

# correlation test - do times get faster as they go?
corr_data <- unity_data_downsampled %>% select(SpawnOrder, TimeFromSpawnToGrab) %>% arrange(SpawnOrder)
cor.test(corr_data$SpawnOrder, corr_data$TimeFromSpawnToGrab)
  # hhi_leap
  corr_data <- unity_data_downsampled %>% filter(Interface=="HHI_Leap") %>%
  select(SpawnOrder, TimeFromSpawnToGrab) %>% arrange(SpawnOrder)
  cor.test(corr_data$SpawnOrder, corr_data$TimeFromSpawnToGrab)
  # b_leap
  corr_data <- unity_data_downsampled %>% filter(Interface=="B_Leap") %>%
  select(SpawnOrder, TimeFromSpawnToGrab) %>% arrange(SpawnOrder)
  cor.test(corr_data$SpawnOrder, corr_data$TimeFromSpawnToGrab)

# linear regression modeling
summary(lm(TimeFromSpawnToGrab ~ SpawnOrder*Interface, data=unity_data_downsampled))
#summary(glm(Distance ~ Interface + SpawnOrder + Interface:SpawnOrder, data=unity_data_downsampled))

plot_data <- unity_data_downsampled %>%
  #filter(TimeFromSpawnToGrabLoss < 15) %>% # get rid of absurd times
  group_by(Interface, SpawnOrder) %>% summarise(mean=mean(TimeFromSpawnToGrab))

learning_curve_grab_time <- ggplot(plot_data, aes(SpawnOrder, mean, color=Interface)) +
  geom_point()+#geom_line()+
  geom_smooth(method="lm")+
  labs(title="Learning Curve: Grab Time")
learning_curve_grab_time

sink("learning_curve_stat_output.csv", append = TRUE)
cat("\nANOVA: Learning Curve: Grab Time")
write.csv(anova_summary(aov(TimeFromSpawnToGrab ~ Interface*SpawnOrder + Error(id/(Interface*SpawnOrder)), data=unity_data_downsampled)))
sink()

```
##### Learning Curve: Release Time

```{r learning_curve_release_time}
# summary(aov(TimeFromGrabToGrabLoss ~ Interface*SpawnOrder + Error(id/(Interface*SpawnOrder)), data=unity_data_downsampled))

anova_summary(aov(TimeFromGrabToGrabLoss ~ Interface*SpawnOrder + Error(id/(Interface*SpawnOrder)), data=unity_data_downsampled))

# correlation test - do times get faster as they go?
corr_data <- unity_data_downsampled %>% select(SpawnOrder, TimeFromGrabToGrabLoss) %>% arrange(SpawnOrder)
cor.test(corr_data$SpawnOrder, corr_data$TimeFromGrabToGrabLoss)
  # how about just for the B_Leap?
  corr_data <- unity_data_downsampled %>% filter(Interface=="B_Leap") %>%
    select(SpawnOrder, TimeFromGrabToGrabLoss) %>% arrange(SpawnOrder)
  cor.test(corr_data$SpawnOrder, corr_data$TimeFromGrabToGrabLoss)

# linear regression modeling
summary(lm(TimeFromGrabToGrabLoss ~ SpawnOrder*Interface, data=unity_data_downsampled))
#summary(glm(Distance ~ Interface + SpawnOrder + Interface:SpawnOrder, data=unity_data_downsampled))

plot_data <- unity_data_downsampled %>%
  #filter(TimeFromSpawnToGrabLoss < 15) %>% # get rid of absurd times
  group_by(Interface, SpawnOrder) %>% summarise(mean=mean(TimeFromGrabToGrabLoss))

learning_curve_release_time <- ggplot(plot_data, aes(SpawnOrder, mean, color=Interface)) +
  geom_point()+#geom_line()+
  geom_smooth(method="lm")+
  labs(title="Learning Curve: Release Time")
learning_curve_release_time

sink("learning_curve_stat_output.csv", append = TRUE)
cat("\nANOVA: Learning Curve: Release Time")
write.csv(anova_summary(aov(TimeFromGrabToGrabLoss ~ Interface*SpawnOrder + Error(id/(Interface*SpawnOrder)), data=unity_data_downsampled)))
sink()

```

```{r learning_curve_compilations}

plot_grid(learning_curve_accuracy,# + theme(legend.position = "none"),
          learning_curve_total_time,# + theme(legend.position = "none"),
          learning_curve_grab_time,# + theme(legend.position = "none"),
          learning_curve_release_time)# + theme(legend.position = "none"))
ggsave("learning_curve_compilation.jpg", width = 12, height=9)

```

### Interface order

This section looks for signs of systematic effects due to the order that subjects used the interfaces in this study.
Some information about the variables:
- Interface order contains all subjects. It is one per subject. For the ANOVA, the Interface factor is within-subjects but the Interface Order, Leap_Group and Oculus_Group factors are not.
- The Interface x InterfaceOrder ANOVA contains all three interfaces in the Interface factor; the other two ANOVAs use only the Leaps
- Leap_Group contains all Interface orders: 3 for Leap first, 3 for HHI first.
- Oculus_Group contains only 4 of 6 Interface order: 2 for when Oculus came first, 2 for when Oculus came last. The logic is that this allows comparison for outcome measures for both Leaps when the Oculus had already been seen tried out and before it had been tried. If Oculus had an effect on ratings for either or both Leap interfaces, it would happen only after the subject had been exposed to the Oculus. Lower ratings for Leaps when Oculus came first would indicate this sort of effect.

#### I.O. Performance

##### Accuracy - I.O.

```{r accuracy_DO_analysis}
# Accuracy
# ANOVAs
Interface.order.anova <-
  anova_summary(effect.size="pes",aov(Distance ~ Interface*InterfaceOrder + Error(id/Interface), data=subject_data_all_long))
Interface.order.anova

  #Leap group
  Interface.order.anova2 <-
    anova_summary(effect.size="pes",aov(Distance ~ Interface*Leap_Group + Error(id/Interface), data=subject_data_all_long%>%ungroup%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap")))

  #Oculus group -- Interface orders, filtered
  oculus.group.anova <-
  anova_summary(effect.size="pes",aov(Distance ~ Interface*Oculus_Group + Error(id/Interface),
      data=subject_data_all_long%>%ungroup%>%
        filter(is.na(Oculus_Group)==FALSE, Interface!="Oculus") %>% mutate(Interface=factor(Interface))))

Interface_order_output<- Interface.order.anova %>% rbind(Interface.order.anova2) %>% rbind(oculus.group.anova) %>% mutate(metric="Accuracy", p=round(p, 4)) %>% select(metric, everything())

  # t-tests 
  stat.test <- subject_data_all_long %>% ungroup(.) %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>%
    group_by(Leap_Group) %>%
    t_test(Distance ~ Interface, paired=TRUE) %>% # paired b/c it's within Leap group
    mutate(test="Within-subjects T-test") %>% rename(Group=Leap_Group)
  
  # plot and test, split by Interface (leap vs. leap, HHI vs. HHI)
  stat.test2 <- subject_data_all_long %>% ungroup(.) %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>% group_by(Interface) %>%
    t_test(Distance ~ Leap_Group, paired=FALSE) %>% # NOT paired b/c it's between Leap groups
    mutate(test="Between-subjects T-test")%>% rename(Group=Interface)
  stat.test <-rbind(stat.test, stat.test2)
  
  # Interfaces when first
  stat.test3 <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="B_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="HHI_Leap")) %>%
    t_test(Distance ~ Interface, paired=FALSE) %>% # NOT paired b/c it's between Leap groups
    mutate(test="Between-subjects T-test", Group="when first")
  stat.test <- stat.test %>% bind_rows(stat.test3)
  
  #Interfaces when second
  stat.test4 <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="HHI_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="B_Leap")) %>%
    t_test(Distance ~ Interface, paired=FALSE) %>% # NOT paired b/c it's between Leap groups
    mutate(test="Between-subjects T-test", Group="when second")
  stat.test <- stat.test %>% bind_rows(stat.test4)
  
  # adjust p value
  stat.test <- stat.test %>% adjust_pvalue() %>% add_significance("p.adj") %>%
    mutate(Interface=group1) #to make the stat.pvalue.manual ggplot item happy
  stat.test

```

##### Grab time - I.O.

```{r grabtime_DO_analysis}

#grabtime
Interface.order.anova <-
  anova_summary(effect.size="pes",aov(grabtime ~ Interface*InterfaceOrder + Error(id/Interface), data=subject_data_all_long))

  #Leap group
  Interface.order.anova2 <-
    anova_summary(effect.size="pes",aov(grabtime ~ Interface*Leap_Group + Error(id/Interface), data=subject_data_all_long%>%ungroup%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap")))
      ggplot(subject_data_all_long %>% filter(Interface!="Oculus"), aes(Leap_Group, grabtime))+
        labs(title="Grab time by Leap order and interface")+
        geom_boxplot(aes(fill=Interface), width=.6)+labs(title="Interaction effect: Leap order on grab time")+
        geom_boxplot(width=.05, fill="white", position=position_nudge(0))

  #Oculus group
  oculus.group.anova <-
  anova_summary(effect.size="pes",aov(Distance ~ Interface*Oculus_Group + Error(id/Interface),
      data=subject_data_all_long%>%ungroup%>%
        filter(is.na(Oculus_Group)==FALSE, Interface!="Oculus") %>% mutate(Interface=factor(Interface))))

Interface_order_output <- Interface_order_output %>% rbind(Interface.order.anova %>% rbind(Interface.order.anova2) %>% rbind(oculus.group.anova) %>% mutate(metric="grabtime", p=round(p, 4)) %>% select(metric, everything()))

    # t-tests - grab time d.o. - leap group
    stat.test <- subject_data_all_long %>% ungroup(.) %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>%
      group_by(Leap_Group) %>%
      t_test(grabtime ~ Interface, paired=TRUE) %>% # paired b/c it's within Leap group
      mutate(test="Within-subjects T-test") %>% rename(Group=Leap_Group)
    
    # plot and test, split by Interface (leap vs. leap, HHI vs. HHI)
    stat.test2 <- subject_data_all_long %>% ungroup(.) %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>% group_by(Interface) %>%
      t_test(grabtime ~ Leap_Group, paired=FALSE) %>% # NOT paired b/c it's between Leap groups
      mutate(test="Between-subjects T-test")%>% rename(Group=Interface)
    stat.test <-rbind(stat.test, stat.test2)
    
    # Interfaces when first
    stat.test3 <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="B_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="HHI_Leap")) %>%
      t_test(grabtime ~ Interface, paired=FALSE) %>% # NOT paired b/c it's between Leap groups
      mutate(test="Between-subjects T-test", Group="when first")
    stat.test <- stat.test %>% bind_rows(stat.test3)
    
    #Interfaces when second
    stat.test4 <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="HHI_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="B_Leap")) %>%
      t_test(grabtime ~ Interface, paired=FALSE) %>% # NOT paired b/c it's between Leap groups
      mutate(test="Between-subjects T-test", Group="when second")
    stat.test <- stat.test %>% bind_rows(stat.test4)
    
    # adjust p value
    stat.test <- stat.test %>% adjust_pvalue() %>% add_significance("p.adj") %>%
      mutate(Interface=group1) #to make the stat.pvalue.manual ggplot item happy
    stat.test
  
    
  
        # make labels for plots
    Leap_Group_labs<-c(paste0("HHI first n=", length((subject_data_all_long %>%
        select(id, Interface, grabtime,Leap_Group)%>%filter(Leap_Group=="HHI_Leap_first")%>%select(id)%>%distinct(.))$id)), paste0("Leap first n=", length((subject_data_all_long%>%filter(Leap_Group=="B_Leap_first")%>%select(id)%>%distinct(.))$id)))
    
    # by leap group (B_Leap_first, HHI_Leap_first)
    temp_set <- subject_data_all_long %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>%
      select(id, Interface, grabtime, Leap_Group)
    temp_plot_data <- subject_data_all_long %>% group_by(Interface, Leap_Group) %>%
      filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>% get_summary_stats(grabtime)
    
    p1<- ggplot(temp_set, aes(x=Interface, y=grabtime, fill=Interface, colour = Interface))+
    geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=myalpha,adjust=mysmoothing)+
    geom_point(position = position_jitter(width = 0.1, height=0), size = 1)+ # the "rain"
    geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean, 3)), position = position_nudge(.5), colour = "white")+
    geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK")+
    geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
    ylab('Time (seconds)')+xlab('Interface')+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
    scale_color_manual(values=mycolors)+#scale_colour_brewer(palette = "Set2")+
    scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2", direction=1)+   
      stat_pvalue_manual(data=stat.test%>%slice(1:2)%>%rename(Leap_Group=Group), xmin="group1", xmax="group2", label = "p.adj.signif", step.increase=.1, y.position=2.5*max(temp_plot_data$mean), position=position_nudge(0.25))+
    labs(title="Grab times by interface order", caption="Means, 95% CI; Within-subjects t-test, adj.: Holm")+
    facet_grid(. ~ Leap_Group)
    #ggsave(last_plot(), filename="trainingtime_leapgroup_raincloud.jpg", width=9, height=5)
    
    
    # plot, split by Interface (leap vs. leap, HHI vs. HHI)
    temp_set <- subject_data_all_long %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>%
      select(id, Interface, grabtime, Leap_Group)
    
    temp_plot_data <- subject_data_all_long %>% group_by(Interface, Leap_Group) %>%
      filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>% get_summary_stats(grabtime)
    
    p2<- ggplot(temp_set, aes(x=Leap_Group, y=grabtime, fill=Interface, colour = Interface))+
    geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=myalpha, adjust=mysmoothing)+
    geom_point(position = position_jitter(width = 0.1, height=0), size = 1)+ # the "rain"
    geom_label(data = temp_plot_data, aes(x = Leap_Group, y = mean, label=round(mean, 3)), position = position_nudge(.5), colour = "white")+
    geom_point(data = temp_plot_data, aes(x = Leap_Group, y = mean), position = position_nudge(.25), colour = "BLACK")+
    geom_errorbar(data = temp_plot_data, aes(x = Leap_Group, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
    ylab('Time (seconds)')+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
    scale_color_manual(values=mycolors)+#scale_colour_brewer(palette = "Set2")+
    scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2", direction=1)+   
      xlab(NULL)+
    stat_pvalue_manual(data=stat.test%>%slice(3:4)%>%mutate(Interface=Group), xmin="group1", xmax="group2", label = "p.adj.signif", step.increase=-.3, y.position=2.5*max(temp_plot_data$mean), position=position_nudge(0.25))+
    labs(title="Grab times: interface vs. itself", caption="Means, 95% CI; Within-subjects t-test, adj.: Holm")+
    scale_x_discrete(labels=c("1st","2nd"))+
    facet_grid(. ~ Interface)#+scale_x_discrete(labels=c("HHI-->Leap","Leap-->HHI"))
    #ggsave(last_plot(), filename="trainingtime_leapgroup_raincloud.jpg", width=9, height=5)
    
    
    # each Interface when first
    temp_set <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="B_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="HHI_Leap"))
    temp_plot_data <- temp_set %>% group_by(Interface)%>% get_summary_stats(grabtime)
    
    p3<- ggplot(temp_set, aes(x=Interface, y=grabtime, fill=Interface, colour = Interface))+
      geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=.7)+#,adjust =2)+
      geom_point(position = position_jitter(width = 0.1, height=0), size = 1)+ # the "rain"
    geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean, 3)), position = position_nudge(.5), colour = "white")+
      geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK")+
      geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
      ylab('Time (seconds)')+xlab(NULL)+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
      scale_colour_brewer(palette = "Set2")+#coord_flip()+
      scale_fill_brewer(palette = "Set2")+
      # stat_compare_means(method="t.test", paired=FALSE, label.x.npc="center")+
      # stat_compare_means(method="wilcox", paired=FALSE, label.x.npc="right")+
      stat_pvalue_manual(data=stat.test%>%slice(5)%>%mutate(Interface="B_Leap"), xmin="group1", xmax="group2", label = "p.adj.signif", y.position=2.5*max(temp_plot_data$mean), position=position_nudge(0.25))+
      labs(title="Grab times when 1st", caption="Means, 95% CI; Within-subjects t-test, adj.: Holm")#+facet_grid(. ~ Leap_Group)
    #ggsave(last_plot(), filename="Grabtime_both_first.jpg", width=6, height=4)
    
    
    # Grab times when second (plot) - BETWEEN SUBJECTS
    temp_set <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="HHI_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="B_Leap"))
    temp_plot_data <- temp_set %>% group_by(Interface)%>% get_summary_stats(grabtime)
    
    p4<- ggplot(temp_set, aes(x=Interface, y=grabtime, fill=Interface, colour = Interface))+
      geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=.7)+#,adjust =2)+
      geom_point(position = position_jitter(width = 0.1, height=0), size = 1)+ # the "rain"
    geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean, 3)), position = position_nudge(.5), colour = "white")+
      geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK")+
      geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
      ylab('Time (seconds)')+xlab('Interface')+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
      scale_colour_brewer(palette = "Set2")+#coord_flip()+
      scale_fill_brewer(palette = "Set2")+
      # stat_compare_means(method="t.test", paired=FALSE, label.x.npc="center")+
      # stat_compare_means(method="wilcox", paired=FALSE, label.x.npc="right")+
      stat_pvalue_manual(data=stat.test%>%slice(5)%>%mutate(Interface="B_Leap"), xmin="group1", xmax="group2", label = "p.adj.signif", y.position=2.5*max(temp_plot_data$mean), position=position_nudge(0.25))+
      labs(title="Grab times when 2nd", subtitle = , caption="Means, 95% CI; Within-subjects t-test, adj.: Holm")#+facet_grid(. ~ Leap_Group)
    ggsave(last_plot(), filename="Grabtime_both_first.jpg", width=6, height=4)
    
    plot_grid(p1, p2)#, p3, p4)
    ggsave("grabtimes_closer_look.jpg", width=12, height=10)
    
    do_grabtime<-p1
    

```


##### Release time

```{r releasetime_DO_analaysis}

# release time
  Interface.order.anova <-
    anova_summary(effect.size="pes",aov(releasetime ~ Interface*InterfaceOrder + Error(id/Interface), data=subject_data_all_long))
  #Interface.order.anova
  
  #Leap group
  Interface.order.anova2 <-
    anova_summary(effect.size="pes",aov(releasetime ~ Interface*Leap_Group + Error(id/Interface), data=subject_data_all_long%>%ungroup%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap")))
  #Interface.order.anova2

  #Oculus group
  oculus.group.anova <-
  anova_summary(effect.size="pes",aov(releasetime ~ Interface*Oculus_Group + Error(id/Interface),
      data=subject_data_all_long%>%ungroup%>%
        filter(is.na(Oculus_Group)==FALSE, Interface!="Oculus") %>% mutate(Interface=factor(Interface))))

Interface_order_output <- Interface_order_output %>% rbind(Interface.order.anova %>% rbind(Interface.order.anova2) %>% rbind(oculus.group.anova) %>% mutate(metric="release time", p=round(p, 4)) %>% select(metric, everything()))
  
      # t-tests - release time d.o. - leap group
    stat.test <- subject_data_all_long %>% ungroup(.) %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>%
      group_by(Leap_Group) %>%
      t_test(releasetime ~ Interface, paired=TRUE) %>% # paired b/c it's within Leap group
      mutate(test="Within-subjects T-test") %>% rename(Group=Leap_Group)
    
    # plot and test, split by Interface (leap vs. leap, HHI vs. HHI)
    stat.test2 <- subject_data_all_long %>% ungroup(.) %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>% group_by(Interface) %>%
      t_test(releasetime ~ Leap_Group, paired=FALSE) %>% # NOT paired b/c it's between Leap groups
      mutate(test="Between-subjects T-test")%>% rename(Group=Interface)
    stat.test <-rbind(stat.test, stat.test2)
    
    # Interfaces when first
    stat.test3 <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="B_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="HHI_Leap")) %>%
      t_test(releasetime ~ Interface, paired=FALSE) %>% # NOT paired b/c it's between Leap groups
      mutate(test="Between-subjects T-test", Group="when first")
    stat.test <- stat.test %>% bind_rows(stat.test3)
    
    #Interfaces when second
    stat.test4 <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="HHI_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="B_Leap")) %>%
      t_test(releasetime ~ Interface, paired=FALSE) %>% # NOT paired b/c it's between Leap groups
      mutate(test="Between-subjects T-test", Group="when second")
    stat.test <- stat.test %>% bind_rows(stat.test4)
    
    # adjust p value
    stat.test <- stat.test %>% adjust_pvalue() %>% add_significance(p.col="p.adj", output.col="p.adj.signif") %>% mutate(Interface=group1) #to make the stat.pvalue.manual ggplot item happy
    
    
    #stat.test<- stat.test %>% mutate(Interface=group1, p.adj.signif=p.signif)
  
    
  
        # make labels for plots
    Leap_Group_labs<-c(paste0("HHI first n=", length((subject_data_all_long %>%
        select(id, Interface, releasetime,Leap_Group)%>%filter(Leap_Group=="HHI_Leap_first")%>%select(id)%>%distinct(.))$id)), paste0("Leap first n=", length((subject_data_all_long%>%filter(Leap_Group=="B_Leap_first")%>%select(id)%>%distinct(.))$id)))
    
    # by leap group (B_Leap_first, HHI_Leap_first)
    temp_set <- subject_data_all_long %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>%
      select(id, Interface, releasetime, Leap_Group)
    temp_plot_data <- subject_data_all_long %>% group_by(Interface, Leap_Group) %>%
      filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>% get_summary_stats(releasetime)
    
    p1<- ggplot(temp_set, aes(x=Interface, y=releasetime, fill=Interface, colour = Interface))+
    geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=myalpha, adjust=mysmoothing)+
    geom_point(position = position_jitter(width = 0.1, height=0), size = 1)+ # the "rain"
    geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean, 3)), position = position_nudge(.5), colour = "white")+
    geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK")+
    geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
    ylab('Time (seconds)')+xlab('Interface')+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
    scale_color_manual(values=mycolors)+#scale_colour_brewer(palette = "Set2")+
    scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2", direction=1)+
    stat_pvalue_manual(data=stat.test%>%slice(1:2)%>%rename(Leap_Group=Group), xmin="group1", xmax="group2", label = "p.adj.signif", step.increase=.1, y.position=2.5*max(temp_plot_data$mean), position=position_nudge(0.25))+
    labs(title="Release times by interface order", caption=paste0(Leap_Group_labs[1],", ", Leap_Group_labs[2],"; mean, 95% CI; Within-subjects T-test, adj.: Holm"))+
    facet_grid(. ~ Leap_Group)
    #ggsave(last_plot(), filename="trainingtime_leapgroup_raincloud.jpg", width=9, height=5)
    
    
    # plot, split by Interface (leap vs. leap, HHI vs. HHI)
    temp_set <- subject_data_all_long %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>%
      select(id, Interface, releasetime, Leap_Group)
    
    temp_plot_data <- subject_data_all_long %>% group_by(Interface, Leap_Group) %>%
      filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>% get_summary_stats(releasetime)
    
    p2<- ggplot(temp_set, aes(x=Leap_Group, y=releasetime, fill=Interface, colour = Interface))+
    geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=.7)+#,adjust =2)+
    geom_point(position = position_jitter(width = 0.1, height=0), size = 1)+ # the "rain"
    geom_label(data = temp_plot_data, aes(x = Leap_Group, y = mean, label=round(mean, 3)), position = position_nudge(.5), colour = "white")+
    geom_point(data = temp_plot_data, aes(x = Leap_Group, y = mean), position = position_nudge(.25), colour = "BLACK")+
    geom_errorbar(data = temp_plot_data, aes(x = Leap_Group, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
    ylab('Time (seconds)')+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
    scale_colour_brewer(palette = "Set2")+#coord_flip()+
    scale_fill_brewer(palette = "Set2")+xlab(NULL)+
    stat_pvalue_manual(data=stat.test%>%slice(3:4)%>%mutate(Interface=Group), xmin="group1", xmax="group2", label = "p.adj.signif", step.increase=-.3, y.position=2.5*max(temp_plot_data$mean), position=position_nudge(0.25))+
    labs(title="release times: interface vs. itself", caption="Means, 95% CI; Within-subjects t-test, adj.: Holm")+
    facet_grid(. ~ Interface)#+scale_x_discrete(labels=c("HHI-->Leap","Leap-->HHI"))
    #ggsave(last_plot(), filename="trainingtime_leapgroup_raincloud.jpg", width=9, height=5)
    
    
    # each Interface when first
    temp_set <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="B_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="HHI_Leap"))
    temp_plot_data <- temp_set %>% group_by(Interface)%>% get_summary_stats(releasetime)
    
    p3<- ggplot(temp_set, aes(x=Interface, y=releasetime, fill=Interface, colour = Interface))+
      geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=.7)+#,adjust =2)+
      geom_point(position = position_jitter(width = 0.1, height=0), size = 1)+ # the "rain"
    geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean, 3)), position = position_nudge(.5), colour = "white")+
      geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK")+
      geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
      ylab('Time (seconds)')+xlab(NULL)+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
      scale_colour_brewer(palette = "Set2")+#coord_flip()+
      scale_fill_brewer(palette = "Set2")+
      # stat_compare_means(method="t.test", paired=FALSE, label.x.npc="center")+
      # stat_compare_means(method="wilcox", paired=FALSE, label.x.npc="right")+
      stat_pvalue_manual(data=stat.test%>%slice(5)%>%mutate(Interface="B_Leap"), xmin="group1", xmax="group2", label = "p.adj.signif", y.position=2.5*max(temp_plot_data$mean), position=position_nudge(0.25))+
      labs(title="release times when 1st", caption="Means, 95% CI; Within-subjects t-test, adj.: Holm")#+facet_grid(. ~ Leap_Group)
    #ggsave(last_plot(), filename="releasetime_both_first.jpg", width=6, height=4)
    
    
    # release times when second (plot) - BETWEEN SUBJECTS
    temp_set <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="HHI_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="B_Leap"))
    temp_plot_data <- temp_set %>% group_by(Interface)%>% get_summary_stats(releasetime)
    
    p4<- ggplot(temp_set, aes(x=Interface, y=releasetime, fill=Interface, colour = Interface))+
      geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=.7)+#,adjust =2)+
      geom_point(position = position_jitter(width = 0.1, height=0), size = 1)+ # the "rain"
    geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean, 3)), position = position_nudge(.5), colour = "white")+
      geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK")+
      geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
      ylab('Time (seconds)')+xlab('Interface')+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
      scale_colour_brewer(palette = "Set2")+#coord_flip()+
      scale_fill_brewer(palette = "Set2")+
      # stat_compare_means(method="t.test", paired=FALSE, label.x.npc="center")+
      # stat_compare_means(method="wilcox", paired=FALSE, label.x.npc="right")+
      stat_pvalue_manual(data=stat.test%>%slice(5)%>%mutate(Interface="B_Leap"), xmin="group1", xmax="group2", label = "p.adj.signif", y.position=2.5*max(temp_plot_data$mean), position=position_nudge(0.25))+
      labs(title="release times when 2nd", subtitle = , caption="Means, 95% CI; Within-subjects t-test, adj.: Holm")#+facet_grid(. ~ Leap_Group)
    ggsave(last_plot(), filename="releasetime_both_first.jpg", width=6, height=4)
    
    plot_grid(p1, p2, p3, p4)
    ggsave("releasetimes_closer_look.jpg", width=12, height=10)
    do_releasetime<-p1

```

##### Total time I.O.

```{r totaltime_Interface_order}

# total time
  Interface.order.anova <-
    anova_summary(effect.size="pes",aov(totaltime ~ Interface*InterfaceOrder + Error(id/Interface), data=subject_data_all_long))
  #Interface.order.anova
  
  #Leap group
  Interface.order.anova2 <-
    anova_summary(effect.size="pes",aov(totaltime ~ Interface*Leap_Group + Error(id/Interface), data=subject_data_all_long%>%ungroup%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap")))
  #Interface.order.anova2

  #Oculus group
  oculus.group.anova <-
  anova_summary(effect.size="pes",aov(totaltime ~ Interface*Oculus_Group + Error(id/Interface),
      data=subject_data_all_long%>%ungroup%>%
        filter(is.na(Oculus_Group)==FALSE, Interface!="Oculus") %>% mutate(Interface=factor(Interface))))
  
  Interface_order_output <- Interface_order_output %>% rbind(Interface.order.anova %>% rbind(Interface.order.anova2) %>% rbind(oculus.group.anova) %>% mutate(metric="total time", p=round(p, 4)) %>% select(metric, everything()))
  
      # t-tests - total time d.o. - leap group
    stat.test <- subject_data_all_long %>% ungroup(.) %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>%
      group_by(Leap_Group) %>%
      t_test(totaltime ~ Interface, paired=TRUE) %>% # paired b/c it's within Leap group
      mutate(test="Within-subjects T-test") %>% rename(Group=Leap_Group)
    
    # plot and test, split by Interface (leap vs. leap, HHI vs. HHI)
    stat.test2 <- subject_data_all_long %>% ungroup(.) %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>% group_by(Interface) %>%
      t_test(totaltime ~ Leap_Group, paired=FALSE) %>% # NOT paired b/c it's between Leap groups
      mutate(test="Between-subjects T-test")%>% rename(Group=Interface)
    stat.test <-rbind(stat.test, stat.test2)
    
    # Interfaces when first
    stat.test3 <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="B_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="HHI_Leap")) %>%
      t_test(totaltime ~ Interface, paired=FALSE) %>% # NOT paired b/c it's between Leap groups
      mutate(test="Between-subjects T-test", Group="when first")
    stat.test <- stat.test %>% bind_rows(stat.test3)
    
    #Interfaces when second
    stat.test4 <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="HHI_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="B_Leap")) %>%
      t_test(totaltime ~ Interface, paired=FALSE) %>% # NOT paired b/c it's between Leap groups
      mutate(test="Between-subjects T-test", Group="when second")
    stat.test <- stat.test %>% bind_rows(stat.test4)
    
    # adjust p value
    stat.test <- stat.test %>% adjust_pvalue() %>% add_significance("p") %>% mutate(Interface=group1, p.adj.signif=p.signif) #to make the stat.pvalue.manual ggplot item happy
    
    
    #stat.test<- stat.test %>% mutate(Interface=group1, p.adj.signif=p.signif)
  
        # make labels for plots
    Leap_Group_labs<-c(paste0("HHI first n=", length((subject_data_all_long %>%
        select(id, Interface, totaltime,Leap_Group)%>%filter(Leap_Group=="HHI_Leap_first")%>%select(id)%>%distinct(.))$id)), paste0("Leap first n=", length((subject_data_all_long%>%filter(Leap_Group=="B_Leap_first")%>%select(id)%>%distinct(.))$id)))
    
    # by leap group (B_Leap_first, HHI_Leap_first)
    temp_set <- subject_data_all_long %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>%
      select(id, Interface, totaltime, Leap_Group)
    temp_plot_data <- subject_data_all_long %>% group_by(Interface, Leap_Group) %>%
      filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>% get_summary_stats(totaltime)
    
    p1<- ggplot(temp_set, aes(x=Interface, y=totaltime, fill=Interface, colour = Interface))+
    geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=myalpha,adjust=mysmoothing)+
    geom_point(position = position_jitter(width = 0.1, height=0), size = 1)+ # the "rain"
    geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean, 3)), position = position_nudge(.5), colour = "white")+
    geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK")+
    geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
    ylab('Time (seconds)')+xlab('Interface')+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
    scale_color_manual(values=mycolors)+#scale_colour_brewer(palette = "Set2")+
    scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2", direction=1)+
    stat_pvalue_manual(data=stat.test%>%slice(1:2)%>%rename(Leap_Group=Group), xmin="group1", xmax="group2", label = "p.adj.signif", step.increase=.1, y.position=2.5*max(temp_plot_data$mean), position=position_nudge(0.25))+
    labs(title="Total times by interface order", caption=paste0(Leap_Group_labs[1],", ", Leap_Group_labs[2],"; mean, 95% CI; Within-subjects T-test, adj.: Holm"))+
    facet_grid(. ~ Leap_Group)
    #ggsave(last_plot(), filename="trainingtime_leapgroup_raincloud.jpg", width=9, height=5)
    
    
    # plot, split by Interface (leap vs. leap, HHI vs. HHI)
    temp_set <- subject_data_all_long %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>%
      select(id, Interface, totaltime, Leap_Group)
    
    temp_plot_data <- subject_data_all_long %>% group_by(Interface, Leap_Group) %>%
      filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>% get_summary_stats(totaltime)
    
    p2<- ggplot(temp_set, aes(x=Leap_Group, y=totaltime, fill=Interface, colour = Interface))+
    geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=.7)+#,adjust =2)+
    geom_point(position = position_jitter(width = 0.1, height=0), size = 1)+ # the "rain"
    geom_label(data = temp_plot_data, aes(x = Leap_Group, y = mean, label=round(mean, 3)), position = position_nudge(.5), colour = "white")+
    geom_point(data = temp_plot_data, aes(x = Leap_Group, y = mean), position = position_nudge(.25), colour = "BLACK")+
    geom_errorbar(data = temp_plot_data, aes(x = Leap_Group, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
    ylab('Time (seconds)')+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
    scale_colour_brewer(palette = "Set2")+#coord_flip()+
    scale_fill_brewer(palette = "Set2")+xlab(NULL)+
    stat_pvalue_manual(data=stat.test%>%slice(3:4)%>%mutate(Interface=Group), xmin="group1", xmax="group2", label = "p.adj.signif", step.increase=-.3, y.position=2.5*max(temp_plot_data$mean), position=position_nudge(0.25))+
    labs(title="total times: interface vs. itself", caption="Means, 95% CI; Within-subjects t-test, adj.: Holm")+
    facet_grid(. ~ Interface)#+scale_x_discrete(labels=c("HHI-->Leap","Leap-->HHI"))
    #ggsave(last_plot(), filename="trainingtime_leapgroup_raincloud.jpg", width=9, height=5)
    
    
    # each Interface when first
    temp_set <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="B_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="HHI_Leap"))
    temp_plot_data <- temp_set %>% group_by(Interface)%>% get_summary_stats(totaltime)
    
    p3<- ggplot(temp_set, aes(x=Interface, y=totaltime, fill=Interface, colour = Interface))+
      geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=.7)+#,adjust =2)+
      geom_point(position = position_jitter(width = 0.1, height=0), size = 1)+ # the "rain"
    geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean, 3)), position = position_nudge(.5), colour = "white")+
      geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK")+
      geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
      ylab('Time (seconds)')+xlab(NULL)+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
      scale_colour_brewer(palette = "Set2")+#coord_flip()+
      scale_fill_brewer(palette = "Set2")+
      # stat_compare_means(method="t.test", paired=FALSE, label.x.npc="center")+
      # stat_compare_means(method="wilcox", paired=FALSE, label.x.npc="right")+
      stat_pvalue_manual(data=stat.test%>%slice(5)%>%mutate(Interface="B_Leap"), xmin="group1", xmax="group2", label = "p.adj.signif", y.position=2.5*max(temp_plot_data$mean), position=position_nudge(0.25))+
      labs(title="total times when 1st", caption="Means, 95% CI; Within-subjects t-test, adj.: Holm")#+facet_grid(. ~ Leap_Group)
    #ggsave(last_plot(), filename="totaltime_both_first.jpg", width=6, height=4)
    
    
    # total times when second (plot) - BETWEEN SUBJECTS
    temp_set <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="HHI_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="B_Leap"))
    temp_plot_data <- temp_set %>% group_by(Interface)%>% get_summary_stats(totaltime)
    
    p4<- ggplot(temp_set, aes(x=Interface, y=totaltime, fill=Interface, colour = Interface))+
      geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=.7)+#,adjust =2)+
      geom_point(position = position_jitter(width = 0.1, height=0), size = 1)+ # the "rain"
    geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=round(mean, 3)), position = position_nudge(.5), colour = "white")+
      geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK")+
      geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
      ylab('Time (seconds)')+xlab('Interface')+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
      scale_colour_brewer(palette = "Set2")+#coord_flip()+
      scale_fill_brewer(palette = "Set2")+
      # stat_compare_means(method="t.test", paired=FALSE, label.x.npc="center")+
      # stat_compare_means(method="wilcox", paired=FALSE, label.x.npc="right")+
      stat_pvalue_manual(data=stat.test%>%slice(5)%>%mutate(Interface="B_Leap"), xmin="group1", xmax="group2", label = "p.adj.signif", y.position=2.5*max(temp_plot_data$mean), position=position_nudge(0.25))+
      labs(title="total times when 2nd", subtitle = , caption="Means, 95% CI; Within-subjects t-test, adj.: Holm")#+facet_grid(. ~ Leap_Group)
    ggsave(last_plot(), filename="totaltime_both_first.jpg", width=6, height=4)
    
    plot_grid(p1, p2, p3, p4)
    ggsave("totaltimes_closer_look.jpg", width=12, height=10)
    do_totaltime<-p1

```  

##### Accidental drop I.O.

```{r accidental_drop_DO}
# accidental drops
  Interface.order.anova <-
    anova_summary(effect.size="pes",aov(Drop_Count ~ Interface*InterfaceOrder + Error(id/Interface), data=subject_data_all_long))
  #Interface.order.anova
  
  #Leap group
  Interface.order.anova2 <-
    anova_summary(effect.size="pes",aov(Drop_Count ~ Interface*Leap_Group + Error(id/Interface), data=subject_data_all_long%>%ungroup%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap")))
  #Interface.order.anova2

  #Oculus group
  oculus.group.anova <-
  anova_summary(effect.size="pes",aov(Drop_Count ~ Interface*Oculus_Group + Error(id/Interface),
      data=subject_data_all_long%>%ungroup%>%
        filter(is.na(Oculus_Group)==FALSE, Interface!="Oculus") %>% mutate(Interface=factor(Interface))))

Interface_order_output <- Interface_order_output %>% rbind(Interface.order.anova %>% rbind(Interface.order.anova2) %>% rbind(oculus.group.anova) %>% mutate(metric="accidental drops", p=round(p, 4)) %>% select(metric, everything()))

```

##### Practice time: Interface order

The plots below may be confusing, but basically they compare every iteration of Interface (B_Leap or HHI Leap) and Interface order (B_Leap first or HHI Leap first) with Holm-adjusted p values. While each Interface is slower when first, not all differences are statistically significant. The significant effects between Interfaces when B_Leap comes first (HHI is faster), and between HHI and itself when it comes first vs. when it comes second.

In other words, when B_Leap precedes HHI Leap, the amount of training time required for a user to feel ready to use the HHI Leap is lower, but NOT the other way around. This suggests that the B_Leap trains the user for the HHI Leap better than the other way around, which makes sense, because the HHI Leap is the B_Leap with extra features (the highlighting and grab delay).

The trend towards a significant effect in the Training Time by Interface plot above is likely due to effects of Interface order, rather than something intrinsic to the Interface. This is therefore not evidence that the HHI Leap is more intuitive (that the user feels ready to use it sooner).

The ANOVA below, only between Leaps and Leap Order, offers a confusing addition: there is a main effect of Interface, suggesting that Interface alone does impact training time.

The interaction effect supports the Interface Order theory, that Interface type and order work together to impact training time-- that a Interface impacts training time differently when it comes first than when it comes second.

```{r practice_time_Interface_order}
# interaction: training time: Interface*leap_group
Interface.order.anova <-
  anova_summary(effect.size="pes",aov(practice_time ~ Interface*InterfaceOrder + Error(id/Interface), data=subject_data_all_long))
Interface.order.anova


stat.test.anova <- 
anova_summary(effect.size="pes",aov(practice_time ~ Interface*Leap_Group + Error(id/Interface), data=subject_data_all_long %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap")))
stat.test.anova
write.csv(stat.test.anova, file="trainingtime_by_leapgroup_anova.csv")
# There was an interaction between leap group and Interface. What was driving this interaction?

 #Leap group
  Interface.order.anova2 <-
    anova_summary(effect.size="pes",aov(practice_time ~ Interface*Leap_Group + Error(id/Interface), data=subject_data_all_long%>%ungroup%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap")))
  #Interface.order.anova2

  #Oculus group
  oculus.group.anova <-
  anova_summary(effect.size="pes",aov(practice_time ~ Interface*Oculus_Group + Error(id/Interface),
      data=subject_data_all_long%>%ungroup%>%
        filter(is.na(Oculus_Group)==FALSE, Interface!="Oculus") %>% mutate(Interface=factor(Interface))))
  

Interface_order_output <- Interface_order_output %>% rbind(Interface.order.anova %>% rbind(Interface.order.anova2) %>% rbind(oculus.group.anova) %>% mutate(metric="training time", p=round(p, 4)) %>% select(metric, everything()))


###
# group all t tests then adjust p value
# t tests
stat.test <- subject_data_all_long %>% ungroup(.) %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>%
  group_by(Leap_Group) %>%
  t_test(practice_time ~ Interface, paired=TRUE) %>% # paired b/c it's within Leap group
  mutate(test="Within-subjects T-test") %>% rename(Group=Leap_Group)

# plot and test, split by Interface (leap vs. leap, HHI vs. HHI)
stat.test2 <- subject_data_all_long %>% ungroup(.) %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>% group_by(Interface) %>%
  t_test(practice_time ~ Leap_Group, paired=FALSE) %>% # NOT paired b/c it's between Leap groups
  mutate(test="Between-subjects T-test")%>% rename(Group=Interface)
stat.test <-rbind(stat.test, stat.test2)

# Interfaces when first
stat.test3 <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="B_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="HHI_Leap")) %>%
  t_test(practice_time ~ Interface, paired=FALSE) %>% # NOT paired b/c it's between Leap groups
  mutate(test="Between-subjects T-test", Group="when first")
stat.test <- stat.test %>% bind_rows(stat.test3)

#Interfaces when second
stat.test4 <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="HHI_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="B_Leap")) %>%
  t_test(practice_time ~ Interface, paired=FALSE) %>% # NOT paired b/c it's between Leap groups
  mutate(test="Between-subjects T-test", Group="when second")
stat.test <- stat.test %>% bind_rows(stat.test4)

# adjust p value
stat.test <- stat.test %>% adjust_pvalue() %>% add_significance("p.adj") %>%
  mutate(Interface=group1) #to make the stat.pvalue.manual ggplot item happy
stat.test

###

# make labels for plots
Leap_Group_labs<-c(paste0("HHI first n=", length((subject_data_all_long %>%
    select(id, Interface, practice_time,Leap_Group)%>%filter(Leap_Group=="HHI_Leap_first")%>%select(id)%>%distinct(.))$id)), paste0("Leap first n=", length((subject_data_all_long%>%filter(Leap_Group=="B_Leap_first")%>%select(id)%>%distinct(.))$id)))

# by leap group (B_Leap_first, HHI_Leap_first)
temp_set <- subject_data_all_long %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>%
  select(id, Interface, practice_time, Leap_Group)
temp_plot_data <- subject_data_all_long %>% group_by(Interface, Leap_Group) %>%
  filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>% get_summary_stats(practice_time)

p1<- ggplot(temp_set, aes(x=Interface, y=practice_time, fill=Interface, colour = Interface))+
geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=myalpha, adjust=mysmoothing)+
geom_point(position = position_jitter(width = 0.1, height=0), size = 1)+ # the "rain"
geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=ceiling(mean)), position = position_nudge(.5), colour = "white")+
geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK")+
geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
ylab('Time (seconds)')+xlab('Interface')+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
scale_color_manual(values=mycolors)+#scale_colour_brewer(palette = "Set2")+
scale_fill_manual(values=mycolors)+#scale_fill_brewer(palette = "Set2", direction=1)+
stat_pvalue_manual(data=stat.test%>%slice(1:2)%>%rename(Leap_Group=Group), xmin="group1", xmax="group2", label = "p.adj.signif", step.increase=.1, y.position=2.5*max(temp_plot_data$mean), position=position_nudge(0.25))+
labs(title="Practice times by Interface order", caption=paste0(Leap_Group_labs[1],", ", Leap_Group_labs[2],"; mean, 95% CI; Within-subjects T-test, adj.: Holm"))+
facet_grid(. ~ Leap_Group)
ggsave(last_plot(), filename="trainingtime_leapgroup_raincloud.jpg", width=9, height=5)


# plot, split by Interface (leap vs. leap, HHI vs. HHI)
temp_set <- subject_data_all_long %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>%
  select(id, Interface, practice_time, Leap_Group)

temp_plot_data <- subject_data_all_long %>% group_by(Interface, Leap_Group) %>%
  filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>% get_summary_stats(practice_time)

p2<- ggplot(temp_set, aes(x=Leap_Group, y=practice_time, fill=Interface, colour = Interface))+
geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=.7)+#,adjust =2)+
geom_point(position = position_jitter(width = 0.1, height=0), size = 1)+ # the "rain"
geom_label(data = temp_plot_data, aes(x = Leap_Group, y = mean, label=ceiling(mean)), position = position_nudge(.5), colour = "white")+
geom_point(data = temp_plot_data, aes(x = Leap_Group, y = mean), position = position_nudge(.25), colour = "BLACK")+
geom_errorbar(data = temp_plot_data, aes(x = Leap_Group, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
ylab('Time (seconds)')+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
scale_colour_brewer(palette = "Set2")+#coord_flip()+
scale_fill_brewer(palette = "Set2")+xlab(NULL)+
stat_pvalue_manual(data=stat.test%>%slice(3:4)%>%mutate(Interface=Group), xmin="group1", xmax="group2", label = "p.adj.signif", step.increase=-.3, y.position=2.5*max(temp_plot_data$mean), position=position_nudge(0.25))+
labs(title="Training times", subtitle="Interface compared to itself, when 1st vs. when 2nd", caption="Means, 95% CI; Within-subjects t-test, adj.: Holm")+
facet_grid(. ~ Interface)#+scale_x_discrete(labels=c("HHI-->Leap","Leap-->HHI"))
ggsave(last_plot(), filename="trainingtime_leapgroup_raincloud.jpg", width=9, height=5)


# each Interface when first
temp_set <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="B_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="HHI_Leap"))
temp_plot_data <- temp_set %>% group_by(Interface)%>% get_summary_stats(practice_time)

p3<- ggplot(temp_set, aes(x=Interface, y=practice_time, fill=Interface, colour = Interface))+
  geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=.7)+#,adjust =2)+
  geom_point(position = position_jitter(width = 0.1, height=0), size = 1)+ # the "rain"
geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=ceiling(mean)), position = position_nudge(.5), colour = "white")+
  geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK")+
  geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
  ylab('Time (seconds)')+xlab(NULL)+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
  scale_colour_brewer(palette = "Set2")+#coord_flip()+
  scale_fill_brewer(palette = "Set2")+
  # stat_compare_means(method="t.test", paired=FALSE, label.x.npc="center")+
  # stat_compare_means(method="wilcox", paired=FALSE, label.x.npc="right")+
  stat_pvalue_manual(data=stat.test%>%slice(5)%>%mutate(Interface="B_Leap"), xmin="group1", xmax="group2", label = "p.adj.signif", y.position=2.5*max(temp_plot_data$mean), position=position_nudge(0.25))+
  labs(title="Training times when 1st", caption="Means, 95% CI; Within-subjects t-test, adj.: Holm")#+facet_grid(. ~ Leap_Group)
ggsave(last_plot(), filename="trainingtime_both_first.jpg", width=6, height=4)


# training times when second (plot) - BETWEEN SUBJECTS
temp_set <- subject_data_all_long %>% ungroup(.) %>% filter((Leap_Group=="B_Leap_first" & Interface=="HHI_Leap") | (Leap_Group=="HHI_Leap_first" & Interface=="B_Leap"))
temp_plot_data <- temp_set %>% group_by(Interface)%>% get_summary_stats(practice_time)

p4<- ggplot(temp_set, aes(x=Interface, y=practice_time, fill=Interface, colour = Interface))+
  geom_flat_violin(position = position_nudge(x = .25, y = 0), alpha=.7)+#,adjust =2)+
  geom_point(position = position_jitter(width = 0.1, height=0), size = 1)+ # the "rain"
geom_label(data = temp_plot_data, aes(x = Interface, y = mean, label=ceiling(mean)), position = position_nudge(.5), colour = "white")+
  geom_point(data = temp_plot_data, aes(x = Interface, y = mean), position = position_nudge(.25), colour = "BLACK")+
  geom_errorbar(data = temp_plot_data, aes(x = Interface, y = mean, ymin=mean-(se*1.96), ymax=mean+(se*1.96)), position = position_nudge(.25), colour = "BLACK", width = 0.05, size = 0.8)+
  ylab('Time (seconds)')+xlab('Interface')+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
  scale_colour_brewer(palette = "Set2")+#coord_flip()+
  scale_fill_brewer(palette = "Set2")+
  # stat_compare_means(method="t.test", paired=FALSE, label.x.npc="center")+
  # stat_compare_means(method="wilcox", paired=FALSE, label.x.npc="right")+
  stat_pvalue_manual(data=stat.test%>%slice(5)%>%mutate(Interface="B_Leap"), xmin="group1", xmax="group2", label = "p.adj.signif", y.position=2.5*max(temp_plot_data$mean), position=position_nudge(0.25))+
  labs(title="Training times when 2nd", subtitle = , caption="Means, 95% CI; Within-subjects t-test, adj.: Holm")#+facet_grid(. ~ Leap_Group)
ggsave(last_plot(), filename="trainingtime_both_first.jpg", width=6, height=4)

plot_grid(p1, p2, p3, p4)
ggsave("practice_times_closer_look.jpg", width=12, height=10)
do_trainingtime<-p1
```

#### I.O. Subjective

```{r Interface_order_subjective}

# Basic stats for Interface order subgroups
table(subject_data_all_wide$InterfaceOrder)
table(subject_data_all_wide$Leap_Group)
table(subject_data_all_wide$Oculus_Group)

cat("leap order within oculus order groups")
cat("Oculus first")
table((subject_data_all_wide %>% filter(Oculus_Group == "Oculus_first"))$Leap_Group)
cat("Oculus last")
table((subject_data_all_wide %>% filter(Oculus_Group == "Oculus_last"))$Leap_Group)


# Interface order for subjective questions

cat("\n\nSubjective Q's -- Interface Order\n")

# comfortable
cat("\nComfortable\n")
Interface.order.anova <-
  anova_summary(effect.size="pes",aov(score ~ Interface*InterfaceOrder + Error(id/Interface), data=likert_scores %>% filter(question=="comfortable")))
Interface.order.anova %>% filter(`p<.05`=="*")

  # Leap group
  leap.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Leap_Group + Error(id/Interface), data=likert_scores%>%ungroup%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap", question=="comfortable")))
  leap.group.anova %>% filter(`p<.05`=="*")
  
  # Oculus
    #Oculus group
    oculus.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Oculus_Group + Error(id/Interface),
        data=likert_scores%>%ungroup%>%
          filter(Oculus_Group=="Oculus_first" | Oculus_Group=="Oculus_last", Interface!="Oculus",
                 question=="comfortable") %>% mutate(Interface=factor(Interface))))
    oculus.group.anova %>% filter(p<0.1)
    
  Interface_order_output <- Interface_order_output %>% rbind(Interface.order.anova %>% rbind(Interface.order.anova2) %>% rbind(oculus.group.anova) %>% mutate(metric="comfortable", p=round(p, 4)) %>% select(metric, everything()))

    
  # t test
t.test<- likert_scores %>% ungroup %>%
    filter(Oculus_Group=="Oculus_first" | Oculus_Group=="Oculus_last", Interface!="Oculus",
               question=="comfortable") %>% 
    mutate(Interface=factor(Interface), Oculus_Group=factor(Oculus_Group)) %>% group_by(Oculus_Group) %>%
 pairwise_t_test(score ~ Interface, paired=TRUE)
#t.test

# precise
cat("\nPrecise\n")

Interface.order.anova <-
  anova_summary(effect.size="pes",aov(score ~ Interface*InterfaceOrder + Error(id/Interface), data=likert_scores %>% filter(question=="precise")))
Interface.order.anova %>% filter(`p<.05`=="*")

  # Leap group
  leap.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Leap_Group + Error(id/Interface), data=likert_scores%>%ungroup%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap", question=="precise")))
  leap.group.anova %>% filter(`p<.05`=="*")
  
  #oculus group
    oculus.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Oculus_Group + Error(id/Interface),
        data=likert_scores%>%ungroup%>%
          filter(Oculus_Group=="Oculus_first" | Oculus_Group=="Oculus_last", Interface!="Oculus",
                 question=="precise") %>% mutate(Interface=factor(Interface))))
    oculus.group.anova %>% filter(`p<.05`=="*")
    oculus.group.anova %>% filter(p<0.1)

Interface_order_output <- Interface_order_output %>% rbind(Interface.order.anova %>% rbind(Interface.order.anova2) %>% rbind(oculus.group.anova) %>% mutate(metric="precise", p=round(p, 4)) %>% select(metric, everything()))

    
# intuitive
cat("\nIntuitive\n")
Interface.order.anova <-
  anova_summary(effect.size="pes",aov(score ~ Interface*InterfaceOrder + Error(id/Interface), data=likert_scores %>% filter(question=="intuitive")))
Interface.order.anova %>% filter(`p<.05`=="*")
  
  # Leap group
  leap.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Leap_Group + Error(id/Interface), data=likert_scores%>%ungroup%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap", question=="intuitive")))
  leap.group.anova %>% filter(`p<.05`=="*")

  # oculus group
    oculus.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Oculus_Group + Error(id/Interface),
        data=likert_scores%>%ungroup%>%
          filter(Oculus_Group=="Oculus_first" | Oculus_Group=="Oculus_last", Interface!="Oculus",
                 question=="intuitive") %>% mutate(Interface=factor(Interface))))
    oculus.group.anova %>% filter(`p<.05`=="*")
    oculus.group.anova %>% filter(p<0.1)

Interface_order_output <- Interface_order_output %>% rbind(Interface.order.anova %>% rbind(Interface.order.anova2) %>% rbind(oculus.group.anova) %>% mutate(metric="intuitive", p=round(p, 4)) %>% select(metric, everything()))
    
    
# tiring
cat("\nTiring\n")

Interface.order.anova <-
  anova_summary(effect.size="pes",aov(score ~ Interface*InterfaceOrder + Error(id/Interface), data=likert_scores %>% filter(question=="tiring")))
Interface.order.anova %>% filter(`p<.05`=="*")
  
  # Leap group
  leap.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Leap_Group + Error(id/Interface), data=likert_scores%>%ungroup%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap", question=="tiring")))
  leap.group.anova %>% filter(`p<.05`=="*")
  
  # oculus group
    oculus.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Oculus_Group + Error(id/Interface),
        data=likert_scores%>%ungroup%>%
          filter(Oculus_Group=="Oculus_first" | Oculus_Group=="Oculus_last", Interface!="Oculus",
                 question=="tiring") %>% mutate(Interface=factor(Interface))))
    oculus.group.anova %>% filter(`p<.05`=="*")
    oculus.group.anova %>% filter(p<0.1)
  
Interface_order_output <- Interface_order_output %>% rbind(Interface.order.anova %>% rbind(Interface.order.anova2) %>% rbind(oculus.group.anova) %>% mutate(metric="tiring", p=round(p, 4)) %>% select(metric, everything()))
    
    
# gripping
cat("\nGripping\n")

Interface.order.anova <-
  anova_summary(effect.size="pes",aov(score ~ Interface*InterfaceOrder + Error(id/Interface), data=likert_scores %>% filter(question=="gripping")))
Interface.order.anova %>% filter(`p<.05`=="*")
  
  # Leap group
  leap.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Leap_Group + Error(id/Interface), data=likert_scores%>%ungroup%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap", question=="gripping")))
  leap.group.anova %>% filter(`p<.05`=="*")
  
  # oculus group
      oculus.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Oculus_Group + Error(id/Interface),
        data=likert_scores%>%ungroup%>%
          filter(Oculus_Group=="Oculus_first" | Oculus_Group=="Oculus_last", Interface!="Oculus",
                 question=="gripping") %>% mutate(Interface=factor(Interface))))
    oculus.group.anova %>% filter(`p<.05`=="*")
    oculus.group.anova %>% filter(p<0.1)
  
Interface_order_output <- Interface_order_output %>% rbind(Interface.order.anova %>% rbind(Interface.order.anova2) %>% rbind(oculus.group.anova) %>% mutate(metric="gripping", p=round(p, 4)) %>% select(metric, everything()))
    
    
# releasing
  cat("\nReleasing\n")

Interface.order.anova <-
  anova_summary(effect.size="pes",aov(score ~ Interface*InterfaceOrder + Error(id/Interface), data=likert_scores %>% filter(question=="releasing")))
Interface.order.anova %>% filter(`p<.05`=="*")
  
  # Leap group
  leap.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Leap_Group + Error(id/Interface), data=likert_scores%>%ungroup%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap", question=="releasing")))
  leap.group.anova %>% filter(`p<.05`=="*")
  
    # oculus group
      oculus.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Oculus_Group + Error(id/Interface),
        data=likert_scores%>%ungroup%>%
          filter(Oculus_Group=="Oculus_first" | Oculus_Group=="Oculus_last", Interface!="Oculus",
                 question=="releasing") %>% mutate(Interface=factor(Interface))))
    oculus.group.anova %>% filter(`p<.05`=="*")
    oculus.group.anova %>% filter(p<0.1)
    
Interface_order_output <- Interface_order_output %>% rbind(Interface.order.anova %>% rbind(Interface.order.anova2) %>% rbind(oculus.group.anova) %>% mutate(metric="releasing", p=round(p, 4)) %>% select(metric, everything()))

  
# natural
  cat("\nNatural\n")

Interface.order.anova <-
  anova_summary(effect.size="pes",aov(score ~ Interface*InterfaceOrder + Error(id/Interface), data=likert_scores %>% filter(question=="natural")))
Interface.order.anova %>% filter(`p<.05`=="*")
  
  # Leap group
  leap.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Leap_Group + Error(id/Interface), data=likert_scores%>%ungroup%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap", question=="natural")))
  leap.group.anova %>% filter(`p<.05`=="*")
  
    # oculus group
      oculus.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Oculus_Group + Error(id/Interface),
        data=likert_scores%>%ungroup%>%
          filter(Oculus_Group=="Oculus_first" | Oculus_Group=="Oculus_last", Interface!="Oculus",
                 question=="natural") %>% mutate(Interface=factor(Interface))))
    oculus.group.anova %>% filter(`p<.05`=="*")
    oculus.group.anova %>% filter(p<0.1)
    
Interface_order_output <- Interface_order_output %>% rbind(Interface.order.anova %>% rbind(Interface.order.anova2) %>% rbind(oculus.group.anova) %>% mutate(metric="natural", p=round(p, 4)) %>% select(metric, everything()))

  
# recommend
  cat("\nRecommend\n")

Interface.order.anova <-
  anova_summary(effect.size="pes",aov(score ~ Interface*InterfaceOrder + Error(id/Interface), data=likert_scores %>% filter(question=="recommend")))
Interface.order.anova %>% filter(`p<.05`=="*")
  
  # Leap group
  leap.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Leap_Group + Error(id/Interface), data=likert_scores%>%ungroup%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap", question=="recommend")))
  leap.group.anova %>% filter(`p<.05`=="*")
  
    # oculus group
      oculus.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Oculus_Group + Error(id/Interface),
        data=likert_scores%>%ungroup%>%
          filter(Oculus_Group=="Oculus_first" | Oculus_Group=="Oculus_last", Interface!="Oculus",
                 question=="recommend") %>% mutate(Interface=factor(Interface))))
    oculus.group.anova %>% filter(`p<.05`=="*")
    oculus.group.anova %>% filter(p<0.1)
    
Interface_order_output <- Interface_order_output %>% rbind(Interface.order.anova %>% rbind(Interface.order.anova2) %>% rbind(oculus.group.anova) %>% mutate(metric="recommend", p=round(p, 4)) %>% select(metric, everything()))

  
# agency
  cat("\nAgency\n")

Interface.order.anova <-
  anova_summary(effect.size="pes",aov(score ~ Interface*InterfaceOrder + Error(id/Interface), data=likert_scores %>% filter(question=="agency")))
Interface.order.anova %>% filter(`p<.05`=="*")
  
  # Leap group
  leap.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Leap_Group + Error(id/Interface), data=likert_scores%>%ungroup%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap", question=="agency")))
  leap.group.anova %>% filter(`p<.05`=="*")
  
    # oculus group
      oculus.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Oculus_Group + Error(id/Interface),
        data=likert_scores%>%ungroup%>%
          filter(Oculus_Group=="Oculus_first" | Oculus_Group=="Oculus_last", Interface!="Oculus",
                 question=="agency")))
    oculus.group.anova %>% filter(`p<.05`=="*")
    oculus.group.anova %>% filter(p<0.1)
    
Interface_order_output <- Interface_order_output %>% rbind(Interface.order.anova %>% rbind(Interface.order.anova2) %>% rbind(oculus.group.anova) %>% mutate(metric="agency", p=round(p, 4)) %>% select(metric, everything()))


  
# satisfaction
  cat("\nSatisfaction\n")

Interface.order.anova <-
  anova_summary(effect.size="pes",aov(score ~ Interface*InterfaceOrder + Error(id/Interface), data=likert_scores %>% filter(question=="satisfaction")))
Interface.order.anova %>% filter(`p<.05`=="*")
  
  # Leap group
  leap.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Leap_Group + Error(id/Interface), data=likert_scores%>%ungroup%>%filter(Interface=="B_Leap" | Interface=="HHI_Leap", question=="satisfaction")))
  leap.group.anova %>% filter(`p<.05`=="*")
  
    # oculus group
      oculus.group.anova <-
    anova_summary(effect.size="pes",aov(score ~ Interface*Oculus_Group + Error(id/Interface),
        data=likert_scores%>%ungroup%>%
          filter(Oculus_Group=="Oculus_first" | Oculus_Group=="Oculus_last", Interface!="Oculus",
                 question=="satisfaction") %>% mutate(Interface=factor(Interface))))
    oculus.group.anova %>% filter(`p<.05`=="*")
    oculus.group.anova %>% filter(p<0.1)

Interface_order_output <- Interface_order_output %>% rbind(Interface.order.anova %>% rbind(Interface.order.anova2) %>% rbind(oculus.group.anova) %>% mutate(metric="satisfaction", p=round(p, 4)) %>% select(metric, everything()))

    
#SUS
  cat("\nSUS score\n")

Interface.order.anova <-
  anova_summary(effect.size="pes",aov(SUS ~ Interface*InterfaceOrder + Error(id/Interface), data=subject_data_all_long))
Interface.order.anova %>% filter(`p<.05`=="*")
  
  # Leap group
  leap.group.anova <-
    anova_summary(effect.size="pes",aov(SUS ~ Interface*Leap_Group + Error(id/Interface), data=subject_data_all_long %>% ungroup %>% filter(Interface=="B_Leap" | Interface=="HHI_Leap") %>% mutate(Interface=factor(Interface))))
  leap.group.anova %>% filter(`p<.05`=="*")
  
    # oculus group
      oculus.group.anova <-
    anova_summary(effect.size="pes",aov(SUS ~ Interface*Oculus_Group + Error(id/Interface),
        data=subject_data_all_long %>% ungroup %>%
          filter(Oculus_Group=="Oculus_first" | Oculus_Group=="Oculus_last", Interface!="Oculus") %>%
          mutate(Interface=factor(Interface))))
    oculus.group.anova %>% filter(`p<.05`=="*")
    oculus.group.anova %>% filter(p<0.1)

Interface_order_output <- Interface_order_output %>% rbind(Interface.order.anova %>% rbind(Interface.order.anova2) %>% rbind(oculus.group.anova) %>% mutate(metric="SUS", p=round(p, 4)) %>% select(metric, everything()))

    

# pairwise t-tests
likert_scores %>% filter(Interface=="HHI_Leap", Oculus_Group!="NA") %>% group_by(question) %>%
  pairwise_t_test(score ~ Oculus_Group) %>% adjust_pvalue() %>% add_significance(p.col="p.adj", output.col="p.adj.signif")
    
#Overall preference
  cat("\nOverall preference\n")

# Interface order and preferred condition
  # note: counts may be too low for chi sq
chi<- chisq.test(table(subject_data_all_wide$InterfaceOrder, subject_data_all_wide$PrefCondition))
# chi$expected
# chi$observed
# chi

chi<- chisq.test(table(subject_data_all_wide$Oculus_Group, subject_data_all_wide$PrefCondition))
# chi$expected
# chi$observed
# chi

```

#### I.O. Plots

```{r Interface_order_plots}

# leap group and times
plot_grid(do_grabtime, do_releasetime, do_totaltime, do_trainingtime)
ggsave("Interface_order_leapgroup_times.jpg", width=10, height=10)

# performance
ggplot(subject_data_all_long %>% filter(Interface!="Oculus") %>%
         mutate(InterfaceOrder=factor(InterfaceOrder, levels=c("OLH", "OHL", "LOH", "HOL", "LHO", "HLO")),
                Interface=factor(Interface)),
       aes(InterfaceOrder, Distance, color=Interface))+
  geom_boxplot()

# subjective
# box plots of scores on subjective questions, comparing oculus groups (for leaps)

# leaps together
ggplot(likert_scores %>% filter(Interface!="Oculus", Oculus_Group!="NA"), aes(question, score, fill=Oculus_Group))+
  geom_boxplot()+
  #facet_grid(.~Oculus_Group)+
  labs(title="all questions (both Leaps combined)")#+coord_flip()

#leaps separate -- seems that only HHI Leap is different
ggplot(likert_scores %>% filter(Interface!="Oculus", Oculus_Group!="NA"), aes(question, score, fill=Oculus_Group))+
  geom_boxplot()+scale_fill_manual(values=c("yellow3","violet"))+
  facet_grid(.~Interface)+coord_flip()+
  labs(title="Oculus order: HHI Leap vs. B_Leap for all subjective questions", caption = "Boxplots, medians and IQR with whiskers at 1.5*IQR")
ggsave("oculus_order_plot.jpg", width=10, height=7)

# just HHI (close-up of above)
# these have higher medians for Oculus_last: tiring, satisfaction, recommend, gripping, agency, comfortable
ggplot(likert_scores %>% filter(Interface=="HHI_Leap", Oculus_Group!="NA") %>% group_by(question), aes(question, score, fill=Oculus_Group))+
  geom_boxplot()+
  #facet_grid(.~Interface)+
  labs(title="Oculus order - all subjective questions (HHI Leap)")#+coord_flip()

# looks like there might be an effect purely on the Oculus. This should have manifested itself as an interaction in the ANOVA, but perhaps ANOVA was not powerful enough to detect it. t-tests would have the same problem, I suppose.

likert_scores %>% filter(Interface=="HHI_Leap", question=="agency") %>% wilcox_test(score ~ Oculus_Group)
# t-test is significant for agency
likert_scores %>% filter(Interface=="HHI_Leap", question=="agency") %>% t_test(score ~ Oculus_Group)


ggplot(likert_scores %>% filter(Interface!="Oculus", question=="precise") %>%
         mutate(InterfaceOrder=factor(InterfaceOrder, levels=c("OLH", "OHL", "LOH", "HOL", "LHO", "HLO")),
                Interface=factor(Interface)),
       aes(InterfaceOrder, score))+
  geom_point(position=position_jitter(width=.1))+
  geom_boxplot()+
  labs(title="Precise scores (Leaps Only) x Oculus order")

ggplot(likert_scores %>% filter(Interface!="Oculus", Oculus_Group!="NA", question=="precise") %>%
                mutate(Interface=factor(Interface)),
       aes(Oculus_Group, score, color=Interface))+
  geom_point(position=position_jitter(width=.1))+
  geom_boxplot()

ggplot(likert_scores %>% filter(Interface!="Oculus", Oculus_Group!="NA", question=="recommend") %>%
                mutate(Interface=factor(Interface)),
       aes(Oculus_Group, score, fill=Interface))+
  #geom_point(position=position_jitter(width=.1))+
  geom_boxplot()

ggplot(likert_scores %>% filter(Interface!="Oculus", Oculus_Group!="NA", question=="agency") %>%
                mutate(Interface=factor(Interface)),
       aes(Oculus_Group, score, color=Interface))+
  geom_point(position=position_jitter(width=.1), color="black", size=.5)+
  geom_boxplot(aes(middle=mean(score)), width=.4, fill="transparent")


# preferred condition
subject_data_all_wide <- subject_data_all_wide %>%
  mutate(InterfaceOrder=factor(InterfaceOrder, levels=c("OLH", "OHL", "LOH", "HOL", "LHO", "HLO")))
                
ggplot(subject_data_all_wide, aes(factor(PrefCondition, levels=c("HHI_Leap", "B_Leap", "Oculus"))))+
  geom_bar(fill="grey")+
  scale_fill_brewer(palette="Set2")+
  facet_grid(. ~ InterfaceOrder)+
  labs(x="", title="Overall Preferred Interface")

ggplot(subject_data_all_long %>% filter(Oculus_Group!="NA") %>% select(id, PrefCondition, Oculus_Group) %>% distinct(.), aes(factor(PrefCondition, levels=c("HHI_Leap", "B_Leap", "Oculus"))))+
  geom_bar(fill="grey")+
  scale_fill_brewer(palette="Set2")+
  facet_grid(. ~ Oculus_Group)+
  labs(x="", title="Overall Preferred Interface")

```

# All tables

```{r all_tables}
# demographics
cat("Demographics")
demographics

# anovas - Interface level
cat("\nDistance")
anova.Interface.distance
cat("\nTotal time")
print(anova.Interface.totaltime)
cat("\nGrab time")
print(anova.Interface.grabtime)
cat("\nRelease time")
print(anova.Interface.releasetime)
cat("\n")

```

## Output to file

```{r output_to_file}

sink("results_tables.csv")

cat("\nDemographics\n")
write.csv(demographics$descriptives)
cat("\nGender")
write.csv(demographics$gender)
cat("\nHandedness")
write.csv(demographics$handedness)
cat("\nExperience\n")
write.csv(exp_counts)

cat("\nInterface Order")
table(Interface_order$InterfaceOrder)
cat("\nLeap groups")
table(subject_data_all_wide$Leap_Group)

cat("\nPerformance measures\n")

cat("\nAccuracy\n")
cat("\nby Interface")
cat("\nDescriptives")
write.csv(descriptives.Interface.distance)
cat("\nANOVA")
write.csv(anova.Interface.distance)
cat("\nt-tests")
write.csv(ttest.Interface.distance)
cat("\nby Cube Size and Interface")
cat("\nDescriptives")
write.csv(descriptives.Interface.cubesize.distance)
cat("\nANOVA")
write.csv(anova.Interface.cubesize.distance)
cat("\nt-tests")
write.csv(ttest.Interface.cubesize.distance)

cat("\nTotal time")
cat("\nby Interface")
cat("\nDescriptives")
write.csv(descriptives.Interface.totaltime)
cat("\nANOVA")
write.csv(anova.Interface.totaltime)
cat("\nt-tests")
write.csv(ttest.Interface.totaltime)
cat("\nby Cube Size and Interface")
cat("\nDescriptives")
write.csv(descriptives.Interface.cubesize.totaltime)
cat("\nANOVA")
write.csv(anova.Interface.cubesize.totaltime)
cat("\nt-tests")
write.csv(ttest.Interface.cubesize.totaltime)

cat("\nGrab time")
cat("\nby Interface")
cat("\nDescriptives")
write.csv(descriptives.Interface.grabtime)
cat("\nANOVA")
write.csv(anova.Interface.grabtime)
cat("\nt-test")
write.csv(ttest.Interface.grabtime)
cat("\nby Cube Size and Interface")
cat("\nDescriptives")
write.csv(descriptives.Interface.cubesize.grabtime)
cat("\nANOVA")
write.csv(anova.Interface.cubesize.grabtime)
cat("\nt-test")
write.csv(ttest.Interface.cubesize.grabtime)

cat("\nRelease time")
cat("\nby Interface")
cat("\nDescriptives")
write.csv(descriptives.Interface.releasetime)
cat("\nANOVA")
write.csv(anova.Interface.releasetime)
cat("\nt-test")
write.csv(ttest.Interface.releasetime)
cat("\nby Cube Size and Interface")
cat("\nDescriptives")
write.csv(descriptives.Interface.cubesize.releasetime)
cat("\nANOVA")
write.csv(anova.Interface.cubesize.releasetime)
cat("\nt-test")
write.csv(ttest.Interface.cubesize.releasetime)

cat("\nAccidental drops")
cat("\nby Interface")
cat("\nDescriptives")
write.csv(descriptives.Interface.drops)
cat("\nANOVA")
write.csv(anova.Interface.drops)
cat("\nt-test")
write.csv(ttest.Interface.drops)
cat("\nby Cube Size and Interface")
cat("\nDescriptives")
write.csv(descriptives.Interface.cubesize.drops)
cat("\nANOVA")
write.csv(anova.Interface.cubesize.drops)
cat("\nt-test")
write.csv(ttest.Interface.cubesize.drops)

cat("\nDifference: HHI Leap to Oculus\n")
write.csv(oculus_diffs)

cat("\n\nSubjective\n")
cat("\n(by Interface)")

cat("\nSUS")
cat("\nDescriptives")
write.csv(descriptives.sus)
cat("\nANOVA")
write.csv(anova.SUS)
cat("\nt-test")
write.csv(ttest.SUS)

cat("\n\n5-pt Likert Questions")
cat("\nDescriptives")
write.csv(descriptives.subjective5pt)
cat("\nGrand ANOVA 5pt")
write.csv(anova.Interface.5ptgrand)
cat("\nIndividual ANOVAs")
write.csv(anova.likert %>% filter(question != "agency" & question != "satisfaction"))
cat("\nGrand t-tests 5pt")
write.csv(ttest.Interface.5ptgrand)
cat("\nIndividual t-tests 5pt")
write.csv(t.tests.likert.all.vs.hhi %>% filter(question != "agency" & question != "satisfaction") %>% select(-Interface))

cat("\n\n7-pt Likert Questions")
cat("\nDescriptives")
write.csv(descriptives.subjective7pt)
cat("\nGrand ANOVA 7pt")
write.csv(anova.Interface.7ptgrand)
cat("\nIndividual ANOVAs")
write.csv(anova.likert %>% filter(question == "agency" | question == "satisfaction"))
cat("\nGrand t-tests 7pt")
write.csv(ttest.Interface.7ptgrand)
cat("\nIndividual t-tests 7pt")
write.csv(t.tests.likert.all.vs.hhi %>% filter(question == "agency" | question == "satisfaction") %>% select(-Interface))

cat("\n\nOverall preference\n")
write.csv(preference)

cat("\nDATA CLEANING\n")
cat("Cut and add to accidental drop count:
- Distance >=0.2
- Distance >= 0.1 & <= 0.2 & TimeFromGrabToGrabLoss < 0.5
- LandOnTable==FALSE\n")
cat("\nTotal trials before clean: ", length(data_set$id))
cat("\nTotal trials AFTER clean: ", length(unity_data_clean$id))

cat("\n\nACCIDENTAL DROP REPORT")
cat("\nTotal accidental drops: ", accidental_drops_total)
cat("\nManual detection: ", accidental_drops_manual, " (", round(accidental_drops_manual.percent, 1), "% of original trials)")
cat("\nAutomatic detection: ", accidental_drops_auto_detect, " (", round(accidental_drops_auto_detect.percent, 1), "% of original trials)")
cat("\nAuto, not detected by manual: ", accidental_drops_auto_only)
cat("\nManual, not detected by auto: ", accidental_drops_manual_only)

sink()
```

```{r output_anovas}
# output all anovas in one place
all_anovas <- bind_rows(
  anova.Interface.distance %>% mutate(Measure="Accuracy") %>% select(Measure, everything()),
  anova.Interface.totaltime %>% mutate(Measure="Total Time") %>% select(Measure, everything()),
  anova.Interface.grabtime %>% mutate(Measure="Grab Time") %>% select(Measure, everything()),
  anova.Interface.releasetime %>% mutate(Measure="Release Time") %>% select(Measure, everything()),
  anova.Interface.drops %>% mutate(Measure="Accidental Drops") %>% select(Measure, everything()),
  anova.SUS %>% mutate(Measure="SUS") %>% select(Measure, everything()),
  anova.likert %>% rename(Measure=question) %>% select(Measure, everything())
) %>% select(-`p<.05`, -Effect) #%>% mutate(F=round(F,2))#, p="<.001")
# then set p values to be "p < .001" (if true) and remove the *
all_anovas[which(all_anovas$p<.001),"p"] <- "p < .001"
all_anovas
sink("anova_data.csv")
cat("ANOVAs\n")
write.csv(all_anovas)
sink()

# output table for LaTeX
stargazer(all_anovas, summary=FALSE, rownames = FALSE, title="caption here")

```

```{r output_t-tests}

Measure=c("Accuracy (m)","Total Time (s)","Grab Time (s)","Release Time (s)","Accidental Drops (#)")

# build df of mean and sd for HHI Leap performance metrics
temp_df <- subject_data_all_long %>% ungroup() %>% filter(Interface=="HHI_Leap")
hhi_leap_mean_sd <- #left_join(get_summary_stats(temp_df, Distance,))
  data.frame(Measure=Measure,
      HHI_Leap_Mean=c(mean(temp_df$Distance), mean(temp_df$totaltime), mean(temp_df$grabtime), mean(temp_df$releasetime), mean(temp_df$Drop_Count)),
      HHI_Leap_SD=c(sd(temp_df$Distance), sd(temp_df$totaltime), sd(temp_df$grabtime), sd(temp_df$releasetime), sd(temp_df$Drop_Count))
             )
# build df of mean and sd for Oculus performance metrics
temp_df <- subject_data_all_long %>% ungroup() %>% filter(Interface=="Oculus")
oculus_mean_sd <-
  data.frame(Measure=Measure,
      Oculus_Mean=c(mean(temp_df$Distance), mean(temp_df$totaltime), mean(temp_df$grabtime), mean(temp_df$releasetime), mean(temp_df$Drop_Count)),
      Oculus_SD=c(sd(temp_df$Distance), sd(temp_df$totaltime), sd(temp_df$grabtime), sd(temp_df$releasetime), sd(temp_df$Drop_Count))
             )
# combine hhi and oculus means and sd's
hhi_leap_oculus_mean_sd <- left_join(hhi_leap_mean_sd, oculus_mean_sd)

# build df of mean and sd for HHI and b_leap performance metrics
temp_df <- subject_data_all_long %>% ungroup() %>% filter(Interface=="B_Leap")
b_leap_mean_sd <-
  data.frame(Measure=Measure,
      B_Leap_Mean=c(mean(temp_df$Distance), mean(temp_df$totaltime), mean(temp_df$grabtime), mean(temp_df$releasetime), mean(temp_df$Drop_Count)),
      B_Leap_SD=c(sd(temp_df$Distance), sd(temp_df$totaltime), sd(temp_df$grabtime), sd(temp_df$releasetime), sd(temp_df$Drop_Count))
             )
# combine hhi_leap and b_leap performance metric means and sd's
hhi_leap_b_leap_mean_sd <- left_join(hhi_leap_mean_sd, b_leap_mean_sd)

# performance t test results (add "measure" column)
all_ttests_interface <- bind_rows(
  ttest.Interface.distance %>% mutate(Measure="Accuracy (m)"),
  ttest.Interface.totaltime %>% mutate(Measure="Total Time (s)"),
  ttest.Interface.grabtime %>% mutate(Measure = "Grab Time (s)"),
  ttest.Interface.releasetime %>% mutate(Measure = "Release Time (s)"),
  ttest.Interface.drops %>% mutate(Measure = "Accidental Drops (#)")
)

# build performance t-test table for HHI vs Oculus
all_ttests_interface_hhiVsOculus <-
  all_ttests_interface %>% filter(group2 == "Oculus") %>%
  left_join(hhi_leap_oculus_mean_sd, by="Measure") %>%
  select(Measure, HHI_Leap_Mean, HHI_Leap_SD, Oculus_Mean, Oculus_SD, t=statistic, df, `p(Holm)`=p.adj) %>%
  # add SUS 
  bind_rows(
    left_join(SUS_mean_sd %>% select(Measure, HHI_Leap_Mean, HHI_Leap_SD,  Oculus_Mean, Oculus_SD),
              ttest.SUS %>% filter(group2=="Oculus") %>% mutate(Measure=`.y.`) %>%
                select(Measure, t=statistic, df, `p(Holm)`=p.adj), by="Measure")) %>%
  # add subjective scores
  bind_rows(
    # combine means/sd's and t-test results
    left_join(
      subjective_mean_sd %>% select(Measure, HHI_Leap_Mean, HHI_Leap_SD, Oculus_Mean, Oculus_SD),
      ttests_subjective_all %>% filter(group2=="Oculus") %>% rename(Measure=question) %>%
        select(Measure, t=statistic, df, `p(Holm)`=p.adj), by="Measure")) %>%
  # round numbers (rounds down)
  mutate_if(is.numeric, round, 4)
# change p =0 to p <.001
all_ttests_interface_hhiVsOculus[which(all_ttests_interface_hhiVsOculus$`p(Holm)`<.001),"p(Holm)"] <- "p < .001"
  
# build performance t-test table for HHI vs B_Leap
all_ttests_interface_hhiVsBLeap <-
  all_ttests_interface %>% filter(group1== "B_Leap") %>%
  left_join(hhi_leap_b_leap_mean_sd, by="Measure") %>%
  select(Measure, HHI_Leap_Mean, HHI_Leap_SD, B_Leap_Mean, B_Leap_SD, t=statistic, df, `p(Holm)`=p.adj) %>%
  mutate(t=-t) %>%
    # add SUS 
  bind_rows(
    left_join(SUS_mean_sd %>% select(Measure, HHI_Leap_Mean, HHI_Leap_SD,  B_Leap_Mean, B_Leap_SD),
              ttest.SUS %>% filter(group1=="B_Leap") %>% mutate(Measure=`.y.`) %>% 
                select(Measure, t=statistic, df, `p(Holm)`=p.adj), by="Measure")) %>% # add subjective scores
  bind_rows(
    left_join(
      subjective_mean_sd %>% select(Measure, HHI_Leap_Mean, HHI_Leap_SD,  B_Leap_Mean, B_Leap_SD),
      ttests_subjective_all %>% filter(group2=="B_Leap") %>% mutate(Measure=question) %>%
        select(Measure, t=statistic, df, `p(Holm)`=p.adj), by="Measure")
  ) %>%
  # round numbers (rounds down)
  mutate_if(is.numeric, round, 4)
# change p =0 to p <.001
all_ttests_interface_hhiVsBLeap[which(all_ttests_interface_hhiVsBLeap$`p(Holm)`<.001),"p(Holm)"] <- "p < .001"

stargazer(all_ttests_interface_hhiVsOculus, summary=FALSE, rownames = FALSE, title="caption")
stargazer(all_ttests_interface_hhiVsBLeap, summary=FALSE, rownames = FALSE, title="caption")



# # output all performance t-tests
# all_performance_ttests_oculus <- bind_rows(
#   subject_data_all_long %>% t_test(Distance ~ Interface, comparisons = list(c("HHI_Leap","Oculus")), paired = TRUE),
#   subject_data_all_long %>% t_test(totaltime ~ Interface, comparisons = list(c("HHI_Leap","Oculus")), paired = TRUE),
#   subject_data_all_long %>% t_test(grabtime ~ Interface, comparisons = list(c("HHI_Leap","Oculus")), paired = TRUE),
#   subject_data_all_long %>% t_test(releasetime ~ Interface, comparisons = list(c("HHI_Leap","Oculus")), paired = TRUE),
#   subject_data_all_long %>% t_test(Drop_Count ~ Interface, comparisons = list(c("HHI_Leap","Oculus")), paired = TRUE)
# ) %>% adjust_pvalue(p.col="p", output.col="p.adj") %>% cbind(Measure) %>% select(Measure, t=statistic, df, p, `p(Holm)`=p.adj)
# all_performance_ttests_oculus
# 
# all_performance_ttests_leap <- bind_rows(
#   subject_data_all_long %>% t_test(Distance ~ Interface, comparisons = list(c("HHI_Leap","B_Leap")), paired = TRUE),
#   subject_data_all_long %>% t_test(totaltime ~ Interface, comparisons = list(c("HHI_Leap","B_Leap")), paired = TRUE),
#   subject_data_all_long %>% t_test(grabtime ~ Interface, comparisons = list(c("HHI_Leap","B_Leap")), paired = TRUE),
#   subject_data_all_long %>% t_test(releasetime ~ Interface, comparisons = list(c("HHI_Leap","B_Leap")), paired = TRUE),
#   subject_data_all_long %>% t_test(Drop_Count ~ Interface, comparisons = list(c("HHI_Leap","B_Leap")), paired = TRUE)
# ) %>% adjust_pvalue(p.col="p", output.col="p.adj") %>% mutate(statistic=-1*statistic) %>% select(Measure=`.y.`, t=statistic, df, p, `p(Holm)`=p.adj)
# all_performance_ttests_leap
# 
# # output to file
# sink("ttest_stats.csv")
# cat("t-tests: Performance Measures (HHI_Leap and Oculus)\n")
# write.csv(all_performance_ttests_oculus)
# cat("\nt-tests: Performance Measures (HHI_Leap and B_Leap)\n")
# write.csv(all_performance_ttests_leap)
# sink()

# # output table for LaTeX
# stargazer(all_performance_ttests %>%
#             select(-p) %>%
#             mutate(`p(Holm)`=round(`p(Holm)`, 3), t=round(t, 3)), summary=FALSE, rownames = FALSE, title="ANOVA Results: Performance Measures")

```

### Output Interface order

```{r output_Interface_order}

write.csv(file = "Interface_order_anova_tables.csv", Interface_order_output)

```


